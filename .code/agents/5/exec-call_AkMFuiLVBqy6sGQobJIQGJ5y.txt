scripts/call-chain-dataflow.sh:12:# --- ÂÜÖÈÉ®Áä∂ÊÄÅÂèòÈáèÔºàÂ∫îÈÄöËøáÂáΩÊï∞ËÆøÈóÆÔºâ ---
scripts/call-chain-dataflow.sh:79:  echo "$DATA_FLOW_SYMBOL_INDEX" | jq -r --arg s "$symbol" '.[$s] // empty'
scripts/call-chain-dataflow.sh:86:  DATA_FLOW_SYMBOL_INDEX=$(echo "$DATA_FLOW_SYMBOL_INDEX" | jq --arg k "$name" --arg v "${file}|${line}" '. + {($k): $v}')
scripts/call-chain-dataflow.sh:119:  if [ -z "$DATA_FLOW_FILE" ]; then
scripts/call-chain-dataflow.sh:128:  if [ ! -f "$resolved" ]; then
scripts/call-chain-dataflow.sh:147:  if command -v python3 &>/dev/null; then
scripts/call-chain-dataflow.sh:156:  if command -v node &>/dev/null; then
scripts/call-chain-dataflow.sh:157:    node -e 'const path=require("path"); console.log(path.resolve(process.argv[1], process.argv[2]));' "$base" "$rel"
scripts/call-chain-dataflow.sh:185:    if [ -f "$candidate" ]; then
scripts/call-chain-dataflow.sh:191:  if [ -d "$resolved" ]; then
scripts/call-chain-dataflow.sh:200:      if [ -f "$index_candidate" ]; then
scripts/call-chain-dataflow.sh:215:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/call-chain-dataflow.sh:217:  [ -z "$rg_cmd" ] && rg_cmd=$(command -v rg 2>/dev/null || true)
scripts/call-chain-dataflow.sh:220:  if [ -n "$rg_cmd" ]; then
scripts/call-chain-dataflow.sh:221:    lines=$("$rg_cmd" -n "^import " "$file" 2>/dev/null || true)
scripts/call-chain-dataflow.sh:223:    lines=$(grep -nE "^import " "$file" 2>/dev/null || true)
scripts/call-chain-dataflow.sh:227:  while IFS= read -r line; do
scripts/call-chain-dataflow.sh:228:    [ -z "$line" ] && continue
scripts/call-chain-dataflow.sh:231:    import_path=$(printf '%s\n' "$line" | sed -E "s/.*from[[:space:]]+['\\\"]([^'\\\"]+)['\\\"].*/\\1/")
scripts/call-chain-dataflow.sh:247:    symbols=$(echo "$line" | sed -E 's/.*[{]([^}]*)[}].*/\1/')
scripts/call-chain-dataflow.sh:249:      IFS=',' read -r -a items <<< "$symbols"
scripts/call-chain-dataflow.sh:252:        item=$(echo "$item" | sed -E 's/^[[:space:]]+|[[:space:]]+$//g')
scripts/call-chain-dataflow.sh:256:        [ -n "$item" ] && map+="${item}|${import_path}"$'\n'
scripts/call-chain-dataflow.sh:267:  echo "$map" | awk -F'|' -v sym="$symbol" '$1==sym {print $2; exit}'
scripts/call-chain-dataflow.sh:277:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/call-chain-dataflow.sh:279:  [ -z "$rg_cmd" ] && rg_cmd=$(command -v rg 2>/dev/null || true)
scripts/call-chain-dataflow.sh:281:  if [ -n "$rg_cmd" ]; then
scripts/call-chain-dataflow.sh:282:    start_line=$("$rg_cmd" -n "function[[:space:]]+${symbol}\\b" "$file" 2>/dev/null | head -1 | cut -d: -f1)
scripts/call-chain-dataflow.sh:284:    start_line=$(grep -nE "function[[:space:]]+${symbol}\\b" "$file" 2>/dev/null | head -1 | cut -d: -f1)
scripts/call-chain-dataflow.sh:287:  if [ -z "$start_line" ]; then
scripts/call-chain-dataflow.sh:292:  body=$(awk -v start="$start_line" '
scripts/call-chain-dataflow.sh:306:  body=$(echo "$body" | sed -E "/function[[:space:]]+${symbol}[[:space:]]*\\(/d")
scripts/call-chain-dataflow.sh:309:    grep -oE '[A-Za-z_][A-Za-z0-9_]*[[:space:]]*[(]' | \
scripts/call-chain-dataflow.sh:310:    sed -E 's/[[:space:]]*[(]//g' | \
scripts/call-chain-dataflow.sh:311:    grep -vE '^(if|for|while|switch|return|catch|function)$' | \
scripts/call-chain-dataflow.sh:312:    sort -u
scripts/call-chain-dataflow.sh:361:    cached_value=$(echo "$DATA_FLOW_SYMBOL_INDEX" | jq -r --arg s "$symbol" '.[$s] // empty')
scripts/call-chain-dataflow.sh:362:    if [ -n "$cached_value" ]; then
scripts/call-chain-dataflow.sh:370:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/call-chain-dataflow.sh:372:  [ -z "$rg_cmd" ] && rg_cmd=$(command -v rg 2>/dev/null || true)
scripts/call-chain-dataflow.sh:374:  if [ -n "$rg_cmd" ]; then
scripts/call-chain-dataflow.sh:376:    result=$("$rg_cmd" -n --max-count=1 \
scripts/call-chain-dataflow.sh:377:      -g '*.ts' -g '*.tsx' -g '*.js' -g '*.jsx' -g '*.mjs' -g '*.cjs' \
scripts/call-chain-dataflow.sh:379:    if [ -n "$result" ]; then
scripts/call-chain-dataflow.sh:392:    [ -f "$f" ] && files+=("$f")
scripts/call-chain-dataflow.sh:395:  [ "${#files[@]}" -eq 0 ] && return 1
scripts/call-chain-dataflow.sh:398:  result=$(awk -v sym="$symbol" '
scripts/call-chain-dataflow.sh:403:  [ -z "$result" ] && return 1
scripts/call-chain-dataflow.sh:421:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/call-chain-dataflow.sh:423:  [ -z "$rg_cmd" ] && rg_cmd=$(command -v rg 2>/dev/null || true)
scripts/call-chain-dataflow.sh:425:  [ -z "$rg_cmd" ] && return 0
scripts/call-chain-dataflow.sh:428:  while IFS= read -r line; do
scripts/call-chain-dataflow.sh:429:    [ -z "$line" ] && continue
scripts/call-chain-dataflow.sh:435:    name=$(echo "$text" | sed -nE 's/.*function[[:space:]]+([A-Za-z_][A-Za-z0-9_]*)[^A-Za-z0-9_].*/\1/p')
scripts/call-chain-dataflow.sh:436:    [ -z "$name" ] && continue
scripts/call-chain-dataflow.sh:439:    existing=$(echo "$DATA_FLOW_SYMBOL_INDEX" | jq -r --arg s "$name" '.[$s] // empty')
scripts/call-chain-dataflow.sh:440:    if [ -z "$existing" ]; then
scripts/call-chain-dataflow.sh:442:      DATA_FLOW_SYMBOL_INDEX=$(echo "$DATA_FLOW_SYMBOL_INDEX" | jq --arg k "$name" --arg v "${file}|${line_num}" '. + {($k): $v}')
scripts/call-chain-dataflow.sh:444:  done < <("$rg_cmd" -n --pcre2 \
scripts/call-chain-dataflow.sh:445:    -g '*.ts' -g '*.tsx' -g '*.js' -g '*.jsx' -g '*.mjs' -g '*.cjs' \
scripts/call-chain-dataflow.sh:458:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/call-chain-dataflow.sh:460:  [ -z "$rg_cmd" ] && rg_cmd=$(command -v rg 2>/dev/null || true)
scripts/call-chain-dataflow.sh:462:  if [ -n "$rg_cmd" ]; then
scripts/call-chain-dataflow.sh:463:    "$rg_cmd" -n --max-count=1 \
scripts/call-chain-dataflow.sh:464:      -g '*.ts' -g '*.tsx' -g '*.js' -g '*.jsx' -g '*.mjs' -g '*.cjs' \
scripts/call-chain-dataflow.sh:469:  grep -R -n -m 1 -E "${symbol}\\b" "$CWD" >/dev/null 2>&1
scripts/call-chain-dataflow.sh:476:  awk -v sym="$symbol" '
scripts/call-chain-dataflow.sh:519:  [ -z "$calls" ] && return 1
scripts/call-chain-dataflow.sh:526:  while IFS= read -r call; do
scripts/call-chain-dataflow.sh:527:    [ -z "$call" ] && continue
scripts/call-chain-dataflow.sh:528:    [ -z "$first_local" ] && first_local="$call"
scripts/call-chain-dataflow.sh:532:    if [ -n "$import_path" ]; then
scripts/call-chain-dataflow.sh:538:  if [ -n "$first_local" ]; then
scripts/call-chain-dataflow.sh:550:  if [ -z "$current_file" ]; then
scripts/call-chain-dataflow.sh:555:  if [ -z "$import_path" ]; then
scripts/call-chain-dataflow.sh:586:  if [ -n "$source_symbol" ]; then
scripts/call-chain-dataflow.sh:591:  while [ "$depth" -lt "$max_depth" ]; do
scripts/call-chain-dataflow.sh:592:    [ -z "$current_symbol" ] && break
scripts/call-chain-dataflow.sh:601:    if [ -z "$current_file" ]; then
scripts/call-chain-dataflow.sh:606:    [ -f "$full_path" ] || break
scripts/call-chain-dataflow.sh:610:    [ -z "$next_symbol" ] && break
scripts/call-chain-dataflow.sh:613:    if [ "$max_depth" -gt 1 ]; then
scripts/call-chain-dataflow.sh:616:      if [ -n "$next_def" ]; then
scripts/call-chain-dataflow.sh:636:  if [ "$depth" -ge "$max_depth" ]; then
scripts/call-chain-dataflow.sh:638:    if [ -n "$current_file" ]; then
scripts/call-chain-dataflow.sh:641:    if [ -n "$full_path" ] && [ -f "$full_path" ]; then
scripts/call-chain-dataflow.sh:644:      [ -n "$extra_call" ] && truncated=true
scripts/call-chain-dataflow.sh:680:  if [ -n "$DATA_FLOW_FILE" ]; then
scripts/call-chain-dataflow.sh:685:  if [ -n "$source_def" ]; then
scripts/call-chain-dataflow.sh:694:  if [ -z "$path_nodes_json" ] || [ "$path_nodes_json" = "[]" ]; then
scripts/call-chain-dataflow.sh:736:  if [ -z "$file" ] || [ ! -f "$CWD/$file" ]; then
scripts/call-chain-dataflow.sh:743:  content=$(sed -n "${line}p" "$CWD/$file" 2>/dev/null || echo "")
scripts/call-chain-dataflow.sh:768:  if [ -n "$source_file" ] && [ -f "$CWD/$source_file" ]; then
scripts/call-chain-dataflow.sh:777:    while IFS= read -r call; do
scripts/call-chain-dataflow.sh:778:      [ -z "$call" ] && continue
scripts/call-chain-dataflow.sh:784:      if [ -n "$import_path" ]; then
scripts/call-chain-dataflow.sh:795:        --arg symbol "$call" \
scripts/call-chain-dataflow.sh:796:        --arg file "$target_file" \
scripts/call-chain-dataflow.sh:797:        --argjson line 0 \
scripts/call-chain-dataflow.sh:798:        --arg transform "function_call" \
scripts/call-chain-dataflow.sh:799:        --arg type "usage" \
scripts/call-chain-dataflow.sh:806:  if [ "$result_len" -gt 0 ]; then
scripts/call-chain-dataflow.sh:813:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/call-chain-dataflow.sh:815:  [ -z "$rg_cmd" ] && rg_cmd=$(command -v rg 2>/dev/null || true)
scripts/call-chain-dataflow.sh:817:  if [ -n "$rg_cmd" ]; then
scripts/call-chain-dataflow.sh:820:    usages=$("$rg_cmd" -n --max-count=20 -t py -t js -t ts -t go \
scripts/call-chain-dataflow.sh:821:      "\\b${symbol}\\b" "$CWD" 2>/dev/null | head -20)
scripts/call-chain-dataflow.sh:823:    while IFS= read -r usage; do
scripts/call-chain-dataflow.sh:824:      [ -z "$usage" ] && continue
scripts/call-chain-dataflow.sh:827:      file_path=$(echo "$usage" | cut -d: -f1)
scripts/call-chain-dataflow.sh:828:      line=$(echo "$usage" | cut -d: -f2)
scripts/call-chain-dataflow.sh:829:      content=$(echo "$usage" | cut -d: -f3-)
scripts/call-chain-dataflow.sh:856:        --arg symbol "$target_sym" \
scripts/call-chain-dataflow.sh:857:        --arg file "$file_path" \
scripts/call-chain-dataflow.sh:858:        --argjson line "$line" \
scripts/call-chain-dataflow.sh:859:        --arg transform "$transform" \
scripts/call-chain-dataflow.sh:860:        --arg type "usage" \
scripts/call-chain-dataflow.sh:875:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/call-chain-dataflow.sh:877:  [ -z "$rg_cmd" ] && rg_cmd=$(command -v rg 2>/dev/null || true)
scripts/call-chain-dataflow.sh:881:  if [ -n "$rg_cmd" ]; then
scripts/call-chain-dataflow.sh:884:    definitions=$("$rg_cmd" -n --max-count=20 -t py -t js -t ts -t go \
scripts/call-chain-dataflow.sh:885:      "(function|def|class|const|let|var|type|interface)\\s+${symbol}\\b|${symbol}\\s*=" "$CWD" 2>/dev/null | head -20)
scripts/call-chain-dataflow.sh:887:    while IFS= read -r def; do
scripts/call-chain-dataflow.sh:888:      [ -z "$def" ] && continue
scripts/call-chain-dataflow.sh:891:      file_path=$(echo "$def" | cut -d: -f1)
scripts/call-chain-dataflow.sh:892:      line=$(echo "$def" | cut -d: -f2)
scripts/call-chain-dataflow.sh:893:      content=$(echo "$def" | cut -d: -f3-)
scripts/call-chain-dataflow.sh:911:      [ -z "$source_sym" ] && source_sym="$symbol"
scripts/call-chain-dataflow.sh:914:        --arg symbol "$source_sym" \
scripts/call-chain-dataflow.sh:915:        --arg file "$file_path" \
scripts/call-chain-dataflow.sh:916:        --argjson line "$line" \
scripts/call-chain-dataflow.sh:917:        --arg transform "$transform" \
scripts/call-chain-dataflow.sh:918:        --arg type "definition" \
scripts/call-chain-dataflow.sh:951:  source_sym=$(echo "$result" | jq -r '.source.symbol')
scripts/call-chain-dataflow.sh:952:  source_file=$(echo "$result" | jq -r '.source.file')
scripts/call-chain-dataflow.sh:974:      sym=$(echo "$node" | jq -r '.symbol')
scripts/call-chain-dataflow.sh:975:      file=$(echo "$node" | jq -r '.file')
scripts/call-chain-dataflow.sh:976:      transform=$(echo "$node" | jq -r '.transform')
scripts/call-chain-dataflow.sh:980:      echo "    ${prev_node} -->|${transform}| ${node_name}"
scripts/call-chain-dataflow.sh:1001:  source_sym=$(echo "$result" | jq -r '.source.symbol')
scripts/call-chain-dataflow.sh:1002:  source_file=$(echo "$result" | jq -r '.source.file')
scripts/call-chain-dataflow.sh:1003:  direction=$(echo "$result" | jq -r '.direction')
scripts/call-chain-dataflow.sh:1012:  [ "$cycle_detected" = "true" ] && echo "‚ö†Ô∏è Ê£ÄÊµãÂà∞Âæ™ÁéØ‰æùËµñ: $(echo "$result" | jq -r '.cycle_path')"
scripts/call-chain-dataflow.sh:1038:      sym=$(echo "$node" | jq -r '.symbol')
scripts/call-chain-dataflow.sh:1039:      file=$(echo "$node" | jq -r '.file')
scripts/call-chain-dataflow.sh:1041:      transform=$(echo "$node" | jq -r '.transform')
scripts/federation-lite-index.sh:10:[[ -n "${FEDERATION_LITE_INDEX_LOADED:-}" ]] && return 0
scripts/federation-lite-index.sh:28:    indexed_at=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
scripts/federation-lite-index.sh:37:        repo_name=$(echo "$config" | jq -r ".repositories[$i].name")
scripts/federation-lite-index.sh:38:        repo_path=$(echo "$config" | jq -r ".repositories[$i].path")
scripts/federation-lite-index.sh:39:        repo_contracts=$(echo "$config" | jq -r ".repositories[$i].contracts")
scripts/federation-lite-index.sh:43:        if [[ ! -d "$repo_path" ]]; then
scripts/federation-lite-index.sh:53:        while IFS= read -r pattern; do
scripts/federation-lite-index.sh:54:            [[ -z "$pattern" ]] && continue
scripts/federation-lite-index.sh:55:            while IFS= read -r file; do
scripts/federation-lite-index.sh:56:                [[ -z "$file" ]] && continue
scripts/federation-lite-index.sh:57:                [[ ! -f "$file" ]] && continue
scripts/federation-lite-index.sh:68:                rel_path=$(realpath --relative-to="$repo_path" "$file" 2>/dev/null || basename "$file")
scripts/federation-lite-index.sh:71:                    --arg path "$rel_path" \
scripts/federation-lite-index.sh:72:                    --arg type "$contract_type" \
scripts/federation-lite-index.sh:73:                    --argjson symbols "$symbols" \
scripts/federation-lite-index.sh:74:                    --arg hash "$hash" \
scripts/federation-lite-index.sh:78:            done < <(find "$repo_path" -type f \( -name "*.proto" -o -name "openapi.yaml" -o -name "openapi.yml" -o -name "swagger.json" -o -name "*.graphql" -o -name "*.d.ts" \) 2>/dev/null)
scripts/federation-lite-index.sh:79:        done < <(echo "$repo_contracts" | jq -r '.[]' 2>/dev/null)
scripts/federation-lite-index.sh:83:            while IFS= read -r file; do
scripts/federation-lite-index.sh:84:                [[ -z "$file" ]] && continue
scripts/federation-lite-index.sh:85:                [[ ! -f "$file" ]] && continue
scripts/federation-lite-index.sh:96:                rel_path=$(realpath --relative-to="$repo_path" "$file" 2>/dev/null || basename "$file")
scripts/federation-lite-index.sh:99:                    --arg path "$rel_path" \
scripts/federation-lite-index.sh:100:                    --arg type "$contract_type" \
scripts/federation-lite-index.sh:101:                    --argjson symbols "$symbols" \
scripts/federation-lite-index.sh:102:                    --arg hash "$hash" \
scripts/federation-lite-index.sh:106:            done < <(find "$repo_path" -type f \( -name "*.proto" -o -name "openapi.yaml" -o -name "openapi.yml" -o -name "swagger.json" -o -name "*.graphql" -o -name "*.d.ts" \) 2>/dev/null)
scripts/federation-lite-index.sh:110:            --arg name "$repo_name" \
scripts/federation-lite-index.sh:111:            --arg path "$repo_path" \
scripts/federation-lite-index.sh:112:            --argjson contracts "$contracts" \
scripts/federation-lite-index.sh:119:    auto_discover_enabled=$(echo "$config" | jq -r '.auto_discover.enabled // false')
scripts/federation-lite-index.sh:125:        search_paths=$(echo "$config" | jq -r '.auto_discover.search_paths // []')
scripts/federation-lite-index.sh:126:        contract_patterns=$(echo "$config" | jq -r '.auto_discover.contract_patterns // []')
scripts/federation-lite-index.sh:129:        while IFS= read -r search_pattern; do
scripts/federation-lite-index.sh:130:            [[ -z "$search_pattern" ]] && continue
scripts/federation-lite-index.sh:134:                [[ ! -d "$discovered_path" ]] && continue
scripts/federation-lite-index.sh:138:                if find "$discovered_path" -maxdepth 3 -type f \
scripts/federation-lite-index.sh:139:                    \( -name "*.proto" -o -name "openapi.yaml" -o -name "openapi.yml" \
scripts/federation-lite-index.sh:140:                    -o -name "swagger.json" -o -name "*.graphql" -o -name "*.d.ts" \) \
scripts/federation-lite-index.sh:141:                    2>/dev/null | head -1 | grep -q .; then
scripts/federation-lite-index.sh:153:                already_indexed=$(echo "$repositories" | jq --arg name "$discovered_name" \
scripts/federation-lite-index.sh:162:                while IFS= read -r file; do
scripts/federation-lite-index.sh:163:                    [[ -z "$file" ]] && continue
scripts/federation-lite-index.sh:164:                    [[ ! -f "$file" ]] && continue
scripts/federation-lite-index.sh:175:                    rel_path=$(realpath --relative-to="$discovered_path" "$file" 2>/dev/null || basename "$file")
scripts/federation-lite-index.sh:178:                        --arg path "$rel_path" \
scripts/federation-lite-index.sh:179:                        --arg type "$contract_type" \
scripts/federation-lite-index.sh:180:                        --argjson symbols "$symbols" \
scripts/federation-lite-index.sh:181:                        --arg hash "$hash" \
scripts/federation-lite-index.sh:185:                done < <(find "$discovered_path" -type f \
scripts/federation-lite-index.sh:186:                    \( -name "*.proto" -o -name "openapi.yaml" -o -name "openapi.yml" \
scripts/federation-lite-index.sh:187:                    -o -name "swagger.json" -o -name "*.graphql" -o -name "*.d.ts" \) 2>/dev/null)
scripts/federation-lite-index.sh:190:                    --arg name "$discovered_name" \
scripts/federation-lite-index.sh:191:                    --arg path "$discovered_path" \
scripts/federation-lite-index.sh:192:                    --argjson contracts "$contracts" \
scripts/federation-lite-index.sh:195:        done < <(echo "$search_paths" | jq -r '.[]' 2>/dev/null)
scripts/federation-lite-index.sh:200:    index_json=$(jq -n \
scripts/federation-lite-index.sh:201:        --arg schema_version "$SCHEMA_VERSION" \
scripts/federation-lite-index.sh:202:        --arg indexed_at "$indexed_at" \
scripts/federation-lite-index.sh:203:        --argjson repositories "$repositories" \
scripts/federation-lite-index.sh:213:    mkdir -p "$index_dir" 2>/dev/null
scripts/federation-lite-index.sh:236:    if [[ ! -f "$FEDERATION_INDEX" ]]; then
scripts/federation-lite-index.sh:238:            jq -n '{"status": "not_indexed", "message": "Federation index not found"}'
scripts/federation-lite-index.sh:250:    indexed_at=$(echo "$index" | jq -r '.indexed_at')
scripts/federation-lite-index.sh:259:        jq -n \
scripts/federation-lite-index.sh:260:            --arg status "indexed" \
scripts/federation-lite-index.sh:261:            --arg indexed_at "$indexed_at" \
scripts/federation-lite-index.sh:262:            --argjson repositories "$repo_count" \
scripts/federation-lite-index.sh:263:            --argjson contracts "$contract_count" \
scripts/federation-lite-index.sh:264:            --argjson symbols "$symbol_count" \
scripts/federation-lite-index.sh:265:            --arg index_path "$FEDERATION_INDEX" \
scripts/federation-lite-index.sh:290:    if [[ ! -f "$FEDERATION_INDEX" ]]; then
scripts/federation-lite-index.sh:291:        log_error "Federation index not found. Run --update first."
scripts/federation-lite-index.sh:306:        repo_name=$(echo "$index" | jq -r ".repositories[$i].name")
scripts/federation-lite-index.sh:307:        repo_path=$(echo "$index" | jq -r ".repositories[$i].path")
scripts/federation-lite-index.sh:314:            contract_path=$(echo "$index" | jq -r ".repositories[$i].contracts[$j].path")
scripts/federation-lite-index.sh:315:            contract_type=$(echo "$index" | jq -r ".repositories[$i].contracts[$j].type")
scripts/federation-lite-index.sh:322:            while IFS= read -r symbol; do
scripts/federation-lite-index.sh:328:                        --arg repo "$repo_name" \
scripts/federation-lite-index.sh:329:                        --arg repo_path "$repo_path" \
scripts/federation-lite-index.sh:330:                        --arg contract "$contract_path" \
scripts/federation-lite-index.sh:331:                        --arg type "$contract_type" \
scripts/federation-lite-index.sh:332:                        --arg symbol "$symbol" \
scripts/federation-lite-index.sh:335:            done < <(echo "$symbols" | jq -r '.[]' 2>/dev/null)
scripts/federation-lite-index.sh:340:        jq -n \
scripts/federation-lite-index.sh:341:            --arg query "$query" \
scripts/federation-lite-index.sh:342:            --argjson results "$results" \
scripts/federation-lite-index.sh:343:            --argjson count "$(echo "$results" | jq 'length')" \
scripts/federation-lite-index.sh:356:        if [[ "$count" -gt 0 ]]; then
scripts/federation-lite-index.sh:357:            echo "$results" | jq -r '.[] | "  \(.symbol) [\(.type)]"'
scripts/federation-lite-index.sh:358:            echo "$results" | jq -r '.[] | "    -> \(.repository): \(.contract)"'
scripts/federation-lite-index.sh:368:    if [[ ! -f "$FEDERATION_INDEX" ]]; then
scripts/federation-lite-index.sh:369:        log_error "Federation index not found. Run --update first."
scripts/federation-lite-index.sh:376:    if [[ -n "$repo_filter" ]]; then
scripts/federation-lite-index.sh:377:        index=$(echo "$index" | jq --arg name "$repo_filter" '.repositories |= map(select(.name == $name))')
scripts/federation-lite-index.sh:383:        echo "$index" | jq -r '.repositories[] | "Repository: \(.name) (\(.path))\n" + (.contracts[] | "  - \(.path) [\(.type)] (\(.symbols | length) symbols)")'
scripts/indexer.sh:12:set -euo pipefail
scripts/indexer.sh:34:            [[ -n "${DEBOUNCE_SECONDS:-}" ]] && { echo "$DEBOUNCE_SECONDS"; return; } ;;
scripts/indexer.sh:36:            [[ -n "${CI_AST_DELTA_ENABLED:-}" ]] && { echo "$CI_AST_DELTA_ENABLED"; return; } ;;
scripts/indexer.sh:38:            [[ -n "${CI_FILE_THRESHOLD:-}" ]] && { echo "$CI_FILE_THRESHOLD"; return; } ;;
scripts/indexer.sh:42:    if [[ -f "$CONFIG_FILE" ]]; then
scripts/indexer.sh:55:        [[ -n "$value" ]] && { echo "$value"; return; }
scripts/indexer.sh:77:    if [[ -x "$SCRIPT_DIR/ast-delta.sh" ]]; then
scripts/indexer.sh:79:        if "$SCRIPT_DIR/ast-delta.sh" status --format json 2>/dev/null | grep -q '"status"'; then
scripts/indexer.sh:89:    if [[ -f "$stamp_file" ]]; then
scripts/indexer.sh:100:    mkdir -p "$(dirname "$stamp_file")"
scripts/indexer.sh:107:    if [[ -f "$db_path" ]]; then
scripts/indexer.sh:108:        stat -f "%m" "$db_path" 2>/dev/null || stat -c "%Y" "$db_path" 2>/dev/null || echo ""
scripts/indexer.sh:117:    if [[ -d "$cache_dir" ]]; then
scripts/indexer.sh:118:        rm -rf "$cache_dir"/*
scripts/indexer.sh:128:    local -a changed_files=("$@")
scripts/indexer.sh:130:    timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
scripts/indexer.sh:137:    if [[ ${#changed_files[@]} -eq 0 ]]; then
scripts/indexer.sh:165:    if [[ -n "$cache_version" && -n "$db_version" && "$cache_version" != "$db_version" ]]; then
scripts/indexer.sh:174:    if [[ ${#changed_files[@]} -gt $FILE_THRESHOLD ]]; then
scripts/indexer.sh:194:    local -a files=("$@")
scripts/indexer.sh:198:    if [[ ${#files[@]} -gt 0 ]]; then
scripts/indexer.sh:199:        files_json=$(printf '%s\n' "${files[@]}" | jq -R . | jq -s .)
scripts/indexer.sh:202:    jq -n \
scripts/indexer.sh:203:        --arg decision "$decision" \
scripts/indexer.sh:204:        --arg reason "$reason" \
scripts/indexer.sh:205:        --arg timestamp "$timestamp" \
scripts/indexer.sh:206:        --argjson changed_files "$files_json" \
scripts/indexer.sh:219:    local -a files=("$@")
scripts/indexer.sh:223:    if [[ ${#files[@]} -eq 1 ]]; then
scripts/indexer.sh:230:        "$SCRIPT_DIR/ast-delta.sh" batch --files "$files_csv" 2>&1
scripts/indexer.sh:235:    if [[ $exit_code -eq 0 ]]; then
scripts/indexer.sh:257:    if [[ -z "$cmd" ]]; then
scripts/indexer.sh:265:    # ‰ΩøÁî® bash -c ËÄå‰∏çÊòØ evalÔºåÊõ¥ÂÆâÂÖ®
scripts/indexer.sh:266:    if ! (cd "$dir" && bash -c "$cmd" 2>/dev/null); then
scripts/indexer.sh:272:    if ! "$SCRIPT_DIR/scip-to-graph.sh" parse --incremental --format json 2>&1; then
scripts/indexer.sh:316:    if [[ -n "$DEBOUNCE_TIMER_PID" ]] && kill -0 "$DEBOUNCE_TIMER_PID" 2>/dev/null; then
scripts/indexer.sh:328:        if [[ $since_last -ge $DEBOUNCE_SECONDS ]]; then
scripts/indexer.sh:338:    if [[ ${#PENDING_FILES[@]} -eq 0 ]]; then
scripts/indexer.sh:367:    if [[ -f "$dir/tsconfig.json" ]] || [[ -f "$dir/package.json" ]]; then
scripts/indexer.sh:369:    elif [[ -f "$dir/pyproject.toml" ]] || [[ -f "$dir/setup.py" ]] || [[ -f "$dir/requirements.txt" ]]; then
scripts/indexer.sh:371:    elif [[ -f "$dir/go.mod" ]]; then
scripts/indexer.sh:373:    elif [[ -f "$dir/Cargo.toml" ]]; then
scripts/indexer.sh:385:            if command -v scip-typescript &>/dev/null; then
scripts/indexer.sh:386:                echo "scip-typescript index --output index.scip"
scripts/indexer.sh:392:            if command -v scip-python &>/dev/null; then
scripts/indexer.sh:393:                echo "scip-python index . --output index.scip"
scripts/indexer.sh:399:            if command -v scip-go &>/dev/null; then
scripts/indexer.sh:400:                echo "scip-go --output index.scip"
scripts/indexer.sh:419:    if command -v fswatch &>/dev/null; then
scripts/indexer.sh:421:    elif command -v inotifywait &>/dev/null; then
scripts/indexer.sh:437:    fswatch -r -e "$IGNORE_PATTERNS" \
scripts/indexer.sh:438:        --include "\\.($WATCH_EXTENSIONS)$" \
scripts/indexer.sh:439:        "$dir" | while read -r changed_file; do
scripts/indexer.sh:446:        if [[ $since_last -lt $INDEX_INTERVAL ]]; then
scripts/indexer.sh:467:    inotifywait -r -m -e modify,create,delete \
scripts/indexer.sh:468:        --exclude "$IGNORE_PATTERNS" \
scripts/indexer.sh:469:        "$dir" | while read -r path action file; do
scripts/indexer.sh:472:        if ! echo "$file" | grep -qE "\.($WATCH_EXTENSIONS)$"; then
scripts/indexer.sh:480:        if [[ $since_last -lt $INDEX_INTERVAL ]]; then
scripts/indexer.sh:504:        if [[ ! -f "$index_file" ]]; then
scripts/indexer.sh:510:                -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.py" -o -name "*.go" \) \
scripts/indexer.sh:511:                -newer "$index_file" \
scripts/indexer.sh:512:                ! -path "*/node_modules/*" ! -path "*/dist/*" ! -path "*/.git/*" \
scripts/indexer.sh:513:                2>/dev/null | head -20)
scripts/indexer.sh:515:            if [[ -n "$newer_files" ]]; then
scripts/indexer.sh:519:                local -a files_array
scripts/indexer.sh:520:                while IFS= read -r f; do
scripts/indexer.sh:521:                    [[ -n "$f" ]] && files_array+=("$f")
scripts/indexer.sh:550:    config_status=$(jq -n \
scripts/indexer.sh:551:        --arg ast_delta_enabled "$AST_DELTA_ENABLED" \
scripts/indexer.sh:552:        --arg file_threshold "$FILE_THRESHOLD" \
scripts/indexer.sh:553:        --arg debounce_seconds "$DEBOUNCE_SECONDS" \
scripts/indexer.sh:562:    if launchctl list 2>/dev/null | grep -q "com.devbooks.indexer"; then
scripts/indexer.sh:570:    if [[ -n "$cache_version" && "$cache_version" == "$db_version" ]]; then
scripts/indexer.sh:572:    elif [[ -z "$cache_version" && -z "$db_version" ]]; then
scripts/indexer.sh:579:        jq -n \
scripts/indexer.sh:580:            --argjson config "$config_status" \
scripts/indexer.sh:581:            --argjson daemon_running "$daemon_running" \
scripts/indexer.sh:582:            --argjson version_match "$version_match" \
scripts/indexer.sh:583:            --arg cache_version "${cache_version:-null}" \
scripts/indexer.sh:584:            --arg db_version "${db_version:-null}" \
scripts/indexer.sh:615:    if [[ -z "$files_csv" ]]; then
scripts/indexer.sh:616:        log_error "ÈúÄË¶ÅÊåáÂÆöÊñá‰ª∂ÂàóË°®: --dry-run --files <file1,file2,...>"
scripts/indexer.sh:621:    local -a files
scripts/indexer.sh:622:    IFS=',' read -ra files <<< "$files_csv"
scripts/indexer.sh:633:    if [[ -z "$files_csv" ]]; then
scripts/indexer.sh:634:        log_error "ÈúÄË¶ÅÊåáÂÆöÊñá‰ª∂ÂàóË°®: --once --files <file1,file2,...>"
scripts/indexer.sh:639:    local -a files
scripts/indexer.sh:640:    IFS=',' read -ra files <<< "$files_csv"
scripts/indexer.sh:666:    if [[ ! -d "$project_dir" ]]; then
scripts/indexer.sh:680:    if [[ ! -f "$project_dir/index.scip" ]]; then
scripts/indexer.sh:712:  indexer.sh --status [--format json]        Ê£ÄÊü•Áä∂ÊÄÅ
scripts/indexer.sh:713:  indexer.sh --dry-run --files <files>       Ê®°ÊãüË∞ÉÂ∫¶ÂÜ≥Á≠ñÔºà‰∏çÊâßË°åÔºâ
scripts/indexer.sh:714:  indexer.sh --once --files <files>          ‰∏ÄÊ¨°ÊÄßÊâßË°åÁ¥¢Âºï
scripts/indexer.sh:715:  indexer.sh --install [È°πÁõÆÁõÆÂΩï]            ÂÆâË£Ö‰∏∫ LaunchAgent (macOS)
scripts/indexer.sh:716:  indexer.sh --uninstall                     Âç∏ËΩΩ LaunchAgent
scripts/indexer.sh:717:  indexer.sh --help                          ÊòæÁ§∫Â∏ÆÂä©
scripts/indexer.sh:784:while [[ $# -gt 0 ]]; do
scripts/indexer.sh:786:        --help|-h)
scripts/indexer.sh:790:        --status)
scripts/indexer.sh:792:            # Ê£ÄÊü•ÊòØÂê¶Êúâ --format ÂèÇÊï∞
scripts/indexer.sh:800:        --dry-run)
scripts/indexer.sh:809:        --once)
scripts/indexer.sh:818:        --files)
scripts/indexer.sh:822:        --format)
scripts/indexer.sh:826:        --install)
scripts/indexer.sh:830:        --uninstall)
scripts/indexer.sh:832:            rm -f "$HOME/Library/LaunchAgents/com.devbooks.indexer.plist"
scripts/scip-to-graph.sh:14:set -euo pipefail
scripts/scip-to-graph.sh:54:    if [[ -f "$proto_file" ]]; then
scripts/scip-to-graph.sh:55:        grep -E "^//[[:space:]]*Version:" "$proto_file" 2>/dev/null | head -1 | sed 's/.*Version:[[:space:]]*//' | tr -d '[:space:]' || echo "unknown"
scripts/scip-to-graph.sh:67:    if [[ ! -f "$config_file" ]]; then
scripts/scip-to-graph.sh:74:    value=$(awk -v key="$config_key" '
scripts/scip-to-graph.sh:87:    if [[ -n "$value" ]]; then
scripts/scip-to-graph.sh:108:    if [[ -n "${SCIP_PROTO_PATH:-}" && -f "${SCIP_PROTO_PATH}" ]]; then
scripts/scip-to-graph.sh:118:    if [[ -z "${VENDORED_PROTO_PATH+x}" ]]; then
scripts/scip-to-graph.sh:121:        if [[ -f "$vendored_path" ]]; then
scripts/scip-to-graph.sh:128:    elif [[ -n "$VENDORED_PROTO_PATH" && -f "$VENDORED_PROTO_PATH" ]]; then
scripts/scip-to-graph.sh:140:    if [[ -f "$cached_path" ]]; then
scripts/scip-to-graph.sh:151:        if command -v curl &>/dev/null; then
scripts/scip-to-graph.sh:152:            if curl -s --connect-timeout 10 "$SCIP_PROTO_URL" -o "$cached_path" 2>/dev/null; then
scripts/scip-to-graph.sh:159:        elif command -v wget &>/dev/null; then
scripts/scip-to-graph.sh:160:            if wget -q --timeout=10 "$SCIP_PROTO_URL" -O "$cached_path" 2>/dev/null; then
scripts/scip-to-graph.sh:178:    log_info "Suggestion: Run 'scripts/vendor-proto.sh --upgrade' to download and vendor the proto file."
scripts/scip-to-graph.sh:193:    if [[ ! -f "$db_path" ]]; then
scripts/scip-to-graph.sh:197:    if [[ ! -f "$scip_path" ]]; then
scripts/scip-to-graph.sh:202:    if [[ "$scip_path" -nt "$db_path" ]]; then
scripts/scip-to-graph.sh:267:    mkdir -p "$(dirname "$node_script")"
scripts/scip-to-graph.sh:443:        rm -f "$node_script"
scripts/scip-to-graph.sh:447:        rm -f "$node_script"
scripts/scip-to-graph.sh:473:    files=$(find "$project_root" -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \) \
scripts/scip-to-graph.sh:474:        -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)
scripts/scip-to-graph.sh:484:        if command -v rg &>/dev/null; then
scripts/scip-to-graph.sh:485:            while IFS=: read -r line_num match; do
scripts/scip-to-graph.sh:487:                func_name=$(echo "$match" | sed -E 's/.*function[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/' | head -1)
scripts/scip-to-graph.sh:488:                if [[ -n "$func_name" && "$func_name" != "$match" ]]; then
scripts/scip-to-graph.sh:496:                    if echo "$match" | grep -qE '\):\s*[a-zA-Z_]'; then
scripts/scip-to-graph.sh:498:                        return_type=$(echo "$match" | grep -oE '\):\s*[a-zA-Z_][a-zA-Z0-9_<>]*' | sed 's/)://; s/^[[:space:]]*//' | head -1)
scripts/scip-to-graph.sh:499:                        if [[ -n "$return_type" && "$return_type" != "function" ]]; then
scripts/scip-to-graph.sh:506:            done < <(rg -n "function[[:space:]]+[a-zA-Z_]" "$file" 2>/dev/null || true)
scripts/scip-to-graph.sh:509:            while IFS=: read -r line_num match; do
scripts/scip-to-graph.sh:511:                import_from=$(echo "$match" | sed -E "s/.*from[[:space:]]+['\"]([^'\"]+)['\"].*/\1/" | head -1)
scripts/scip-to-graph.sh:512:                if [[ -n "$import_from" && "$import_from" != "$match" ]]; then
scripts/scip-to-graph.sh:517:            done < <(rg -n "import.*from" "$file" 2>/dev/null || true)
scripts/scip-to-graph.sh:520:            while IFS=: read -r line_num match; do
scripts/scip-to-graph.sh:522:                class_name=$(echo "$match" | sed -E 's/.*class[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/' | head -1)
scripts/scip-to-graph.sh:523:                interface_name=$(echo "$match" | sed -E 's/.*implements[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/' | head -1)
scripts/scip-to-graph.sh:524:                if [[ -n "$class_name" && -n "$interface_name" && "$class_name" != "$match" && "$interface_name" != "$match" ]]; then
scripts/scip-to-graph.sh:530:            done < <(rg -n "class[[:space:]]+[a-zA-Z_].*implements" "$file" 2>/dev/null || true)
scripts/scip-to-graph.sh:533:            while IFS=: read -r line_num match; do
scripts/scip-to-graph.sh:535:                class_name=$(echo "$match" | sed -E 's/.*class[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/' | head -1)
scripts/scip-to-graph.sh:536:                parent_name=$(echo "$match" | sed -E 's/.*extends[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/' | head -1)
scripts/scip-to-graph.sh:537:                if [[ -n "$class_name" && -n "$parent_name" && "$class_name" != "$match" && "$parent_name" != "$match" ]]; then
scripts/scip-to-graph.sh:543:            done < <(rg -n "class[[:space:]]+[a-zA-Z_].*extends" "$file" 2>/dev/null || true)
scripts/scip-to-graph.sh:546:            while IFS=: read -r line_num match; do
scripts/scip-to-graph.sh:548:                func_name=$(echo "$match" | sed -E 's/.*function[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/' | head -1)
scripts/scip-to-graph.sh:549:                if [[ -n "$func_name" && "$func_name" != "$match" ]]; then
scripts/scip-to-graph.sh:557:                    if echo "$match" | grep -qE '\):\s*[a-zA-Z_]'; then
scripts/scip-to-graph.sh:559:                        return_type=$(echo "$match" | grep -oE '\):\s*[a-zA-Z_][a-zA-Z0-9_<>]*' | sed 's/)://; s/^[[:space:]]*//' | head -1)
scripts/scip-to-graph.sh:560:                        if [[ -n "$return_type" && "$return_type" != "function" ]]; then
scripts/scip-to-graph.sh:567:            done < <(grep -n "function[[:space:]]*[a-zA-Z_]" "$file" 2>/dev/null || true)
scripts/scip-to-graph.sh:570:            while IFS=: read -r line_num match; do
scripts/scip-to-graph.sh:572:                import_from=$(echo "$match" | sed -E "s/.*from[[:space:]]+['\"]([^'\"]+)['\"].*/\1/" | head -1)
scripts/scip-to-graph.sh:573:                if [[ -n "$import_from" && "$import_from" != "$match" ]]; then
scripts/scip-to-graph.sh:578:            done < <(grep -n "import.*from" "$file" 2>/dev/null || true)
scripts/scip-to-graph.sh:581:            while IFS=: read -r line_num match; do
scripts/scip-to-graph.sh:583:                class_name=$(echo "$match" | sed -E 's/.*class[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/' | head -1)
scripts/scip-to-graph.sh:584:                interface_name=$(echo "$match" | sed -E 's/.*implements[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/' | head -1)
scripts/scip-to-graph.sh:585:                if [[ -n "$class_name" && -n "$interface_name" && "$class_name" != "$match" && "$interface_name" != "$match" ]]; then
scripts/scip-to-graph.sh:591:            done < <(grep -n "class[[:space:]]*[a-zA-Z_].*implements" "$file" 2>/dev/null || true)
scripts/scip-to-graph.sh:594:            while IFS=: read -r line_num match; do
scripts/scip-to-graph.sh:596:                class_name=$(echo "$match" | sed -E 's/.*class[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/' | head -1)
scripts/scip-to-graph.sh:597:                parent_name=$(echo "$match" | sed -E 's/.*extends[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/' | head -1)
scripts/scip-to-graph.sh:598:                if [[ -n "$class_name" && -n "$parent_name" && "$class_name" != "$match" && "$parent_name" != "$match" ]]; then
scripts/scip-to-graph.sh:604:            done < <(grep -n "class[[:space:]]*[a-zA-Z_].*extends" "$file" 2>/dev/null || true)
scripts/scip-to-graph.sh:612:    if [[ ${#nodes[@]} -gt 0 ]]; then
scripts/scip-to-graph.sh:613:        nodes_json=$(printf '%s\n' "${nodes[@]}" | paste -sd ',' -)
scripts/scip-to-graph.sh:618:    if [[ ${#edges[@]} -gt 0 ]]; then
scripts/scip-to-graph.sh:619:        edges_json=$(printf '%s\n' "${edges[@]}" | paste -sd ',' -)
scripts/scip-to-graph.sh:651:    while [[ $# -gt 0 ]]; do
scripts/scip-to-graph.sh:653:            --incremental) incremental=true; shift ;;
scripts/scip-to-graph.sh:654:            --force) force=true; shift ;;
scripts/scip-to-graph.sh:655:            --format) format="$2"; shift 2 ;;
scripts/scip-to-graph.sh:656:            --project-root) project_root="$2"; shift 2 ;;
scripts/scip-to-graph.sh:665:    if [[ ! -f "$SCIP_INDEX_PATH" ]]; then
scripts/scip-to-graph.sh:672:    mkdir -p "$(dirname "$GRAPH_DB_PATH")"
scripts/scip-to-graph.sh:706:        if echo "$parse_result" | jq -e '.success == true' >/dev/null 2>&1; then
scripts/scip-to-graph.sh:724:        rm -f "$temp_json"
scripts/scip-to-graph.sh:730:    import_result=$("$SCRIPT_DIR/graph-store.sh" batch-import --file "$temp_json" 2>&1)
scripts/scip-to-graph.sh:738:    rm -f "$temp_json"
scripts/scip-to-graph.sh:743:        symbols=$(echo "$parse_result" | jq -r '.symbols // 0' 2>/dev/null || echo "0")
scripts/scip-to-graph.sh:757:    if [[ ! -f "$scip_path" ]]; then
scripts/scip-to-graph.sh:768:        rm -f "$temp_json"
scripts/scip-to-graph.sh:770:        rm -f "$temp_json"
scripts/scip-to-graph.sh:796:    while [[ $# -gt 0 ]]; do
scripts/scip-to-graph.sh:798:            --format) format="$2"; shift 2 ;;
scripts/scip-to-graph.sh:806:            jq -n \
scripts/scip-to-graph.sh:807:                --arg path "$RESOLVED_PROTO_PATH" \
scripts/scip-to-graph.sh:808:                --arg source "$RESOLVED_PROTO_SOURCE" \
scripts/scip-to-graph.sh:809:                --arg version "$RESOLVED_PROTO_VERSION" \
scripts/scip-to-graph.sh:827:            jq -n \
scripts/scip-to-graph.sh:828:                --arg source "$RESOLVED_PROTO_SOURCE" \
scripts/scip-to-graph.sh:858:    --incremental       Â¢ûÈáèÊõ¥Êñ∞Ôºà‰ªÖÂΩì SCIP ÊØîÊï∞ÊçÆÂ∫ìÊñ∞Êó∂Ëß£ÊûêÔºâ
scripts/scip-to-graph.sh:859:    --force             Âº∫Âà∂ÂÆåÂÖ®ÈáçÂª∫
scripts/scip-to-graph.sh:860:    --format <fmt>      ËæìÂá∫Ê†ºÂºè: text, json
scripts/scip-to-graph.sh:861:    --project-root <p>  È°πÁõÆÊ†πÁõÆÂΩïÔºàÁî®‰∫éÊ≠£ÂàôÈôçÁ∫ßÔºâ
scripts/scip-to-graph.sh:864:    --format <fmt>      ËæìÂá∫Ê†ºÂºè: text, json
scripts/scip-to-graph.sh:889:    scip-to-graph.sh parse --incremental
scripts/scip-to-graph.sh:892:    scip-to-graph.sh parse --force --format json
scripts/scip-to-graph.sh:895:    scip-to-graph.sh check-proto --format json
scripts/scip-to-graph.sh:902:    # Ê£ÄÊü•ÊòØÂê¶‰ΩøÁî®Êñ∞ÁöÑÂèÇÊï∞Ê†ºÂºèÔºà--input, --output, --fallback-regex, --check-protoÔºâ
scripts/scip-to-graph.sh:903:    if [[ "$1" == --* ]]; then
scripts/scip-to-graph.sh:911:        while [[ $# -gt 0 ]]; do
scripts/scip-to-graph.sh:913:                --input)
scripts/scip-to-graph.sh:917:                --output)
scripts/scip-to-graph.sh:921:                --fallback-regex)
scripts/scip-to-graph.sh:925:                --check-proto)
scripts/scip-to-graph.sh:929:                --format)
scripts/scip-to-graph.sh:933:                --help|-h)
scripts/scip-to-graph.sh:946:            cmd_check_proto --format "$format"
scripts/scip-to-graph.sh:951:        if [[ -z "$input_file" || -z "$output_db" ]]; then
scripts/scip-to-graph.sh:952:            log_error "Missing required parameters: --input and --output"
scripts/scip-to-graph.sh:973:            bash "$SCRIPT_DIR/graph-store.sh" batch-import --file "$temp_json" >/dev/null 2>&1
scripts/scip-to-graph.sh:974:            rm -f "$temp_json"
scripts/scip-to-graph.sh:977:            rm -f "$temp_json"
scripts/show-context.sh:5:set -euo pipefail
scripts/show-context.sh:17:echo -e "${BLUE}=== DevBooks Ëá™Âä®‰∏ä‰∏ãÊñá ===${NC}\n"
scripts/show-context.sh:20:echo -e "${GREEN}üìä Á¥¢ÂºïÁä∂ÊÄÅÔºö${NC}"
scripts/show-context.sh:22:if [ -f "$EMBEDDING_INDEX" ] && [ -s "$EMBEDDING_INDEX" ]; then
scripts/show-context.sh:23:  FILE_COUNT=$(wc -l < "$EMBEDDING_INDEX" | tr -d ' ')
scripts/show-context.sh:25:elif [ -f "$PROJECT_ROOT/index.scip" ]; then
scripts/show-context.sh:27:elif [ -d "$PROJECT_ROOT/.git/ckb" ]; then
scripts/show-context.sh:34:echo -e "\n${RED}üî• ÁÉ≠ÁÇπÊñá‰ª∂Ôºö${NC}"
scripts/show-context.sh:35:if [ -d "$PROJECT_ROOT/.git" ]; then
scripts/show-context.sh:36:  git -C "$PROJECT_ROOT" log --since="30 days ago" --name-only --pretty=format: 2>/dev/null | \
scripts/show-context.sh:37:    grep -v '^$' | \
scripts/show-context.sh:38:    grep -vE 'node_modules|dist|build|\.lock|\.md$|__pycache__|\.pyc$' | \
scripts/show-context.sh:39:    sort | uniq -c | sort -rn | head -5 | \
scripts/show-context.sh:40:    while read -r count file; do
scripts/show-context.sh:48:echo -e "\n${YELLOW}üí° ÂèØÁî®Â∑•ÂÖ∑Ôºö${NC}"
scripts/show-context.sh:57:echo -e "\n${BLUE}üì¶ È°πÁõÆ‰ø°ÊÅØÔºö${NC}"
scripts/show-context.sh:58:if [ -f "$PROJECT_ROOT/package.json" ]; then
scripts/show-context.sh:59:  PROJECT_NAME=$(jq -r '.name // "Êú™ÂëΩÂêç"' "$PROJECT_ROOT/package.json" 2>/dev/null)
scripts/show-context.sh:61:  if [ -f "$PROJECT_ROOT/tsconfig.json" ]; then
scripts/show-context.sh:69:if [ -d "$PROJECT_ROOT/.git" ]; then
scripts/show-context.sh:70:  echo -e "\n${BLUE}üìù ÊúÄËøëÊèê‰∫§Ôºö${NC}"
scripts/show-context.sh:71:  git -C "$PROJECT_ROOT" log --oneline -3 2>/dev/null | \
scripts/show-context.sh:72:    while read -r line; do
scripts/show-context.sh:77:echo -e "\n${YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${NC}"
scripts/show-context.sh:78:echo -e "${YELLOW}üí° ËøôÊòØ AI Âú®ÊØèÊ¨°ÂØπËØùÊó∂Ëá™Âä®ÁúãÂà∞ÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØ${NC}"
scripts/show-context.sh:79:echo -e "${YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${NC}"
scripts/federation-lite-discovery.sh:10:[[ -n "${FEDERATION_LITE_DISCOVERY_LOADED:-}" ]] && return 0
scripts/federation-lite-discovery.sh:56:    while IFS= read -r line; do
scripts/federation-lite-discovery.sh:59:            symbols=$(echo "$symbols" | jq --arg s "${BASH_REMATCH[2]}" '. + [$s]')
scripts/federation-lite-discovery.sh:63:            symbols=$(echo "$symbols" | jq --arg s "${BASH_REMATCH[2]}" '. + [$s]')
scripts/federation-lite-discovery.sh:67:            symbols=$(echo "$symbols" | jq --arg s "${BASH_REMATCH[2]}" '. + [$s]')
scripts/federation-lite-discovery.sh:71:            symbols=$(echo "$symbols" | jq --arg s "${BASH_REMATCH[2]}" '. + [$s]')
scripts/federation-lite-discovery.sh:88:        paths=$(jq -r '.paths | keys[]' "$file" 2>/dev/null || echo "")
scripts/federation-lite-discovery.sh:92:            methods=$(jq -r ".paths[\"$path\"] | keys[]" "$file" 2>/dev/null || echo "")
scripts/federation-lite-discovery.sh:95:                symbols=$(echo "$symbols" | jq --arg s "$method_upper $path" '. + [$s]')
scripts/federation-lite-discovery.sh:101:        schemas=$(jq -r '.components.schemas | keys[]' "$file" 2>/dev/null || echo "")
scripts/federation-lite-discovery.sh:103:            symbols=$(echo "$symbols" | jq --arg s "$schema" '. + [$s]')
scripts/federation-lite-discovery.sh:111:        while IFS= read -r line; do
scripts/federation-lite-discovery.sh:128:            if [[ "$in_paths" == "true" && -n "$current_path" && "$line" =~ ^[[:space:]]+(get|post|put|delete|patch):[[:space:]]*$ ]]; then
scripts/federation-lite-discovery.sh:131:                symbols=$(echo "$symbols" | jq --arg s "$method $current_path" '. + [$s]')
scripts/federation-lite-discovery.sh:135:                symbols=$(echo "$symbols" | jq --arg s "${BASH_REMATCH[1]}" '. + [$s]')
scripts/federation-lite-discovery.sh:149:    while IFS= read -r line; do
scripts/federation-lite-discovery.sh:152:            symbols=$(echo "$symbols" | jq --arg s "${BASH_REMATCH[2]}" '. + [$s]')
scripts/federation-lite-discovery.sh:156:            symbols=$(echo "$symbols" | jq --arg s "${BASH_REMATCH[2]}" '. + [$s]')
scripts/federation-lite-discovery.sh:169:    while IFS= read -r line; do
scripts/federation-lite-discovery.sh:172:            symbols=$(echo "$symbols" | jq --arg s "${BASH_REMATCH[3]}" '. + [$s]')
scripts/federation-lite-discovery.sh:209:    while IFS= read -r file; do
scripts/federation-lite-discovery.sh:210:        [[ -z "$file" ]] && continue
scripts/federation-lite-discovery.sh:211:        [[ ! -f "$file" ]] && continue
scripts/federation-lite-discovery.sh:214:        rel_path=$(realpath --relative-to="$repo_path" "$file" 2>/dev/null || basename "$file")
scripts/federation-lite-discovery.sh:217:        while IFS= read -r line; do
scripts/federation-lite-discovery.sh:225:                    --arg name "$func_name" \
scripts/federation-lite-discovery.sh:226:                    --arg file "$rel_path" \
scripts/federation-lite-discovery.sh:227:                    --arg type "function" \
scripts/federation-lite-discovery.sh:235:                    --arg name "$func_name" \
scripts/federation-lite-discovery.sh:236:                    --arg file "$rel_path" \
scripts/federation-lite-discovery.sh:237:                    --arg type "function" \
scripts/federation-lite-discovery.sh:241:    done < <(find "$repo_path" -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \) \
scripts/federation-lite-discovery.sh:242:        -not -path "*/node_modules/*" -not -path "*/.git/*" 2>/dev/null)
scripts/vuln-tracker.sh:15:set -euo pipefail
scripts/vuln-tracker.sh:43:    npm_version=$(npm --version 2>/dev/null || echo "0.0.0")
scripts/vuln-tracker.sh:45:    major_version=$(echo "$npm_version" | cut -d. -f1)
scripts/vuln-tracker.sh:47:    if [[ $major_version -ge 7 ]]; then
scripts/vuln-tracker.sh:66:    # Êú™Áü•‰∏•ÈáçÊÄßÔºåËøîÂõû -1
scripts/vuln-tracker.sh:80:    if [[ "$sev_index" -ge "$thr_index" ]]; then
scripts/vuln-tracker.sh:100:    date -u +"%Y-%m-%dT%H:%M:%SZ"
scripts/vuln-tracker.sh:116:    echo "$json" | jq --arg threshold "$threshold" --arg include_dev "$include_dev" '
scripts/vuln-tracker.sh:123:            severity_order[s] // -1;
scripts/vuln-tracker.sh:169:    echo "$json" | jq --arg threshold "$threshold" --arg include_dev "$include_dev" '
scripts/vuln-tracker.sh:176:            severity_order[s] // -1;
scripts/vuln-tracker.sh:229:    jq -n \
scripts/vuln-tracker.sh:230:        --arg scan_time "$scan_time" \
scripts/vuln-tracker.sh:231:        --argjson total "$total" \
scripts/vuln-tracker.sh:232:        --argjson by_severity "$by_severity" \
scripts/vuln-tracker.sh:233:        --argjson vulnerabilities "$vulnerabilities" \
scripts/vuln-tracker.sh:258:    if [[ "$total" -eq 0 ]]; then
scripts/vuln-tracker.sh:268:    echo "$vulnerabilities" | jq -r '.[] | [
scripts/vuln-tracker.sh:273:    ] | @tsv' | while IFS=$'\t' read -r name severity via fixable; do
scripts/vuln-tracker.sh:288:    while [[ $# -gt 0 ]]; do
scripts/vuln-tracker.sh:290:            --format) format="$2"; shift 2 ;;
scripts/vuln-tracker.sh:291:            --severity) severity="$2"; shift 2 ;;
scripts/vuln-tracker.sh:292:            --include-dev) include_dev="true"; shift ;;
scripts/vuln-tracker.sh:293:            --dir) dir="$2"; shift 2 ;;
scripts/vuln-tracker.sh:299:    if [[ ! -d "$dir" ]]; then
scripts/vuln-tracker.sh:310:    if [[ ! -f "$dir/package.json" ]]; then
scripts/vuln-tracker.sh:342:    audit_json=$(npm audit --json 2>/dev/null || true)
scripts/vuln-tracker.sh:346:    if [[ -z "$audit_json" ]]; then
scripts/vuln-tracker.sh:365:    if [[ -z "$vulnerabilities" || "$vulnerabilities" == "null" ]]; then
scripts/vuln-tracker.sh:394:    while [[ $# -gt 0 ]]; do
scripts/vuln-tracker.sh:396:            --input) input="$2"; shift 2 ;;
scripts/vuln-tracker.sh:397:            --format)
scripts/vuln-tracker.sh:405:            --severity) severity="$2"; shift 2 ;;
scripts/vuln-tracker.sh:406:            --include-dev) include_dev="true"; shift ;;
scripts/vuln-tracker.sh:412:    if [[ -z "$input" ]]; then
scripts/vuln-tracker.sh:413:        log_error "ËØ∑ÊåáÂÆöËæìÂÖ•Êñá‰ª∂: --input <file>"
scripts/vuln-tracker.sh:417:    if [[ ! -f "$input" ]]; then
scripts/vuln-tracker.sh:433:    if echo "$audit_json" | jq -e '.vulnerabilities' > /dev/null 2>&1; then
scripts/vuln-tracker.sh:435:    elif echo "$audit_json" | jq -e '.advisories' > /dev/null 2>&1; then
scripts/vuln-tracker.sh:448:    if [[ -z "$vulnerabilities" || "$vulnerabilities" == "null" ]]; then
scripts/vuln-tracker.sh:466:            if [[ "$total" -eq 0 ]]; then
scripts/vuln-tracker.sh:469:                echo "$vulnerabilities" | jq -r '.[] | "\(.name): \(.severity)"'
scripts/vuln-tracker.sh:483:    if [[ $# -gt 0 && ! "$1" =~ ^-- ]]; then
scripts/vuln-tracker.sh:488:    while [[ $# -gt 0 ]]; do
scripts/vuln-tracker.sh:490:            --dir) dir="$2"; shift 2 ;;
scripts/vuln-tracker.sh:495:    if [[ -z "$package_name" ]]; then
scripts/vuln-tracker.sh:501:    if [[ ! -d "$dir" ]]; then
scripts/vuln-tracker.sh:508:    if [[ ! -f "$dir/package.json" ]]; then
scripts/vuln-tracker.sh:519:    dep_tree=$(npm ls "$package_name" --json 2>/dev/null || echo "{}")
scripts/vuln-tracker.sh:524:    if [[ -d "$dir/src" ]]; then
scripts/vuln-tracker.sh:525:        while IFS= read -r file; do
scripts/vuln-tracker.sh:527:        done < <(grep -rl "require.*['\"]${package_name}['\"]" "$dir/src" 2>/dev/null || true)
scripts/vuln-tracker.sh:528:        while IFS= read -r file; do
scripts/vuln-tracker.sh:530:        done < <(grep -rl "from ['\"]${package_name}['\"]" "$dir/src" 2>/dev/null || true)
scripts/vuln-tracker.sh:536:    if echo "$dep_tree" | jq -e '.dependencies' > /dev/null 2>&1; then
scripts/vuln-tracker.sh:538:        dep_name=$(echo "$dep_tree" | jq -r '.name // "project"')
scripts/vuln-tracker.sh:542:        if echo "$dep_tree" | jq -e ".dependencies[\"$package_name\"]" > /dev/null 2>&1; then
scripts/vuln-tracker.sh:547:            indirect=$(echo "$dep_tree" | jq -r ".. | objects | select(.dependencies[\"$package_name\"]?) | .name // empty" 2>/dev/null | head -1)
scripts/vuln-tracker.sh:548:            if [[ -n "$indirect" ]]; then
scripts/vuln-tracker.sh:560:    if [[ ${#chain[@]} -gt 0 ]]; then
scripts/vuln-tracker.sh:561:        chain_json=$(printf '%s\n' "${chain[@]}" | jq -R . | jq -s .)
scripts/vuln-tracker.sh:566:    if [[ ${#using_files[@]} -gt 0 ]]; then
scripts/vuln-tracker.sh:567:        files_json=$(printf '%s\n' "${using_files[@]}" | jq -R . | jq -s .)
scripts/vuln-tracker.sh:572:    jq -n \
scripts/vuln-tracker.sh:573:        --arg package "$package_name" \
scripts/vuln-tracker.sh:574:        --argjson chain "$chain_json" \
scripts/vuln-tracker.sh:575:        --argjson files "$files_json" \
scripts/vuln-tracker.sh:598:    --format <fmt>      ËæìÂá∫Ê†ºÂºè: json (ÈªòËÆ§), md
scripts/vuln-tracker.sh:599:    --severity <level>  ÊúÄ‰Ωé‰∏•ÈáçÊÄß: low, moderate (ÈªòËÆ§), high, critical
scripts/vuln-tracker.sh:600:    --include-dev       ÂåÖÂê´ÂºÄÂèë‰æùËµñ
scripts/vuln-tracker.sh:601:    --dir <path>        È°πÁõÆÁõÆÂΩïÔºàÈªòËÆ§ÂΩìÂâçÁõÆÂΩïÔºâ
scripts/vuln-tracker.sh:604:    --input <file>      ËæìÂÖ•ÁöÑ npm audit JSON Êñá‰ª∂ÔºàÂøÖÈúÄÔºâ
scripts/vuln-tracker.sh:605:    --format <fmt>      ËæìÂá∫Ê†ºÂºè: json (ÈªòËÆ§), md, npm6, npm7
scripts/vuln-tracker.sh:606:    --severity <level>  ÊúÄ‰Ωé‰∏•ÈáçÊÄßÈòàÂÄº
scripts/vuln-tracker.sh:607:    --include-dev       ÂåÖÂê´ÂºÄÂèë‰æùËµñ
scripts/vuln-tracker.sh:611:    --dir <path>        È°πÁõÆÁõÆÂΩïÔºàÈªòËÆ§ÂΩìÂâçÁõÆÂΩïÔºâ
scripts/vuln-tracker.sh:629:    vuln-tracker.sh scan --severity high --format md
scripts/vuln-tracker.sh:632:    vuln-tracker.sh scan --include-dev
scripts/vuln-tracker.sh:635:    vuln-tracker.sh parse --input audit.json --format json
scripts/vuln-tracker.sh:641:    vuln-tracker.sh scan --dir /path/to/project
scripts/daemon.sh:15:set -euo pipefail
scripts/daemon.sh:43:    if command -v perl &>/dev/null; then
scripts/daemon.sh:44:        perl -MTime::HiRes -e 'printf "%d\n", Time::HiRes::time() * 1000' 2>/dev/null
scripts/daemon.sh:45:    elif command -v gdate &>/dev/null; then
scripts/daemon.sh:52:_ensure_dir() { mkdir -p "$DEVBOOKS_DIR"; }
scripts/daemon.sh:56:    [ -n "$pid" ] && kill -0 "$pid" 2>/dev/null
scripts/daemon.sh:78:    date -u +"%Y-%m-%dT%H:%M:%SZ" 2>/dev/null || date +"%Y-%m-%dT%H:%M:%SZ"
scripts/daemon.sh:91:    mkdir -p "$DAEMON_CANCEL_DIR"
scripts/daemon.sh:110:    if [[ ! -f "$cancel_file" ]]; then
scripts/daemon.sh:116:        if command -v flock &>/dev/null; then
scripts/daemon.sh:117:            flock -x 200 2>/dev/null || true
scripts/daemon.sh:128:    if [[ ! -f "$cancel_file" ]]; then
scripts/daemon.sh:141:    rm -f "$cancel_file" 2>/dev/null || true
scripts/daemon.sh:146:    rm -rf "$DAEMON_CANCEL_DIR" 2>/dev/null || true
scripts/daemon.sh:161:    rm -f "$DEVBOOKS_DIR/daemon.active_request" 2>/dev/null || true
scripts/daemon.sh:166:    rm -f "$DAEMON_SOCK"
scripts/daemon.sh:168:    python3 -c "
scripts/daemon.sh:178:        if command -v socat &>/dev/null; then
scripts/daemon.sh:181:            pkill -f "socat.*$DAEMON_SOCK" 2>/dev/null || true
scripts/daemon.sh:185:    [ ! -e "$DAEMON_SOCK" ] && touch "$DAEMON_SOCK"
scripts/daemon.sh:196:    if [ "${DAEMON_MOCK_DELAY_MS:-0}" -gt 0 ]; then
scripts/daemon.sh:200:        while [ $i -lt $delay_iterations ]; do
scripts/daemon.sh:202:            if [[ -n "$request_id" ]] && _is_request_cancelled "$request_id"; then
scripts/daemon.sh:212:    local action=$(echo "$req" | jq -r '.action // "ping"' 2>/dev/null || echo "ping")
scripts/daemon.sh:213:    local payload=$(echo "$req" | jq -r '.payload // ""' 2>/dev/null || echo "")
scripts/daemon.sh:216:    if [[ -n "$request_id" ]] && _is_request_cancelled "$request_id"; then
scripts/daemon.sh:228:            if [ -x "$SCRIPT_DIR/graph-store.sh" ] && [ -f "$GRAPH_DB_PATH" ]; then
scripts/daemon.sh:241:    if [[ -n "$request_id" ]] && _is_request_cancelled "$request_id"; then
scripts/daemon.sh:267:    rm -f "$request_file" "$response_file"
scripts/daemon.sh:272:        [ -f "$stop_flag" ] && break
scripts/daemon.sh:275:        if [ -f "$request_file" ]; then
scripts/daemon.sh:278:            rm -f "$request_file"
scripts/daemon.sh:280:            if [ -n "$req" ]; then
scripts/daemon.sh:289:                    if [[ -n "$active_req" ]]; then
scripts/daemon.sh:299:                if [ "$current_queue" -ge "$DAEMON_QUEUE_SIZE" ]; then
scripts/daemon.sh:311:                [ "$current_queue" -gt 0 ] && _set_queue_size $((current_queue - 1))
scripts/daemon.sh:326:    rm -f "$DAEMON_SOCK" "$request_file" "$response_file"
scripts/daemon.sh:336:        [ -f "$stop_flag" ] && break
scripts/daemon.sh:343:            if [ "$count" -ge "$DAEMON_MAX_RESTARTS" ]; then
scripts/daemon.sh:345:                rm -f "$DAEMON_PID_FILE"
scripts/daemon.sh:364:    if [ -f "$DAEMON_PID_FILE" ]; then
scripts/daemon.sh:371:        rm -f "$DAEMON_PID_FILE" "$DAEMON_SOCK"
scripts/daemon.sh:376:    rm -f "$DEVBOOKS_DIR/daemon.stop" "$DEVBOOKS_DIR/monitor.stop"
scripts/daemon.sh:377:    rm -f "$DEVBOOKS_DIR/daemon.request" "$DEVBOOKS_DIR/daemon.response"
scripts/daemon.sh:390:    while [ ! -e "$DAEMON_SOCK" ] && [ $i -lt 50 ]; do
scripts/daemon.sh:401:        if ! ci_daemon_warmup --async --format json >/dev/null 2>&1; then
scripts/daemon.sh:415:    if [ -f "$DAEMON_PID_FILE" ]; then
scripts/daemon.sh:420:            kill -9 "$pid" 2>/dev/null || true
scripts/daemon.sh:425:    if [ -f "$DEVBOOKS_DIR/monitor.pid" ]; then
scripts/daemon.sh:427:        _process_exists "$mpid" && kill -9 "$mpid" 2>/dev/null || true
scripts/daemon.sh:428:        rm -f "$DEVBOOKS_DIR/monitor.pid"
scripts/daemon.sh:432:    if [ -f "$DEVBOOKS_DIR/warmup.pid" ]; then
scripts/daemon.sh:434:        _process_exists "$wpid" && kill -9 "$wpid" 2>/dev/null || true
scripts/daemon.sh:435:        rm -f "$DEVBOOKS_DIR/warmup.pid"
scripts/daemon.sh:439:    rm -f "$DAEMON_PID_FILE" "$DAEMON_SOCK"
scripts/daemon.sh:440:    rm -f "$DEVBOOKS_DIR/daemon.stop" "$DEVBOOKS_DIR/monitor.stop"
scripts/daemon.sh:441:    rm -f "$DEVBOOKS_DIR/daemon.request" "$DEVBOOKS_DIR/daemon.response"
scripts/daemon.sh:442:    rm -f "$DEVBOOKS_DIR/daemon.state" "$DEVBOOKS_DIR/daemon.restarts"
scripts/daemon.sh:443:    rm -f "$DEVBOOKS_DIR/daemon.queue"
scripts/daemon.sh:444:    rm -f "$DEVBOOKS_DIR/daemon.active_request"
scripts/daemon.sh:447:    rm -f "$DEVBOOKS_DIR/warmup.status" "$DEVBOOKS_DIR/warmup.started_at"
scripts/daemon.sh:448:    rm -f "$DEVBOOKS_DIR/warmup.completed_at" "$DEVBOOKS_DIR/warmup.items_cached"
scripts/daemon.sh:461:    if [ -f "$DAEMON_PID_FILE" ]; then
scripts/daemon.sh:463:        if [ -n "$pid" ] && [ "$pid" != "null" ] && _process_exists "$pid"; then
scripts/daemon.sh:482:    if [[ -n "$warmup_started_at" ]]; then
scripts/daemon.sh:485:    if [[ -n "$warmup_completed_at" ]]; then
scripts/daemon.sh:498:    if [ ! -f "$DAEMON_PID_FILE" ]; then
scripts/daemon.sh:513:    rm -f "$response_file"
scripts/daemon.sh:521:    while [ ! -f "$response_file" ] && [ $i -lt 100 ]; do
scripts/daemon.sh:526:    if [ -f "$response_file" ]; then
scripts/daemon.sh:528:        rm -f "$response_file"
scripts/daemon.sh:555:    if command -v timeout &>/dev/null; then
scripts/daemon.sh:557:    elif command -v gtimeout &>/dev/null; then
scripts/daemon.sh:562:    if [ -x "$SCRIPT_DIR/hotspot-analyzer.sh" ]; then
scripts/daemon.sh:564:        if [[ -n "$timeout_cmd" ]]; then
scripts/daemon.sh:565:            hotspots=$($timeout_cmd "$timeout" "$SCRIPT_DIR/hotspot-analyzer.sh" --top "$hotspot_limit" --format json 2>/dev/null | jq -r '.hotspots[].file // empty' 2>/dev/null) || true
scripts/daemon.sh:567:            hotspots=$("$SCRIPT_DIR/hotspot-analyzer.sh" --top "$hotspot_limit" --format json 2>/dev/null | jq -r '.hotspots[].file // empty' 2>/dev/null) || true
scripts/daemon.sh:570:        if [[ -n "$hotspots" ]]; then
scripts/daemon.sh:571:            while IFS= read -r file; do
scripts/daemon.sh:572:                [[ -z "$file" ]] && continue
scripts/daemon.sh:575:                if [ -x "$SCRIPT_DIR/cache-manager.sh" ]; then
scripts/daemon.sh:588:    if [ -x "$SCRIPT_DIR/graph-store.sh" ] && [ -f "$GRAPH_DB_PATH" ]; then
scripts/daemon.sh:589:        IFS=',' read -ra QUERY_LIST <<< "$queries"
scripts/daemon.sh:591:            [[ -z "$query" ]] && continue
scripts/daemon.sh:597:            if [ -x "$SCRIPT_DIR/cache-manager.sh" ]; then
scripts/daemon.sh:607:    if [ -x "$SCRIPT_DIR/cache-manager.sh" ]; then
scripts/daemon.sh:610:        stats=$("$SCRIPT_DIR/cache-manager.sh" stats --format json 2>/dev/null) || true
scripts/daemon.sh:611:        if [[ -n "$stats" ]]; then
scripts/daemon.sh:612:            symbols_cached=$(echo "$stats" | jq -r '.total_entries // 0' 2>/dev/null) || symbols_cached=0
scripts/daemon.sh:646:    while [[ $# -gt 0 ]]; do
scripts/daemon.sh:648:            --timeout)
scripts/daemon.sh:652:            --queries)
scripts/daemon.sh:656:            --hotspot-limit)
scripts/daemon.sh:660:            --format)
scripts/daemon.sh:664:            --async)
scripts/daemon.sh:712:        if command -v timeout &>/dev/null; then
scripts/daemon.sh:714:        elif command -v gtimeout &>/dev/null; then
scripts/daemon.sh:718:        if [[ -n "$timeout_cmd" ]]; then
scripts/daemon.sh:719:            $timeout_cmd bash -c "_warmup_background '$timeout' '$hotspot_limit' '$queries' '$format'" 2>/dev/null || _warmup_failed "timeout"
scripts/daemon.sh:739:        -h|--help|help)
scripts/daemon.sh:752:  --timeout N       Warmup timeout in seconds (default: 30)
scripts/daemon.sh:753:  --queries Q1,Q2   Comma-separated query list
scripts/daemon.sh:754:  --hotspot-limit N Number of hotspot files to cache (default: 10)
scripts/daemon.sh:755:  --format FORMAT   Output format: json or text (default: json)
scripts/daemon.sh:756:  --async           Run warmup in background
scripts/daemon.sh:765:  daemon.sh warmup --timeout 60 --format json
scripts/daemon.sh:766:  daemon.sh warmup --async
scripts/federation-lite-core.sh:10:[[ -n "${FEDERATION_LITE_CORE_LOADED:-}" ]] && return 0
scripts/federation-lite-core.sh:56:    if command -v md5sum &>/dev/null; then
scripts/federation-lite-core.sh:57:        md5sum "$file" 2>/dev/null | cut -d' ' -f1
scripts/federation-lite-core.sh:58:    elif command -v md5 &>/dev/null; then
scripts/federation-lite-core.sh:59:        md5 -q "$file" 2>/dev/null
scripts/federation-lite-core.sh:61:        cksum "$file" 2>/dev/null | cut -d' ' -f1
scripts/federation-lite-core.sh:86:    if [[ ! -f "$config_file" ]]; then
scripts/federation-lite-core.sh:106:    while IFS= read -r line || [[ -n "$line" ]]; do
scripts/federation-lite-core.sh:109:        [[ -z "${line// }" ]] && continue
scripts/federation-lite-core.sh:149:                    current_repo=$(echo "$current_repo" | jq --argjson c "$contracts" '.contracts = $c')
scripts/federation-lite-core.sh:150:                    repos=$(echo "$repos" | jq --argjson r "$current_repo" '. + [$r]')
scripts/federation-lite-core.sh:152:                current_repo=$(jq -n --arg name "${BASH_REMATCH[1]}" '{"name": $name}')
scripts/federation-lite-core.sh:159:                current_repo=$(echo "$current_repo" | jq --arg p "${BASH_REMATCH[1]}" '.path = $p')
scripts/federation-lite-core.sh:168:                contracts=$(echo "$contracts" | jq --arg c "${BASH_REMATCH[1]}" '. + [$c]')
scripts/federation-lite-core.sh:174:                auto_discover=$(echo "$auto_discover" | jq --arg e "${BASH_REMATCH[1]}" '.enabled = ($e == "true")')
scripts/federation-lite-core.sh:190:                search_paths=$(echo "$search_paths" | jq --arg p "${BASH_REMATCH[1]}" '. + [$p]')
scripts/federation-lite-core.sh:194:                contract_patterns=$(echo "$contract_patterns" | jq --arg p "${BASH_REMATCH[1]}" '. + [$p]')
scripts/federation-lite-core.sh:201:        current_repo=$(echo "$current_repo" | jq --argjson c "$contracts" '.contracts = $c')
scripts/federation-lite-core.sh:202:        repos=$(echo "$repos" | jq --argjson r "$current_repo" '. + [$r]')
scripts/federation-lite-core.sh:206:    auto_discover=$(echo "$auto_discover" | jq --argjson sp "$search_paths" --argjson cp "$contract_patterns" \
scripts/federation-lite-core.sh:209:    jq -n --argjson repos "$repos" --argjson ad "$auto_discover" \
scripts/federation-lite-core.sh:222:  federation-lite.sh --status
scripts/federation-lite-core.sh:223:  federation-lite.sh --update [--config config/federation.yaml]
scripts/federation-lite-core.sh:224:  federation-lite.sh --search "<symbol>" [--format json]
scripts/federation-lite-core.sh:225:  federation-lite.sh --list-contracts [--repo "<name>"]
scripts/federation-lite-core.sh:228:  federation-lite.sh --help
scripts/federation-lite-core.sh:231:  --status            Show index status
scripts/federation-lite-core.sh:232:  --update            Update the federation index
scripts/federation-lite-core.sh:233:  --config <file>     Configuration file (default: config/federation.yaml)
scripts/federation-lite-core.sh:234:  --search <symbol>   Search for a symbol across repositories
scripts/federation-lite-core.sh:235:  --list-contracts    List all indexed contracts
scripts/federation-lite-core.sh:236:  --repo <name>       Filter by repository name
scripts/federation-lite-core.sh:237:  --format <type>     Output format: json or text (default: json)
scripts/federation-lite-core.sh:238:  --debug             Enable debug output
scripts/federation-lite-core.sh:239:  --help              Show this help message
scripts/federation-lite-core.sh:243:    --local-repo <path>     Path to local repository (default: current directory)
scripts/federation-lite-core.sh:244:    --db <path>             Path to graph.db (default: .devbooks/graph.db)
scripts/federation-lite-core.sh:245:    --min-confidence <n>    Minimum confidence threshold (default: 0.5)
scripts/federation-lite-core.sh:246:    --sync                  Sync mode: update existing edges, remove stale ones
scripts/federation-lite-core.sh:249:    --virtual-edges         Enable virtual edge results
scripts/federation-lite-core.sh:250:    --confidence <n>        Minimum confidence filter (default: 0.0)
scripts/federation-lite-core.sh:268:  federation-lite.sh --status
scripts/federation-lite-core.sh:271:  federation-lite.sh --update
scripts/federation-lite-core.sh:274:  federation-lite.sh --search "UserService"
scripts/federation-lite-core.sh:277:  federation-lite.sh --list-contracts
scripts/federation-lite-core.sh:280:  federation-lite.sh generate-virtual-edges --local-repo ./my-app --min-confidence 0.5
scripts/federation-lite-core.sh:283:  federation-lite.sh query-virtual "getUserById" --confidence 0.5
bin/ci-search:6:#   ci-search --help
bin/ci-search:7:#   ci-search --version
bin/ci-search:10:#   -l, --limit <n>     Max results (default: 10)
bin/ci-search:11:#   -m, --mode <mode>   Search mode: semantic|keyword (default: semantic)
bin/ci-search:12:#   -h, --help          Show this help
bin/ci-search:13:#   -v, --version       Show version
bin/ci-search:15:set -euo pipefail
bin/ci-search:31:  ci-search --help
bin/ci-search:32:  ci-search --version
bin/ci-search:35:  -l, --limit <n>     Max results (default: 10)
bin/ci-search:36:  -m, --mode <mode>   Search mode: semantic|keyword (default: semantic)
bin/ci-search:37:  -h, --help          Show this help
bin/ci-search:38:  -v, --version       Show version
bin/ci-search:42:  ci-search "authentication" --limit 20
bin/ci-search:43:  ci-search "api endpoint" --mode keyword
bin/ci-search:53:while [[ $# -gt 0 ]]; do
bin/ci-search:55:        -h|--help)
bin/ci-search:59:        -v|--version)
bin/ci-search:63:        -l|--limit)
bin/ci-search:67:        -m|--mode)
bin/ci-search:84:if [[ -z "$QUERY" ]]; then
bin/ci-search:91:if [[ -x "${SCRIPTS_DIR}/embedding.sh" ]]; then
bin/ci-search:92:    exec bash "${SCRIPTS_DIR}/embedding.sh" search "$QUERY" --limit "$LIMIT" --mode "$MODE"
scripts/test-embedding.sh:4:set -euo pipefail
scripts/test-embedding.sh:17:echo_info()  { echo -e "${BLUE}[Test]${NC} $1"; }
scripts/test-embedding.sh:18:echo_ok()    { echo -e "${GREEN}[Test]${NC} ‚úì $1"; }
scripts/test-embedding.sh:19:echo_fail()  { echo -e "${RED}[Test]${NC} ‚úó $1"; }
scripts/test-embedding.sh:20:echo_warn()  { echo -e "${YELLOW}[Test]${NC} ‚ö† $1"; }
scripts/test-embedding.sh:51:run_test "Ê£ÄÊü•ËÑöÊú¨Â≠òÂú®" "[ -f '$EMBEDDING_SCRIPT' ]"
scripts/test-embedding.sh:52:run_test "Ê£ÄÊü•ËÑöÊú¨ÂèØÊâßË°å" "[ -x '$EMBEDDING_SCRIPT' ]"
scripts/test-embedding.sh:56:  if command -v "$1" &>/dev/null; then
scripts/test-embedding.sh:79:run_test "ÊòæÁ§∫Â∏ÆÂä©" "$EMBEDDING_SCRIPT help | grep -q 'DevBooks Embedding'"
scripts/test-embedding.sh:81:run_test "Ê£ÄÊü•ÈÖçÁΩÆÊñá‰ª∂" "[ -f '$PROJECT_ROOT/.devbooks/embedding.yaml' ]"
scripts/test-embedding.sh:95:if [ -z "${OPENAI_API_KEY:-${EMBEDDING_API_KEY}}" ]; then
scripts/test-embedding.sh:105:  mkdir -p "$TEST_DIR"
scripts/test-embedding.sh:144:  rm -rf "$TEST_DIR"
scripts/test-embedding.sh:154:if [ -f "$HOOK_SCRIPT" ]; then
scripts/test-embedding.sh:155:  run_test "Hook ËÑöÊú¨Â≠òÂú®" "[ -f '$HOOK_SCRIPT' ]"
scripts/test-embedding.sh:156:  run_test "Hook ËÑöÊú¨ÂèØÊâßË°å" "[ -x '$HOOK_SCRIPT' ] || chmod +x '$HOOK_SCRIPT'"
scripts/test-embedding.sh:161:  if echo "$TEST_INPUT" | "$HOOK_SCRIPT" | jq -e '.additionalContext' >/dev/null 2>&1; then
scripts/test-embedding.sh:179:file_count=$(find "$PROJECT_ROOT" -type f \
scripts/test-embedding.sh:180:  \( -name "*.ts" -o -name "*.js" -o -name "*.py" \) \
scripts/test-embedding.sh:181:  ! -path "*/node_modules/*" \
scripts/test-embedding.sh:182:  ! -path "*/dist/*" \
scripts/test-embedding.sh:183:  ! -path "*/.git/*" \
scripts/test-embedding.sh:184:  2>/dev/null | wc -l)
scripts/test-embedding.sh:191:if [ "$file_count" -gt 0 ] && [ "$duration" -lt 10 ]; then
scripts/test-embedding.sh:204:echo -e "${GREEN}ÈÄöËøá: $TESTS_PASSED${NC}"
scripts/test-embedding.sh:205:echo -e "${RED}Â§±Ë¥•: $TESTS_FAILED${NC}"
scripts/test-embedding.sh:208:if [ "$TESTS_FAILED" -eq 0 ]; then
scripts/ast-diff.sh:18:set -euo pipefail
scripts/ast-diff.sh:28:if [ -f "$COMMON_LIB" ]; then
scripts/ast-diff.sh:39:  log_info()  { echo -e "${BLUE}[ASTDiff]${NC} $1" >&2; }
scripts/ast-diff.sh:40:  log_ok()    { echo -e "${GREEN}[ASTDiff]${NC} $1" >&2; }
scripts/ast-diff.sh:41:  log_warn()  { echo -e "${YELLOW}[ASTDiff]${NC} $1" >&2; }
scripts/ast-diff.sh:42:  log_error() { echo -e "${RED}[ASTDiff]${NC} $1" >&2; }
scripts/ast-diff.sh:46:if declare -f check_dependencies &>/dev/null; then
scripts/ast-diff.sh:49:  command -v jq &>/dev/null || { log_error "Áº∫Â∞ë‰æùËµñ: jq"; exit 2; }
scripts/ast-diff.sh:54:if declare -f is_feature_enabled &>/dev/null; then
scripts/ast-diff.sh:86:  --force-full          Âº∫Âà∂ÂÖ®ÈáèÈáçÂª∫
scripts/ast-diff.sh:87:  --cwd <path>          Â∑•‰ΩúÁõÆÂΩïÔºàÈªòËÆ§: ÂΩìÂâçÁõÆÂΩïÔºâ
scripts/ast-diff.sh:88:  --format <text|json>  ËæìÂá∫Ê†ºÂºèÔºàÈªòËÆ§: jsonÔºâ
scripts/ast-diff.sh:89:  --version             ÊòæÁ§∫ÁâàÊú¨
scripts/ast-diff.sh:90:  --help                ÊòæÁ§∫Ê≠§Â∏ÆÂä©
scripts/ast-diff.sh:113:  ast-diff.sh update --force-full
scripts/ast-diff.sh:129:  if [[ $# -gt 0 ]] && [[ "$1" != --* ]]; then
scripts/ast-diff.sh:134:  while [[ $# -gt 0 ]]; do
scripts/ast-diff.sh:136:      --force-full)
scripts/ast-diff.sh:140:      --cwd)
scripts/ast-diff.sh:149:      --format)
scripts/ast-diff.sh:153:      --version)
scripts/ast-diff.sh:157:      --help|-h)
scripts/ast-diff.sh:174:  if [ ! -f "$SCIP_INDEX" ]; then
scripts/ast-diff.sh:182:  if [ -f "$SCIP_INDEX" ]; then
scripts/ast-diff.sh:183:    stat -f %m "$SCIP_INDEX" 2>/dev/null || stat -c %Y "$SCIP_INDEX" 2>/dev/null || echo 0
scripts/ast-diff.sh:191:  if [ -f "$LAST_INDEX_TIME_FILE" ]; then
scripts/ast-diff.sh:200:  mkdir -p "$CACHE_DIR" 2>/dev/null
scripts/ast-diff.sh:210:  if [ ! -d "$CWD/.git" ]; then
scripts/ast-diff.sh:212:    find "$CWD" -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" -o -name "*.py" -o -name "*.go" \) \
scripts/ast-diff.sh:213:      -newer "$LAST_INDEX_TIME_FILE" 2>/dev/null | \
scripts/ast-diff.sh:214:      grep -vE 'node_modules|dist|build|\.git' | \
scripts/ast-diff.sh:215:      while read -r f; do echo "${f#"$CWD"/}"; done
scripts/ast-diff.sh:222:    git -C "$CWD" ls-files '*.ts' '*.tsx' '*.js' '*.jsx' '*.py' '*.go' 2>/dev/null | head -100
scripts/ast-diff.sh:226:    since_date=$(date -r "$since_time" "+%Y-%m-%d %H:%M:%S" 2>/dev/null || \
scripts/ast-diff.sh:227:                 date -d "@$since_time" "+%Y-%m-%d %H:%M:%S" 2>/dev/null || \
scripts/ast-diff.sh:231:    git -C "$CWD" diff --name-only --diff-filter=ACMR HEAD -- '*.ts' '*.tsx' '*.js' '*.jsx' '*.py' '*.go' 2>/dev/null
scripts/ast-diff.sh:234:    git -C "$CWD" ls-files --others --exclude-standard '*.ts' '*.tsx' '*.js' '*.jsx' '*.py' '*.go' 2>/dev/null
scripts/ast-diff.sh:242:# Êú™Êù•ÂÆûÁé∞Ë∑ØÂæÑÔºöscip-typescript index --incremental --files <changed-files>
scripts/ast-diff.sh:285:  if command -v scip-typescript &>/dev/null; then
scripts/ast-diff.sh:312:    result=$(jq -n \
scripts/ast-diff.sh:313:      --arg version "1.0" \
scripts/ast-diff.sh:314:      --arg status "no_index" \
scripts/ast-diff.sh:315:      --arg message "SCIP Á¥¢Âºï‰∏çÂ≠òÂú®ÔºåËØ∑ÂÖàËøêË°åÁ¥¢ÂºïÁîüÊàêÂ∑•ÂÖ∑ÔºàÂ¶Ç scip-typescript index .Ôºâ" \
scripts/ast-diff.sh:329:    elapsed=$(echo "$full_result" | cut -d: -f1)
scripts/ast-diff.sh:330:    index_status=$(echo "$full_result" | cut -d: -f2)
scripts/ast-diff.sh:334:      result=$(jq -n \
scripts/ast-diff.sh:335:        --arg version "1.0" \
scripts/ast-diff.sh:336:        --arg status "skipped" \
scripts/ast-diff.sh:337:        --arg mode "full" \
scripts/ast-diff.sh:338:        --argjson elapsed "$elapsed" \
scripts/ast-diff.sh:339:        --arg message "scip-typescript ‰∏çÂèØÁî®ÔºåÁ¥¢ÂºïÊú™Êõ¥Êñ∞" \
scripts/ast-diff.sh:348:      result=$(jq -n \
scripts/ast-diff.sh:349:        --arg version "1.0" \
scripts/ast-diff.sh:350:        --arg status "updated" \
scripts/ast-diff.sh:351:        --arg mode "full" \
scripts/ast-diff.sh:352:        --argjson elapsed "$elapsed" \
scripts/ast-diff.sh:372:  if [ -z "$changed_files" ]; then
scripts/ast-diff.sh:375:    result=$(jq -n \
scripts/ast-diff.sh:376:      --arg version "1.0" \
scripts/ast-diff.sh:377:      --arg status "up_to_date" \
scripts/ast-diff.sh:378:      --arg message "Á¥¢ÂºïÂ∑≤ÊòØÊúÄÊñ∞ÔºåÊó†ÈúÄÊõ¥Êñ∞" \
scripts/ast-diff.sh:390:  files_json=$(echo "$changed_files" | jq -R -s 'split("\n") | map(select(length > 0))')
scripts/ast-diff.sh:400:  if [ "$elapsed" -gt 1000 ]; then
scripts/ast-diff.sh:410:  result=$(jq -n \
scripts/ast-diff.sh:411:    --arg version "1.0" \
scripts/ast-diff.sh:412:    --arg status "updated" \
scripts/ast-diff.sh:413:    --arg mode "incremental" \
scripts/ast-diff.sh:414:    --argjson simulated true \
scripts/ast-diff.sh:415:    --argjson file_count "$file_count" \
scripts/ast-diff.sh:416:    --argjson elapsed "$total_elapsed" \
scripts/ast-diff.sh:417:    --argjson files "$files_json" \
scripts/ast-diff.sh:450:    if [ -n "$changed" ]; then
scripts/ast-diff.sh:451:      pending_files=$(echo "$changed" | jq -R -s 'split("\n") | map(select(length > 0))')
scripts/ast-diff.sh:459:  result=$(jq -n \
scripts/ast-diff.sh:460:    --arg version "1.0" \
scripts/ast-diff.sh:461:    --argjson index_exists "$index_exists" \
scripts/ast-diff.sh:462:    --argjson index_mtime "$index_mtime" \
scripts/ast-diff.sh:463:    --argjson last_update "$last_update" \
scripts/ast-diff.sh:464:    --argjson pending_count "$pending_count" \
scripts/ast-diff.sh:465:    --argjson pending_files "$pending_files" \
scripts/ast-diff.sh:488:  if [ -n "$changed_files" ]; then
scripts/ast-diff.sh:489:    files_json=$(echo "$changed_files" | jq -R -s 'split("\n") | map(select(length > 0))')
scripts/ast-diff.sh:496:  result=$(jq -n \
scripts/ast-diff.sh:497:    --arg version "1.0" \
scripts/ast-diff.sh:498:    --argjson file_count "$file_count" \
scripts/ast-diff.sh:499:    --argjson files "$files_json" \
scripts/ast-diff.sh:519:    status=$(echo "$result" | jq -r '.status // "unknown"')
scripts/ast-diff.sh:524:        mode=$(echo "$result" | jq -r '.mode // "unknown"')
scripts/ast-diff.sh:525:        file_count=$(echo "$result" | jq -r '.changed_files // 0')
scripts/ast-diff.sh:526:        elapsed=$(echo "$result" | jq -r '.elapsed_ms // 0')
scripts/ast-diff.sh:536:        message=$(echo "$result" | jq -r '.message // "SCIP Á¥¢Âºï‰∏çÂ≠òÂú®"')
scripts/ast-diff.sh:542:        index_exists=$(echo "$result" | jq -r '.index_exists // false')
scripts/ast-diff.sh:543:        pending_count=$(echo "$result" | jq -r '.pending_files // 0')
scripts/ast-diff.sh:550:        if [ "$pending_count" -gt 0 ]; then
scripts/ast-diff.sh:553:          echo "$result" | jq -r '.files[]' | head -10 | sed 's/^/  - /'
scripts/vendor-proto.sh:10:#   --check      Ê£ÄÊü• vendored proto ÁâàÊú¨‰∏é scip-typescript ÂÖºÂÆπÊÄß
scripts/vendor-proto.sh:11:#   --upgrade    ‰ªé GitHub ‰∏ãËΩΩÊúÄÊñ∞ proto Âπ∂Êõ¥Êñ∞ vendored/scip.proto
scripts/vendor-proto.sh:12:#   --version    ÊòæÁ§∫ÂΩìÂâç vendored proto ÁâàÊú¨
scripts/vendor-proto.sh:14:set -euo pipefail
scripts/vendor-proto.sh:37:    if [[ ! -f "$proto_file" ]]; then
scripts/vendor-proto.sh:44:    version=$(grep -E "^//[[:space:]]*Version:" "$proto_file" 2>/dev/null | head -1 | sed 's/.*Version:[[:space:]]*//' | tr -d '[:space:]')
scripts/vendor-proto.sh:46:    if [[ -n "$version" ]]; then
scripts/vendor-proto.sh:57:    if command -v scip-typescript &>/dev/null; then
scripts/vendor-proto.sh:58:        scip-typescript --version 2>/dev/null | head -1 | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' || echo "unknown"
scripts/vendor-proto.sh:59:    elif [[ -f "$PROJECT_ROOT/node_modules/.bin/scip-typescript" ]]; then
scripts/vendor-proto.sh:60:        "$PROJECT_ROOT/node_modules/.bin/scip-typescript" --version 2>/dev/null | head -1 | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' || echo "unknown"
scripts/vendor-proto.sh:79:    proto_major=$(echo "$proto_version" | cut -d'.' -f1)
scripts/vendor-proto.sh:80:    scip_major=$(echo "$scip_version" | cut -d'.' -f1)
scripts/vendor-proto.sh:90:# ==================== ÂëΩ‰ª§: --check ====================
scripts/vendor-proto.sh:96:    if [[ ! -f "$VENDORED_PROTO" ]]; then
scripts/vendor-proto.sh:101:            log_info "ËøêË°å $0 --upgrade Êù•‰∏ãËΩΩ"
scripts/vendor-proto.sh:118:    elif [[ $? -eq 1 ]]; then
scripts/vendor-proto.sh:124:        jq -n \
scripts/vendor-proto.sh:125:            --arg proto_version "$proto_version" \
scripts/vendor-proto.sh:126:            --arg scip_version "$scip_version" \
scripts/vendor-proto.sh:127:            --arg status "$compatible_status" \
scripts/vendor-proto.sh:128:            --argjson compatible "$compatible_bool" \
scripts/vendor-proto.sh:146:        log_warn "ÁâàÊú¨ÂèØËÉΩ‰∏çÂÖºÂÆπÔºåÂª∫ËÆÆËøêË°å $0 --upgrade"
scripts/vendor-proto.sh:153:# ==================== ÂëΩ‰ª§: --upgrade ====================
scripts/vendor-proto.sh:161:    if command -v curl &>/dev/null; then
scripts/vendor-proto.sh:162:        if ! curl -s --connect-timeout 10 "$SCIP_PROTO_URL" -o "$TEMP_PROTO" 2>/dev/null; then
scripts/vendor-proto.sh:164:            rm -f "$TEMP_PROTO"
scripts/vendor-proto.sh:167:    elif command -v wget &>/dev/null; then
scripts/vendor-proto.sh:168:        if ! wget -q --timeout=10 "$SCIP_PROTO_URL" -O "$TEMP_PROTO" 2>/dev/null; then
scripts/vendor-proto.sh:170:            rm -f "$TEMP_PROTO"
scripts/vendor-proto.sh:179:    if [[ ! -s "$TEMP_PROTO" ]]; then
scripts/vendor-proto.sh:181:        rm -f "$TEMP_PROTO"
scripts/vendor-proto.sh:186:    if ! grep -q "^syntax = \"proto3\"" "$TEMP_PROTO" 2>/dev/null; then
scripts/vendor-proto.sh:188:        rm -f "$TEMP_PROTO"
scripts/vendor-proto.sh:193:    mkdir -p "$(dirname "$VENDORED_PROTO")"
scripts/vendor-proto.sh:207:        echo "// To upgrade: scripts/vendor-proto.sh --upgrade"
scripts/vendor-proto.sh:212:    rm -f "$TEMP_PROTO"
scripts/vendor-proto.sh:220:# ==================== ÂëΩ‰ª§: --version ====================
scripts/vendor-proto.sh:225:    if [[ ! -f "$VENDORED_PROTO" ]]; then
scripts/vendor-proto.sh:238:        jq -n --arg version "$version" '{"version": $version, "path": "vendored/scip.proto"}'
scripts/vendor-proto.sh:251:    vendor-proto.sh --check [--format json]    Ê£ÄÊü•ÁâàÊú¨ÂÖºÂÆπÊÄß
scripts/vendor-proto.sh:252:    vendor-proto.sh --upgrade                  ‰ªé GitHub ‰∏ãËΩΩÊúÄÊñ∞ proto
scripts/vendor-proto.sh:253:    vendor-proto.sh --version [--format json]  ÊòæÁ§∫ÂΩìÂâçÁâàÊú¨
scripts/vendor-proto.sh:254:    vendor-proto.sh --help                     ÊòæÁ§∫Â∏ÆÂä©
scripts/vendor-proto.sh:260:    --check ‰ºöÊ£ÄÊü•Ôºö
scripts/vendor-proto.sh:264:    --upgrade ‰ºöÔºö
scripts/vendor-proto.sh:271:    vendor-proto.sh --check
scripts/vendor-proto.sh:274:    vendor-proto.sh --check --format json
scripts/vendor-proto.sh:277:    vendor-proto.sh --upgrade
scripts/vendor-proto.sh:288:    while [[ $# -gt 0 ]]; do
scripts/vendor-proto.sh:290:            --check)
scripts/vendor-proto.sh:294:            --upgrade)
scripts/vendor-proto.sh:298:            --version)
scripts/vendor-proto.sh:302:            --format)
scripts/vendor-proto.sh:306:            --help|-h)
scripts/graph-rag-fusion.sh:25:  jq -n \
scripts/graph-rag-fusion.sh:26:    --argjson keyword "$keyword_json" \
scripts/graph-rag-fusion.sh:27:    --argjson vector "$vector_json" \
scripts/graph-rag-fusion.sh:28:    --argjson graph "$graph_json" \
scripts/graph-rag-fusion.sh:29:    --argjson wk "$weight_keyword" \
scripts/graph-rag-fusion.sh:30:    --argjson wv "$weight_vector" \
scripts/graph-rag-fusion.sh:31:    --argjson wg "$weight_graph" \
scripts/graph-rag-fusion.sh:32:    --argjson rrf_k "$rrf_k" \
scripts/graph-rag-fusion.sh:57:  if [[ ! -f "$config_file" ]]; then
scripts/graph-rag-fusion.sh:101:    file_path=$(echo "$truncated" | jq -r ".[$i].file_path")
scripts/graph-rag-fusion.sh:102:    score=$(echo "$truncated" | jq -r ".[$i].relevance_score // 0")
scripts/graph-rag-fusion.sh:128:  if ! echo "$response" | jq -e '.' &>/dev/null; then
scripts/graph-rag-fusion.sh:135:  if ! echo "$response" | jq -e 'type == "array"' &>/dev/null; then
scripts/graph-rag-fusion.sh:153:    idx=$(echo "$rankings" | jq -r ".[$i].index // -1")
scripts/graph-rag-fusion.sh:154:    score=$(echo "$rankings" | jq -r ".[$i].score // 0")
scripts/graph-rag-fusion.sh:155:    reason=$(echo "$rankings" | jq -r ".[$i].reason // \"\"")
scripts/graph-rag-fusion.sh:157:    if [[ "$idx" -ge 0 && "$idx" -lt "$orig_count" ]]; then
scripts/graph-rag-fusion.sh:161:        --argjson llm_score "$score" \
scripts/graph-rag-fusion.sh:162:        --arg llm_reason "$reason" \
scripts/graph-rag-fusion.sh:164:      reranked=$(echo "$reranked" | jq --argjson c "$candidate" '. + [$c]')
scripts/graph-rag-fusion.sh:174:  if [ -z "$path" ] || [ ! -f "$path" ]; then
scripts/graph-rag-fusion.sh:178:  if stat -f %m "$path" >/dev/null 2>&1; then
scripts/graph-rag-fusion.sh:179:    stat -f %m "$path"
scripts/graph-rag-fusion.sh:180:  elif stat -c %Y "$path" >/dev/null 2>&1; then
scripts/graph-rag-fusion.sh:181:    stat -c %Y "$path"
scripts/graph-rag-fusion.sh:200:  while [ "$i" -lt "$count" ]; do
scripts/graph-rag-fusion.sh:205:    file_path=$(echo "$candidate" | jq -r '.file_path // .file // ""')
scripts/graph-rag-fusion.sh:206:    [ -z "$file_path" ] && file_path="unknown"
scripts/graph-rag-fusion.sh:214:    if [ -n "$base_lower" ]; then
scripts/graph-rag-fusion.sh:228:    if [ -n "$file_path" ] && [ "$file_path" != "unknown" ]; then
scripts/graph-rag-fusion.sh:229:      depth=$(echo "$file_path" | awk -F'/' '{print NF}')
scripts/graph-rag-fusion.sh:235:    [ -z "$mtime" ] && mtime="0"
scripts/graph-rag-fusion.sh:239:    heuristic_score=$(awk -v m="$match" -v d="$depth" -v t="$mtime" \
scripts/graph-rag-fusion.sh:241:    [ -z "$heuristic_score" ] && heuristic_score="0.00"
scripts/graph-rag-fusion.sh:244:      --argjson match "$match" \
scripts/graph-rag-fusion.sh:245:      --argjson depth "$depth" \
scripts/graph-rag-fusion.sh:246:      --argjson mtime "$mtime" \
scripts/graph-rag-fusion.sh:247:      --argjson score "$heuristic_score" \
scripts/graph-rag-fusion.sh:250:    updated=$(echo "$updated" | jq --argjson c "$candidate" '. + [$c]')
scripts/graph-rag-fusion.sh:273:    if [[ -n "$state_file" ]]; then
scripts/graph-rag-fusion.sh:299:  if [[ "$max_candidate_length" =~ ^[0-9]+$ ]] && [[ "$max_candidate_length" -gt 0 ]]; then
scripts/graph-rag-fusion.sh:306:  if [[ "$count" -gt "$rerank_limit" ]]; then
scripts/graph-rag-fusion.sh:309:  if [[ "$count" -eq 0 ]]; then
scripts/graph-rag-fusion.sh:326:  if [[ -z "${LLM_MOCK_RESPONSE:-}" && -z "${LLM_MOCK_DELAY_MS:-}" ]]; then
scripts/graph-rag-fusion.sh:351:  while [[ $attempt -le $max_retries ]]; do
scripts/graph-rag-fusion.sh:352:    if [[ $attempt -gt 0 ]]; then
scripts/graph-rag-fusion.sh:365:    rm -f "$response_file"
scripts/graph-rag-fusion.sh:367:    if [[ $exit_code -eq 124 ]]; then
scripts/graph-rag-fusion.sh:373:    if [[ $exit_code -ne 0 ]] || echo "$response" | jq -e '.error' &>/dev/null; then
scripts/graph-rag-fusion.sh:374:      last_error=$(echo "$response" | jq -r '.error // "unknown error"' 2>/dev/null || echo "llm_error")
scripts/graph-rag-fusion.sh:379:    if ! echo "$response" | jq -e '.' &>/dev/null; then
scripts/graph-rag-fusion.sh:385:    if ! echo "$response" | jq -e 'type == "array"' &>/dev/null; then
scripts/graph-rag-fusion.sh:394:    if [[ $? -eq 0 ]] && [[ -n "$reranked" ]] && [[ "$reranked" != "[]" ]]; then
scripts/graph-rag-fusion.sh:428:  if [ "$FUSION_DEPTH" -gt 0 ]; then
scripts/llm-providers/README.md:97:  if [[ -n "${LLM_MOCK_RESPONSE:-}" ]]; then
scripts/llm-providers/README.md:111:  if [[ -n "${LLM_MOCK_RESPONSE:-}" ]]; then
scripts/ast-delta.sh:24:set -euo pipefail
scripts/ast-delta.sh:64:    mkdir -p "$DEVBOOKS_DIR"
scripts/ast-delta.sh:65:    mkdir -p "$AST_CACHE_DIR"
scripts/ast-delta.sh:87:    if [[ "$min_age" -eq 0 ]]; then
scripts/ast-delta.sh:88:        temp_files=$(find "$DEVBOOKS_DIR" -name ".ast-delta-temp-*.tmp" 2>/dev/null || true)
scripts/ast-delta.sh:90:        temp_files=$(find "$DEVBOOKS_DIR" -name ".ast-delta-temp-*.tmp" -mmin +"$min_age" 2>/dev/null || true)
scripts/ast-delta.sh:92:    if [[ -n "$temp_files" ]]; then
scripts/ast-delta.sh:94:        echo "$temp_files" | xargs rm -f 2>/dev/null || true
scripts/ast-delta.sh:113:    if [[ -n "$_TREE_SITTER_AVAILABLE" ]]; then
scripts/ast-delta.sh:125:    if ! command -v node &>/dev/null; then
scripts/ast-delta.sh:141:    if node -e "$check_script" 2>/dev/null; then
scripts/ast-delta.sh:152:    if [[ -f "$VERSION_STAMP_FILE" ]]; then
scripts/ast-delta.sh:166:    if [[ -s "$tmp_file" ]]; then
scripts/ast-delta.sh:169:        rm -f "$tmp_file"
scripts/ast-delta.sh:176:    if [[ ! -f "$GRAPH_DB_PATH" ]]; then
scripts/ast-delta.sh:188:    if [[ ! -f "$GRAPH_DB_PATH" ]]; then
scripts/ast-delta.sh:201:    timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
scripts/ast-delta.sh:204:    if [[ -f "index.scip" ]]; then
scripts/ast-delta.sh:205:        scip_mtime=$(stat -c %Y "index.scip" 2>/dev/null || stat -f %m "index.scip" 2>/dev/null || echo "")
scripts/ast-delta.sh:209:    file_count=$(find "$AST_CACHE_DIR" -name "*.ast" 2>/dev/null | wc -l | tr -d ' ')
scripts/ast-delta.sh:230:    mkdir -p "$(dirname "$cache_file")"
scripts/ast-delta.sh:236:    if [[ ! -s "$tmp_file" ]]; then
scripts/ast-delta.sh:237:        rm -f "$tmp_file"
scripts/ast-delta.sh:249:    if [[ ! -f "$file_path" ]]; then
scripts/ast-delta.sh:308:    node -e "$parse_script" "$file_path" 2>/dev/null
scripts/ast-delta.sh:315:    if [[ ! -f "$file_path" ]]; then
scripts/ast-delta.sh:323:    line_count=$(echo "$content" | wc -l | tr -d ' ')
scripts/ast-delta.sh:330:    funcs=$(grep -n "^[[:space:]]*\(export[[:space:]]\+\)\?\(async[[:space:]]\+\)\?function[[:space:]]\+" "$file_path" 2>/dev/null || true)
scripts/ast-delta.sh:333:    classes=$(grep -n "^[[:space:]]*\(export[[:space:]]\+\)\?\(abstract[[:space:]]\+\)\?class[[:space:]]\+" "$file_path" 2>/dev/null || true)
scripts/ast-delta.sh:363:    if [[ ! -d "$AST_CACHE_DIR" ]] || [[ ! -f "$VERSION_STAMP_FILE" ]]; then
scripts/ast-delta.sh:369:    cache_version=$(cat "$VERSION_STAMP_FILE" 2>/dev/null | grep -o '"timestamp"[[:space:]]*:[[:space:]]*"[^"]*"' | head -1 | sed 's/.*"\([^"]*\)"$/\1/')
scripts/ast-delta.sh:374:    if [[ -n "$db_version" ]] && [[ "$cache_version" != "$db_version" ]]; then
scripts/ast-delta.sh:380:    if [[ "$file_count" -gt "$AST_DELTA_BATCH_THRESHOLD" ]]; then
scripts/ast-delta.sh:395:    if [[ ! -x "$SCRIPT_DIR/graph-store.sh" ]]; then
scripts/ast-delta.sh:404:    if command -v jq &>/dev/null; then
scripts/ast-delta.sh:407:        nodes=$(echo "$ast_json" | jq -c 'recurse(.children[]?) | select(.name != null)' 2>/dev/null || true)
scripts/ast-delta.sh:409:        if [[ -n "$nodes" ]]; then
scripts/ast-delta.sh:410:            while IFS= read -r node; do
scripts/ast-delta.sh:413:                id=$(echo "$node" | jq -r '.id // empty')
scripts/ast-delta.sh:414:                name=$(echo "$node" | jq -r '.name // empty')
scripts/ast-delta.sh:415:                kind=$(echo "$node" | jq -r '.type // empty')
scripts/ast-delta.sh:416:                line_start=$(echo "$node" | jq -r '.startLine // empty')
scripts/ast-delta.sh:417:                line_end=$(echo "$node" | jq -r '.endLine // empty')
scripts/ast-delta.sh:419:                if [[ -n "$id" && -n "$name" && -n "$kind" ]]; then
scripts/ast-delta.sh:421:                        --id "$id" \
scripts/ast-delta.sh:422:                        --symbol "$name" \
scripts/ast-delta.sh:423:                        --kind "$kind" \
scripts/ast-delta.sh:424:                        --file "$file_path" \
scripts/ast-delta.sh:425:                        --line-start "$line_start" \
scripts/ast-delta.sh:426:                        --line-end "$line_end" >/dev/null 2>&1 || true
scripts/ast-delta.sh:439:    while [[ $# -gt 0 ]]; do
scripts/ast-delta.sh:441:            --force-rebuild)
scripts/ast-delta.sh:452:    if [[ -z "$file_path" ]]; then
scripts/ast-delta.sh:459:    if [[ ! -f "$file_path" ]]; then
scripts/ast-delta.sh:469:    if [[ "$force_rebuild" != "true" ]] && [[ -f "$cache_file" ]] && ! [[ "$file_path" -nt "$cache_file" ]]; then
scripts/ast-delta.sh:472:        if [[ -f "$VERSION_STAMP_FILE" ]] && [[ -f "$GRAPH_DB_PATH" ]]; then
scripts/ast-delta.sh:474:            cache_ts=$(grep -o '"timestamp"[[:space:]]*:[[:space:]]*"[^"]*"' "$VERSION_STAMP_FILE" 2>/dev/null | head -1 | sed 's/.*"\([^"]*\)"$/\1/')
scripts/ast-delta.sh:476:            if [[ -n "$db_ts" ]] && [[ "$cache_ts" != "$db_ts" ]]; then
scripts/ast-delta.sh:511:            if [[ -f "$cache_file" ]] && ! [[ "$file_path" -nt "$cache_file" ]]; then
scripts/ast-delta.sh:518:                if [[ -z "$ast_json" || "$ast_json" == *'"error"'* ]]; then
scripts/ast-delta.sh:530:            rm -rf "${AST_CACHE_DIR:?}"/*
scripts/ast-delta.sh:533:            if [[ -z "$ast_json" || "$ast_json" == *'"error"'* ]]; then
scripts/ast-delta.sh:544:            if [[ -f "$cache_file_fb" ]] && ! [[ "$file_path" -nt "$cache_file_fb" ]]; then
scripts/ast-delta.sh:558:        if [[ -n "$ast_json" ]]; then
scripts/ast-delta.sh:572:        timestamp=$(echo "$new_stamp" | grep -o '"timestamp"[[:space:]]*:[[:space:]]*"[^"]*"' | head -1 | sed 's/.*"\([^"]*\)"$/\1/')
scripts/ast-delta.sh:585:    while [[ $# -gt 0 ]]; do
scripts/ast-delta.sh:587:            --since)
scripts/ast-delta.sh:601:    if [[ -n "$since" ]]; then
scripts/ast-delta.sh:603:        if command -v git &>/dev/null && git rev-parse --is-inside-work-tree &>/dev/null; then
scripts/ast-delta.sh:604:            while IFS= read -r file; do
scripts/ast-delta.sh:605:                if [[ -f "$file" ]]; then
scripts/ast-delta.sh:608:            done < <(git diff --name-only "$since" 2>/dev/null | grep -E '\.(ts|tsx|js|jsx|mts|mjs)$' || true)
scripts/ast-delta.sh:612:        while IFS= read -r file; do
scripts/ast-delta.sh:614:        done < <(find . -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \) \
scripts/ast-delta.sh:615:            -not -path "*/node_modules/*" -not -path "*/.git/*" -not -path "*/dist/*" 2>/dev/null || true)
scripts/ast-delta.sh:620:    if [[ $file_count -eq 0 ]]; then
scripts/ast-delta.sh:655:            rm -rf "${AST_CACHE_DIR:?}"/*
scripts/ast-delta.sh:658:            if [[ -x "$SCRIPT_DIR/scip-to-graph.sh" ]]; then
scripts/ast-delta.sh:678:            if [[ -x "$SCRIPT_DIR/scip-to-graph.sh" ]]; then
scripts/ast-delta.sh:711:    cache_file_count=$(find "$AST_CACHE_DIR" -name "*.ast" 2>/dev/null | wc -l | tr -d ' ')
scripts/ast-delta.sh:714:    cache_size_kb=$(du -sk "$AST_CACHE_DIR" 2>/dev/null | cut -f1 || echo "0")
scripts/ast-delta.sh:723:    if [[ -f "$GRAPH_DB_PATH" ]]; then
scripts/ast-delta.sh:751:    file_count=$(find "$AST_CACHE_DIR" -name "*.ast" 2>/dev/null | wc -l | tr -d ' ')
scripts/ast-delta.sh:753:    rm -rf "$AST_CACHE_DIR"/*
scripts/ast-delta.sh:756:    rm -f "$VERSION_STAMP_FILE"
scripts/ast-delta.sh:778:    --force-rebuild        Âº∫Âà∂ÊâßË°åÂÖ®ÈáèÈáçÂª∫
scripts/ast-delta.sh:781:    --since <ref>          Git ÂºïÁî®ÔºàÂ¶Ç HEAD~1, mainÔºâ
scripts/ast-delta.sh:803:    ast-delta.sh batch --since HEAD~1
scripts/call-chain-core.sh:38:  if [[ -n "${CKB_UNAVAILABLE:-}" ]]; then
scripts/call-chain-core.sh:43:  if [[ -n "${MOCK_CKB_AVAILABLE:-}" ]]; then
scripts/call-chain-core.sh:61:  call-chain-tracer.sh --symbol "funcName" [ÈÄâÈ°π]
scripts/call-chain-core.sh:64:  --symbol <name>       ÁõÆÊ†áÁ¨¶Âè∑ÂêçÁß∞ÔºàÂøÖÈúÄÔºâ
scripts/call-chain-core.sh:65:  --direction <dir>     ÈÅçÂéÜÊñπÂêë: callers | callees | bothÔºàÈªòËÆ§: bothÔºâ
scripts/call-chain-core.sh:66:  --depth <n>           ÊúÄÂ§ßÈÅçÂéÜÊ∑±Â∫¶ 1-4ÔºàÈªòËÆ§: 2Ôºâ
scripts/call-chain-core.sh:67:  --trace-usage         ËøΩÊ∫Ø‰ªéÂÖ•Âè£Âà∞ÁõÆÊ†áÁöÑË∞ÉÁî®Ë∑ØÂæÑ
scripts/call-chain-core.sh:68:  --trace-data-flow     ËøΩË∏™Êï∞ÊçÆÊµÅÔºöÊòæÁ§∫ÂèÇÊï∞Â¶Ç‰ΩïÂú®ÂáΩÊï∞Èó¥ÊµÅÂä® (AC-006)
scripts/call-chain-core.sh:69:  --data-flow           ÂêØÁî®ÂÆåÊï¥Êï∞ÊçÆÊµÅËøΩË∏™Ê®°Âºè (M3: AC-004)
scripts/call-chain-core.sh:70:  --data-flow-direction <dir>  Êï∞ÊçÆÊµÅËøΩË∏™ÊñπÂêë: forward | backward | bothÔºàÈªòËÆ§: bothÔºâ
scripts/call-chain-core.sh:74:  --file <path>         ÊåáÂÆöÊï∞ÊçÆÊµÅËøΩË∏™ÂÖ•Âè£Êñá‰ª∂Ôºà‰ªÖÊîØÊåÅ TS/JSÔºâ
scripts/call-chain-core.sh:75:  --max-depth <n>       Êï∞ÊçÆÊµÅËøΩË∏™ÊúÄÂ§ßÊ∑±Â∫¶ 1-10ÔºàÈªòËÆ§: 5Ôºâ
scripts/call-chain-core.sh:76:  --include-transforms  Âú®Êï∞ÊçÆÊµÅËøΩË∏™‰∏≠ÂåÖÂê´ËΩ¨Êç¢ËØ¶ÊÉÖ
scripts/call-chain-core.sh:77:  --cwd <path>          Â∑•‰ΩúÁõÆÂΩïÔºàÈªòËÆ§: ÂΩìÂâçÁõÆÂΩïÔºâ
scripts/call-chain-core.sh:78:  --format <text|json|mermaid>  ËæìÂá∫Ê†ºÂºèÔºàÈªòËÆ§: jsonÔºâ
scripts/call-chain-core.sh:79:  --enable-all-features ÂøΩÁï•ÂäüËÉΩÂºÄÂÖ≥ÈÖçÁΩÆÔºåÂº∫Âà∂ÂêØÁî®ÊâÄÊúâÂäüËÉΩ
scripts/call-chain-core.sh:80:  --mock-ckb            ‰ΩøÁî®Ê®°ÊãüÊï∞ÊçÆÔºàÊµãËØïÁî®Ôºâ
scripts/call-chain-core.sh:81:  --version             ÊòæÁ§∫ÁâàÊú¨
scripts/call-chain-core.sh:82:  --help                ÊòæÁ§∫Ê≠§Â∏ÆÂä©
scripts/call-chain-core.sh:119:  call-chain-tracer.sh --symbol "getUserById" --direction callers
scripts/call-chain-core.sh:122:  call-chain-tracer.sh --symbol "processPayment" --direction callees --depth 3
scripts/call-chain-core.sh:125:  call-chain-tracer.sh --symbol "handleError" --trace-usage
scripts/call-chain-core.sh:128:  call-chain-tracer.sh --symbol "userInput" --data-flow --data-flow-direction forward
scripts/call-chain-core.sh:131:  call-chain-tracer.sh --symbol "errorData" --data-flow --data-flow-direction backward --max-depth 10
scripts/call-chain-core.sh:143:  # Workaround: If first arg doesn't start with --, treat it as symbol
scripts/call-chain-core.sh:144:  # This handles cases where --symbol flag is dropped by MCP transport
scripts/call-chain-core.sh:145:  if [[ $# -gt 0 ]] && [[ "$1" != --* ]]; then
scripts/call-chain-core.sh:150:  while [[ $# -gt 0 ]]; do
scripts/call-chain-core.sh:152:      --symbol)
scripts/call-chain-core.sh:156:      --direction)
scripts/call-chain-core.sh:160:      --depth)
scripts/call-chain-core.sh:164:      --trace-usage)
scripts/call-chain-core.sh:168:      --trace-data-flow)
scripts/call-chain-core.sh:172:      --data-flow)
scripts/call-chain-core.sh:177:      --data-flow-direction)
scripts/call-chain-core.sh:182:      --max-depth)
scripts/call-chain-core.sh:187:      --include-transforms)
scripts/call-chain-core.sh:192:      --file)
scripts/call-chain-core.sh:196:      --cwd)
scripts/call-chain-core.sh:201:      --format)
scripts/call-chain-core.sh:205:      --enable-all-features)
scripts/call-chain-core.sh:209:      --mock-ckb)
scripts/call-chain-core.sh:213:      --version)
scripts/call-chain-core.sh:217:      --help|-h)
scripts/call-chain-core.sh:229:  if [ -z "$SYMBOL" ]; then
scripts/call-chain-core.sh:230:    log_error "ÂøÖÈ°ªÊèê‰æõ --symbol ÂèÇÊï∞"
scripts/call-chain-core.sh:239:  elif [ "$DEPTH" -lt 1 ]; then
scripts/call-chain-core.sh:242:  elif [ "$DEPTH" -gt 4 ]; then
scripts/call-chain-core.sh:271:    elif [ "$DATA_FLOW_MAX_DEPTH" -lt 1 ]; then
scripts/call-chain-core.sh:274:    elif [ "$DATA_FLOW_MAX_DEPTH" -gt 10 ]; then
scripts/call-chain-core.sh:280:  if [ -n "$CWD" ] && [ ! -d "$CWD" ]; then
scripts/call-chain-core.sh:293:  if [[ -n "${MOCK_SIMPLE_CYCLE:-}" ]]; then
scripts/call-chain-core.sh:308:  result=$(echo "$result" | jq --arg sym "ckb:test:sym:$symbol" \
scripts/call-chain-core.sh:309:    --arg file "src/${symbol}.ts" \
scripts/call-chain-core.sh:313:  if [[ $depth -ge 1 ]]; then
scripts/call-chain-core.sh:318:  if [[ $depth -ge 2 ]]; then
scripts/call-chain-core.sh:323:  if [[ $depth -ge 3 ]]; then
scripts/call-chain-core.sh:328:  if [[ $depth -ge 4 ]]; then
scripts/cod-visualizer.sh:13:set -euo pipefail
scripts/cod-visualizer.sh:47:    if [[ ! -f "$config_file" ]]; then
scripts/cod-visualizer.sh:78:    if [[ ! -f "$GRAPH_DB_PATH" ]]; then
scripts/cod-visualizer.sh:93:    sqlite3 -json "$GRAPH_DB_PATH" "$sql" 2>/dev/null
scripts/cod-visualizer.sh:115:    if [[ ! -x "$hotspot_script" ]]; then
scripts/cod-visualizer.sh:123:    hotspot_data=$("$hotspot_script" --format json --top 100 2>/dev/null || echo '{"hotspots":[]}')
scripts/cod-visualizer.sh:128:    if command -v jq &>/dev/null; then
scripts/cod-visualizer.sh:130:        file_score=$(echo "$hotspot_data" | jq --arg f "$file_path" '.hotspots[] | select(.file == $f) | .score // 0' 2>/dev/null || echo "0")
scripts/cod-visualizer.sh:132:        if [[ "$max_score" != "0" && "$max_score" != "null" && -n "$file_score" && "$file_score" != "null" ]]; then
scripts/cod-visualizer.sh:133:            normalized=$(awk -v fs="$file_score" -v ms="$max_score" 'BEGIN { printf "%.2f", fs / ms }')
scripts/cod-visualizer.sh:149:    if [[ ! -f "$full_path" ]]; then
scripts/cod-visualizer.sh:153:    if [[ ! -f "$full_path" ]]; then
scripts/cod-visualizer.sh:160:    lines=$(wc -l < "$full_path" 2>/dev/null | tr -d ' ')
scripts/cod-visualizer.sh:161:    if [[ -n "$lines" && "$lines" -gt 0 ]]; then
scripts/cod-visualizer.sh:172:    if awk -v s="$score" -v t="$HOTSPOT_HIGH_THRESHOLD" 'BEGIN { exit !(s > t) }'; then
scripts/cod-visualizer.sh:174:    elif awk -v s="$score" -v t="$HOTSPOT_MED_THRESHOLD" 'BEGIN { exit !(s > t) }'; then
scripts/cod-visualizer.sh:194:    echo "    USER((User)) --> CORE"
scripts/cod-visualizer.sh:195:    echo "    EXT_MCP[MCP Client] --> CORE"
scripts/cod-visualizer.sh:196:    echo "    CORE --> SCRIPTS"
scripts/cod-visualizer.sh:197:    echo "    SCRIPTS --> CONFIG"
scripts/cod-visualizer.sh:210:    timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
scripts/cod-visualizer.sh:252:    if [[ -z "$modules" ]]; then
scripts/cod-visualizer.sh:255:        [[ -d "src" ]] && dirs+=("src")
scripts/cod-visualizer.sh:256:        [[ -d "scripts" ]] && dirs+=("scripts")
scripts/cod-visualizer.sh:257:        [[ -d "hooks" ]] && dirs+=("hooks")
scripts/cod-visualizer.sh:258:        [[ -d "config" ]] && dirs+=("config")
scripts/cod-visualizer.sh:259:        [[ -d "tests" ]] && dirs+=("tests")
scripts/cod-visualizer.sh:261:        if [[ ${#dirs[@]} -eq 0 ]]; then
scripts/cod-visualizer.sh:281:        if [[ -d "src" && -d "scripts" ]]; then
scripts/cod-visualizer.sh:282:            echo "    mod_src --> mod_scripts"
scripts/cod-visualizer.sh:284:        if [[ -d "tests" && -d "src" ]]; then
scripts/cod-visualizer.sh:285:            echo "    mod_tests --> mod_src"
scripts/cod-visualizer.sh:287:        if [[ -d "scripts" && -d "config" ]]; then
scripts/cod-visualizer.sh:288:            echo "    mod_scripts --> mod_config"
scripts/cod-visualizer.sh:293:        while IFS='|' read -r symbol file_path; do
scripts/cod-visualizer.sh:294:            [[ -z "$symbol" ]] && continue
scripts/cod-visualizer.sh:327:        if [[ -n "$edges" ]]; then
scripts/cod-visualizer.sh:329:            while IFS='|' read -r source target edge_type; do
scripts/cod-visualizer.sh:330:                [[ -z "$source" || -z "$target" ]] && continue
scripts/cod-visualizer.sh:334:                echo "    $src_id --> $tgt_id"
scripts/cod-visualizer.sh:344:        if [[ -d "scripts" ]]; then
scripts/cod-visualizer.sh:355:    timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
scripts/cod-visualizer.sh:367:        if [[ -n "$modules" ]]; then
scripts/cod-visualizer.sh:369:            while IFS='|' read -r symbol file_path; do
scripts/cod-visualizer.sh:370:                [[ -z "$symbol" ]] && continue
scripts/cod-visualizer.sh:388:            if [[ ${#nodes_arr[@]} -gt 0 ]]; then
scripts/cod-visualizer.sh:389:                nodes_json=$(printf '%s\n' "${nodes_arr[@]}" | paste -sd ',' -)
scripts/cod-visualizer.sh:405:        if [[ -n "$edges" ]]; then
scripts/cod-visualizer.sh:407:            while IFS='|' read -r source target edge_type; do
scripts/cod-visualizer.sh:408:                [[ -z "$source" || -z "$target" ]] && continue
scripts/cod-visualizer.sh:413:            if [[ ${#links_arr[@]} -gt 0 ]]; then
scripts/cod-visualizer.sh:414:                links_json=$(printf '%s\n' "${links_arr[@]}" | paste -sd ',' -)
scripts/cod-visualizer.sh:423:        [[ -d "src" ]] && dirs+=("src")
scripts/cod-visualizer.sh:424:        [[ -d "scripts" ]] && dirs+=("scripts")
scripts/cod-visualizer.sh:425:        [[ -d "hooks" ]] && dirs+=("hooks")
scripts/cod-visualizer.sh:426:        [[ -d "config" ]] && dirs+=("config")
scripts/cod-visualizer.sh:427:        [[ -d "tests" ]] && dirs+=("tests")
scripts/cod-visualizer.sh:429:        if [[ ${#dirs[@]} -eq 0 ]]; then
scripts/cod-visualizer.sh:450:        nodes_json=$(printf '%s\n' "${nodes_arr[@]}" | paste -sd ',' -)
scripts/cod-visualizer.sh:455:        if [[ -d "src" && -d "scripts" ]]; then
scripts/cod-visualizer.sh:459:        if [[ -d "tests" && -d "src" ]]; then
scripts/cod-visualizer.sh:463:        if [[ ${#links_arr[@]} -gt 0 ]]; then
scripts/cod-visualizer.sh:464:            links_json=$(printf '%s\n' "${links_arr[@]}" | paste -sd ',' -)
scripts/cod-visualizer.sh:502:    if [[ -z "$files" ]]; then
scripts/cod-visualizer.sh:503:        if [[ -d "$module_path" ]]; then
scripts/cod-visualizer.sh:504:            files=$(find "$module_path" -maxdepth 2 -type f \( -name "*.sh" -o -name "*.ts" -o -name "*.js" -o -name "*.py" \) 2>/dev/null | head -20)
scripts/cod-visualizer.sh:506:            if [[ -z "$files" ]]; then
scripts/cod-visualizer.sh:515:            while IFS= read -r file; do
scripts/cod-visualizer.sh:516:                [[ -z "$file" ]] && continue
scripts/cod-visualizer.sh:540:        while IFS='|' read -r symbol file_path; do
scripts/cod-visualizer.sh:541:            [[ -z "$symbol" ]] && continue
scripts/cod-visualizer.sh:570:        if [[ -n "$edges" ]]; then
scripts/cod-visualizer.sh:572:            while IFS='|' read -r source target edge_type; do
scripts/cod-visualizer.sh:573:                [[ -z "$source" || -z "$target" ]] && continue
scripts/cod-visualizer.sh:577:                echo "    $src_id --> $tgt_id"
scripts/cod-visualizer.sh:588:            while IFS='|' read -r symbol file_path; do
scripts/cod-visualizer.sh:589:                [[ -z "$file_path" ]] && continue
scripts/cod-visualizer.sh:610:    timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
scripts/cod-visualizer.sh:625:        if [[ -n "$files" ]]; then
scripts/cod-visualizer.sh:627:            while IFS='|' read -r symbol file_path; do
scripts/cod-visualizer.sh:628:                [[ -z "$symbol" ]] && continue
scripts/cod-visualizer.sh:645:            if [[ ${#nodes_arr[@]} -gt 0 ]]; then
scripts/cod-visualizer.sh:646:                nodes_json=$(printf '%s\n' "${nodes_arr[@]}" | paste -sd ',' -)
scripts/cod-visualizer.sh:664:        if [[ -n "$edges" ]]; then
scripts/cod-visualizer.sh:666:            while IFS='|' read -r source target edge_type; do
scripts/cod-visualizer.sh:667:                [[ -z "$source" || -z "$target" ]] && continue
scripts/cod-visualizer.sh:672:            if [[ ${#links_arr[@]} -gt 0 ]]; then
scripts/cod-visualizer.sh:673:                links_json=$(printf '%s\n' "${links_arr[@]}" | paste -sd ',' -)
scripts/cod-visualizer.sh:681:        if [[ -d "$module_path" ]]; then
scripts/cod-visualizer.sh:683:            file_list=$(find "$module_path" -maxdepth 2 -type f \( -name "*.sh" -o -name "*.ts" -o -name "*.js" -o -name "*.py" \) 2>/dev/null | head -20)
scripts/cod-visualizer.sh:685:            if [[ -n "$file_list" ]]; then
scripts/cod-visualizer.sh:687:                while IFS= read -r file; do
scripts/cod-visualizer.sh:688:                    [[ -z "$file" ]] && continue
scripts/cod-visualizer.sh:707:                if [[ ${#nodes_arr[@]} -gt 0 ]]; then
scripts/cod-visualizer.sh:708:                    nodes_json=$(printf '%s\n' "${nodes_arr[@]}" | paste -sd ',' -)
scripts/cod-visualizer.sh:739:    while [[ $# -gt 0 ]]; do
scripts/cod-visualizer.sh:741:            --level)
scripts/cod-visualizer.sh:745:            --format)
scripts/cod-visualizer.sh:749:            --include-hotspots)
scripts/cod-visualizer.sh:753:            --include-complexity)
scripts/cod-visualizer.sh:757:            --output)
scripts/cod-visualizer.sh:779:    if [[ "$format" == "mermaid" && -z "$output_file" ]]; then
scripts/cod-visualizer.sh:810:    if [[ -n "$output_file" ]]; then
scripts/cod-visualizer.sh:828:    while [[ $# -gt 0 ]]; do
scripts/cod-visualizer.sh:830:            --format)
scripts/cod-visualizer.sh:834:            --include-hotspots)
scripts/cod-visualizer.sh:838:            --include-complexity)
scripts/cod-visualizer.sh:842:            --output)
scripts/cod-visualizer.sh:850:                if [[ -z "$module_path" ]]; then
scripts/cod-visualizer.sh:858:    if [[ -z "$module_path" ]]; then
scripts/cod-visualizer.sh:883:    if [[ -n "$output_file" ]]; then
scripts/cod-visualizer.sh:905:    --level <1|2|3>         ÂèØËßÜÂåñÂ±ÇÁ∫ßÔºàÈªòËÆ§: 2Ôºâ
scripts/cod-visualizer.sh:909:    --format <format>       ËæìÂá∫Ê†ºÂºèÔºàÈªòËÆ§: mermaidÔºâ
scripts/cod-visualizer.sh:912:    --include-hotspots      ÂåÖÂê´ÁÉ≠ÁÇπÁùÄËâ≤
scripts/cod-visualizer.sh:913:    --include-complexity    ÂåÖÂê´Â§çÊùÇÂ∫¶Ê†áÊ≥®
scripts/cod-visualizer.sh:914:    --output <file>         ËæìÂá∫Âà∞Êñá‰ª∂
scripts/cod-visualizer.sh:917:    --format <format>       ËæìÂá∫Ê†ºÂºèÔºàÈªòËÆ§: mermaidÔºâ
scripts/cod-visualizer.sh:918:    --include-hotspots      ÂåÖÂê´ÁÉ≠ÁÇπÁùÄËâ≤
scripts/cod-visualizer.sh:919:    --include-complexity    ÂåÖÂê´Â§çÊùÇÂ∫¶Ê†áÊ≥®
scripts/cod-visualizer.sh:920:    --output <file>         ËæìÂá∫Âà∞Êñá‰ª∂
scripts/cod-visualizer.sh:929:    cod-visualizer.sh generate --level 2 --format mermaid
scripts/cod-visualizer.sh:932:    cod-visualizer.sh generate --level 2 --format d3json --include-hotspots
scripts/cod-visualizer.sh:935:    cod-visualizer.sh module scripts/ --format d3json
scripts/cod-visualizer.sh:938:    cod-visualizer.sh generate --level 2 --format mermaid --output arch.mmd
scripts/performance-regression.sh:5:#   performance-regression.sh --baseline <baseline.json> --current <current.json>
scripts/performance-regression.sh:11:set -euo pipefail
scripts/performance-regression.sh:24:  if [[ -n "${DEVBOOKS_ENABLE_ALL_FEATURES:-}" ]]; then
scripts/performance-regression.sh:28:  if [[ ! -f "$FEATURES_CONFIG_FILE" ]]; then
scripts/performance-regression.sh:33:  value=$(awk -v feature="$feature" '
scripts/performance-regression.sh:60:  performance-regression.sh --baseline <baseline.json> --current <current.json>
scripts/performance-regression.sh:63:  --baseline <file>          Âü∫Á∫øÊä•Âëä
scripts/performance-regression.sh:64:  --current <file>           ÂΩìÂâçÊä•Âëä
scripts/performance-regression.sh:65:  --enable-all-features      ÂøΩÁï•ÂäüËÉΩÂºÄÂÖ≥ÈÖçÁΩÆÔºåÂº∫Âà∂ÂêØÁî®ÊâÄÊúâÂäüËÉΩ
scripts/performance-regression.sh:66:  --help                     ÊòæÁ§∫Â∏ÆÂä©
scripts/performance-regression.sh:72:  if [[ -z "$file" || ! -f "$file" ]]; then
scripts/performance-regression.sh:87:  while [[ $# -gt 0 ]]; do
scripts/performance-regression.sh:89:      --baseline)
scripts/performance-regression.sh:93:      --current)
scripts/performance-regression.sh:97:      --enable-all-features)
scripts/performance-regression.sh:101:      --help|-h)
scripts/performance-regression.sh:116:  if [[ -z "$baseline" || -z "$current" ]]; then
scripts/performance-regression.sh:125:  base_mrr=$(jq -r '.mrr_at_10 // 0' "$baseline")
scripts/performance-regression.sh:126:  base_p95=$(jq -r '.p95_latency_ms // 0' "$baseline")
scripts/performance-regression.sh:127:  curr_mrr=$(jq -r '.mrr_at_10 // 0' "$current")
scripts/performance-regression.sh:128:  curr_p95=$(jq -r '.p95_latency_ms // 0' "$current")
scripts/performance-regression.sh:131:  mrr_threshold=$(awk -v base="$base_mrr" 'BEGIN {printf "%.6f", base * 0.95}')
scripts/performance-regression.sh:132:  p95_threshold=$(awk -v base="$base_p95" 'BEGIN {printf "%.2f", base * 1.10}')
scripts/performance-regression.sh:135:  if awk -v curr="$curr_mrr" -v thr="$mrr_threshold" 'BEGIN {exit !(curr < thr)}'; then
scripts/performance-regression.sh:138:  if awk -v curr="$curr_p95" -v thr="$p95_threshold" 'BEGIN {exit !(curr > thr)}'; then
scripts/bug-locator.sh:12:#   bug-locator.sh --error "ÈîôËØØ‰ø°ÊÅØ" [ÈÄâÈ°π]
scripts/bug-locator.sh:18:set -euo pipefail
scripts/bug-locator.sh:28:if [ -f "$COMMON_LIB" ]; then
scripts/bug-locator.sh:39:  log_info()  { echo -e "${BLUE}[BugLocator]${NC} $1" >&2; }
scripts/bug-locator.sh:40:  log_ok()    { echo -e "${GREEN}[BugLocator]${NC} $1" >&2; }
scripts/bug-locator.sh:41:  log_warn()  { echo -e "${YELLOW}[BugLocator]${NC} $1" >&2; }
scripts/bug-locator.sh:42:  log_error() { echo -e "${RED}[BugLocator]${NC} $1" >&2; }
scripts/bug-locator.sh:52:if declare -f check_dependencies &>/dev/null; then
scripts/bug-locator.sh:55:  command -v jq &>/dev/null || { log_error "Áº∫Â∞ë‰æùËµñ: jq"; exit 2; }
scripts/bug-locator.sh:90:  if declare -f get_feature_value &>/dev/null; then
scripts/bug-locator.sh:93:    if [ -n "$w" ]; then
scripts/bug-locator.sh:111:  bug-locator.sh --error "ÈîôËØØ‰ø°ÊÅØ" [ÈÄâÈ°π]
scripts/bug-locator.sh:114:  --error <text>        ÈîôËØØ‰ø°ÊÅØÔºàÂøÖÈúÄÔºâ
scripts/bug-locator.sh:115:  --top-n <n>           ËøîÂõûÂÄôÈÄâÊï∞ÈáèÔºàÈªòËÆ§: 5Ôºâ
scripts/bug-locator.sh:116:  --history-depth <d>   Git ÂéÜÂè≤Â§©Êï∞ÔºàÈªòËÆ§: 30Ôºâ
scripts/bug-locator.sh:117:  --cwd <path>          Â∑•‰ΩúÁõÆÂΩïÔºàÈªòËÆ§: ÂΩìÂâçÁõÆÂΩïÔºâ
scripts/bug-locator.sh:118:  --format <text|json>  ËæìÂá∫Ê†ºÂºèÔºàÈªòËÆ§: jsonÔºâ
scripts/bug-locator.sh:119:  --with-impact         ÂêØÁî®ÂΩ±ÂìçÂàÜÊûêËûçÂêàÔºàAC-G08Ôºâ
scripts/bug-locator.sh:120:  --impact-depth <n>    ÂΩ±ÂìçÂàÜÊûêÊ∑±Â∫¶ÔºàÈªòËÆ§: 3Ôºâ
scripts/bug-locator.sh:121:  --version             ÊòæÁ§∫ÁâàÊú¨
scripts/bug-locator.sh:122:  --help                ÊòæÁ§∫Ê≠§Â∏ÆÂä©
scripts/bug-locator.sh:165:  bug-locator.sh --error "TypeError: Cannot read property 'id' of undefined"
scripts/bug-locator.sh:168:  bug-locator.sh --error "NullPointerException at User.getName" --history-depth 60
scripts/bug-locator.sh:171:  bug-locator.sh --error "Error in payment processing" --format text
scripts/bug-locator.sh:174:  bug-locator.sh --error "authentication error" --with-impact --impact-depth 3
scripts/bug-locator.sh:186:  while [[ $# -gt 0 ]]; do
scripts/bug-locator.sh:188:      --error)
scripts/bug-locator.sh:192:      --top-n)
scripts/bug-locator.sh:196:      --history-depth)
scripts/bug-locator.sh:200:      --cwd)
scripts/bug-locator.sh:205:      --format)
scripts/bug-locator.sh:209:      --with-impact)
scripts/bug-locator.sh:213:      --impact-depth)
scripts/bug-locator.sh:217:      --version)
scripts/bug-locator.sh:221:      --help|-h)
scripts/bug-locator.sh:233:  if [ -z "$ERROR_INFO" ]; then
scripts/bug-locator.sh:234:    log_error "ÂøÖÈ°ªÊèê‰æõ --error ÂèÇÊï∞"
scripts/bug-locator.sh:253:  file_matches=$(echo "$error" | grep -oE '[a-zA-Z0-9_/.-]+\.(ts|tsx|js|jsx|py|go|java|rs):[0-9]+' | head -10)
scripts/bug-locator.sh:255:  while IFS= read -r match; do
scripts/bug-locator.sh:256:    [ -z "$match" ] && continue
scripts/bug-locator.sh:258:    file_path=$(echo "$match" | cut -d: -f1)
scripts/bug-locator.sh:259:    line=$(echo "$match" | cut -d: -f2)
scripts/bug-locator.sh:261:    files=$(echo "$files" | jq --arg f "$file_path" --argjson l "$line" \
scripts/bug-locator.sh:272:  symbol_matches=$(echo "$error" | grep -oE '\b[a-zA-Z][a-zA-Z0-9]*[A-Z][a-zA-Z0-9]*\b' | head -10)
scripts/bug-locator.sh:274:  while IFS= read -r sym; do
scripts/bug-locator.sh:275:    [ -z "$sym" ] && continue
scripts/bug-locator.sh:276:    symbols=$(echo "$symbols" | jq --arg s "$sym" '. + [$s]')
scripts/bug-locator.sh:281:  snake_matches=$(echo "$error" | grep -oE '\b[a-z]+_[a-z_]+\b' | head -5)
scripts/bug-locator.sh:283:  while IFS= read -r sym; do
scripts/bug-locator.sh:284:    [ -z "$sym" ] && continue
scripts/bug-locator.sh:285:    symbols=$(echo "$symbols" | jq --arg s "$sym" '. + [$s]')
scripts/bug-locator.sh:290:  quoted_matches=$(echo "$error" | grep -oE "'[a-zA-Z_][a-zA-Z0-9_]*'" | tr -d "'" | head -5)
scripts/bug-locator.sh:292:  while IFS= read -r sym; do
scripts/bug-locator.sh:293:    [ -z "$sym" ] && continue
scripts/bug-locator.sh:294:    symbols=$(echo "$symbols" | jq --arg s "$sym" '. + [$s]')
scripts/bug-locator.sh:301:  jq -n --argjson symbols "$symbols" --argjson files "$files" \
scripts/bug-locator.sh:317:  file_path=$(echo "$node" | jq -r '.file_path // empty')
scripts/bug-locator.sh:319:  line=$(echo "$node" | jq -r '.line // 0')
scripts/bug-locator.sh:321:  if [ -n "$file_path" ] && [ "$file_path" != "null" ]; then
scripts/bug-locator.sh:324:    if declare -f float_calc &>/dev/null; then
scripts/bug-locator.sh:331:      --arg f "$file_path" \
scripts/bug-locator.sh:332:      --argjson l "$line" \
scripts/bug-locator.sh:333:      --argjson score "$distance_score" \
scripts/bug-locator.sh:363:  if [ ! -x "$call_chain_tool" ]; then
scripts/bug-locator.sh:374:    symbol=$(echo "$symbols_json" | jq -r ".symbols[$i]")
scripts/bug-locator.sh:378:    chain_result=$("$call_chain_tool" --symbol "$symbol" --depth 2 --cwd "$CWD" 2>/dev/null || echo '{}')
scripts/bug-locator.sh:400:    file_path=$(echo "$symbols_json" | jq -r ".files[$i].file_path")
scripts/bug-locator.sh:401:    line=$(echo "$symbols_json" | jq -r ".files[$i].line")
scripts/bug-locator.sh:404:      --arg f "$file_path" \
scripts/bug-locator.sh:405:      --argjson l "$line" \
scripts/bug-locator.sh:419:  if [ ! -d "$CWD/.git" ]; then
scripts/bug-locator.sh:426:  recent_files=$(git -C "$CWD" log \
scripts/bug-locator.sh:427:    --since="${HISTORY_DEPTH} days ago" \
scripts/bug-locator.sh:428:    --name-only \
scripts/bug-locator.sh:429:    --pretty=format: \
scripts/bug-locator.sh:430:    --max-count=500 \
scripts/bug-locator.sh:431:    2>/dev/null | grep -v '^$' | sort | uniq -c | sort -rn)
scripts/bug-locator.sh:435:  max_changes=$(echo "$recent_files" | head -1 | awk '{print $1}')
scripts/bug-locator.sh:436:  [ -z "$max_changes" ] && max_changes=1
scripts/bug-locator.sh:447:    file_path=$(echo "$candidate" | jq -r '.file_path')
scripts/bug-locator.sh:451:    changes=$(echo "$recent_files" | grep -E "\s${file_path}$" | awk '{print $1}' | head -1)
scripts/bug-locator.sh:452:    [ -z "$changes" ] && changes=0
scripts/bug-locator.sh:456:    if declare -f float_calc &>/dev/null; then
scripts/bug-locator.sh:462:    candidate=$(echo "$candidate" | jq --argjson score "$history_score" '. + {history_score: $score}')
scripts/bug-locator.sh:463:    result=$(echo "$result" | jq --argjson c "$candidate" '. + [$c]')
scripts/bug-locator.sh:474:  if [ ! -d "$CWD/.git" ]; then
scripts/bug-locator.sh:481:  if declare -f is_feature_enabled &>/dev/null; then
scripts/bug-locator.sh:486:  if [ "$hotspot_enabled" = true ] && [ -x "$HOTSPOT_ANALYZER" ]; then
scripts/bug-locator.sh:488:    hotspot_result=$("$HOTSPOT_ANALYZER" --format json --path "$CWD" --top 20 --days "$HISTORY_DEPTH" 2>/dev/null) || true
scripts/bug-locator.sh:491:    if echo "$hotspot_result" | jq -e '.hotspots' >/dev/null 2>&1; then
scripts/bug-locator.sh:514:  freq_data=$(git -C "$CWD" log \
scripts/bug-locator.sh:515:    --since="${HISTORY_DEPTH} days ago" \
scripts/bug-locator.sh:516:    --name-only \
scripts/bug-locator.sh:517:    --pretty=format: \
scripts/bug-locator.sh:518:    --max-count=200 \
scripts/bug-locator.sh:520:    grep -v '^$' | \
scripts/bug-locator.sh:521:    grep -vE 'node_modules|dist|build|\.lock|\.md$|\.json$|__pycache__|\.pyc$' | \
scripts/bug-locator.sh:522:    sort | uniq -c | sort -rn | head -20) || true
scripts/bug-locator.sh:526:  while IFS= read -r line; do
scripts/bug-locator.sh:527:    [ -z "$line" ] && continue
scripts/bug-locator.sh:533:    if [ "$count" -ge 3 ]; then
scripts/bug-locator.sh:534:      hotspots=$(echo "$hotspots" | jq --arg f "$file" --argjson c "$count" \
scripts/bug-locator.sh:555:  [ -z "$max_score" ] || [ "$max_score" = "null" ] && max_score=1
scripts/bug-locator.sh:561:    file_path=$(echo "$candidate" | jq -r '.file_path')
scripts/bug-locator.sh:566:    hotspot_entry=$(echo "$hotspots_json" | jq --arg f "$file_path" '.[] | select(.file_path == $f)')
scripts/bug-locator.sh:568:    if [ -n "$hotspot_entry" ] && [ "$hotspot_entry" != "null" ]; then
scripts/bug-locator.sh:570:      raw_score=$(echo "$hotspot_entry" | jq -r '.score // 0')
scripts/bug-locator.sh:574:      if declare -f float_calc &>/dev/null; then
scripts/bug-locator.sh:581:        [ "$(echo "$hotspot_score > 1" | bc 2>/dev/null || echo 0)" -eq 1 ] && hotspot_score=1.0
scripts/bug-locator.sh:589:      --argjson is_hot "$is_hotspot" \
scripts/bug-locator.sh:590:      --argjson score "$hotspot_score" \
scripts/bug-locator.sh:593:    result=$(echo "$result" | jq --argjson c "$candidate" '. + [$c]')
scripts/bug-locator.sh:612:  if echo "$error" | grep -qiE "TypeError|undefined|null"; then
scripts/bug-locator.sh:614:  elif echo "$error" | grep -qiE "SyntaxError|parse"; then
scripts/bug-locator.sh:616:  elif echo "$error" | grep -qiE "ReferenceError|not defined"; then
scripts/bug-locator.sh:618:  elif echo "$error" | grep -qiE "NetworkError|fetch|request"; then
scripts/bug-locator.sh:620:  elif echo "$error" | grep -qiE "AuthError|unauthorized|forbidden"; then
scripts/bug-locator.sh:628:    file_path=$(echo "$candidate" | jq -r '.file_path')
scripts/bug-locator.sh:636:        if echo "$file_path" | grep -qiE "types?|model|data|util"; then
scripts/bug-locator.sh:641:        if echo "$file_path" | grep -qiE "auth|login|user|session"; then
scripts/bug-locator.sh:646:        if echo "$file_path" | grep -qiE "api|fetch|request|http|client"; then
scripts/bug-locator.sh:652:    candidate=$(echo "$candidate" | jq --argjson score "$error_pattern_score" \
scripts/bug-locator.sh:655:    result=$(echo "$result" | jq --argjson c "$candidate" '. + [$c]')
scripts/bug-locator.sh:675:    call_chain_score=$(echo "$candidate" | jq -r '.call_chain_score // 0')
scripts/bug-locator.sh:676:    history_score=$(echo "$candidate" | jq -r '.history_score // 0')
scripts/bug-locator.sh:677:    hotspot_score=$(echo "$candidate" | jq -r '.hotspot_score // 0')
scripts/bug-locator.sh:678:    error_pattern_score=$(echo "$candidate" | jq -r '.error_pattern_score // 0.5')
scripts/bug-locator.sh:683:    if declare -f float_calc &>/dev/null; then
scripts/bug-locator.sh:692:    if declare -f float_calc &>/dev/null; then
scripts/bug-locator.sh:703:    [ "$(echo "$candidate" | jq -r '.is_hotspot')" = "true" ] && reasons+=("ÁÉ≠ÁÇπÊñá‰ª∂")
scripts/bug-locator.sh:710:      --argjson conf "$confidence" \
scripts/bug-locator.sh:711:      --arg reason "$reason" \
scripts/bug-locator.sh:714:    result=$(echo "$result" | jq --argjson c "$candidate" '. + [$c]')
scripts/bug-locator.sh:727:  if declare -f hash_string_md5 &>/dev/null; then
scripts/bug-locator.sh:729:  elif command -v md5sum &>/dev/null; then
scripts/bug-locator.sh:730:    printf '%s' "$key_input" | md5sum | cut -d' ' -f1
scripts/bug-locator.sh:731:  elif command -v md5 &>/dev/null; then
scripts/bug-locator.sh:732:    if md5 -q /dev/null >/dev/null 2>&1; then
scripts/bug-locator.sh:733:      printf '%s' "$key_input" | md5 -q
scripts/bug-locator.sh:738:    printf '%s' "$key_input" | cksum | cut -d' ' -f1
scripts/bug-locator.sh:754:    if [[ -f "$candidate" ]]; then
scripts/bug-locator.sh:773:  if [[ ! -x "$CACHE_MANAGER" ]]; then
scripts/bug-locator.sh:782:  cache_result=$("$CACHE_MANAGER" --get "$cache_anchor" --query "$query_hash" 2>/dev/null)
scripts/bug-locator.sh:784:  if [[ -n "$cache_result" ]] && echo "$cache_result" | jq -e '.candidates' &>/dev/null; then
scripts/bug-locator.sh:804:  if [[ ! -x "$CACHE_MANAGER" ]]; then
scripts/bug-locator.sh:812:  "$CACHE_MANAGER" --set "$cache_anchor" --query "$query_hash" --value "$result" 2>/dev/null || true
scripts/bug-locator.sh:840:  if [ -z "$candidates" ] || [ "$candidates" = "[]" ]; then
scripts/bug-locator.sh:872:    line=$(echo "$candidate" | jq -r '.line // 1')
scripts/bug-locator.sh:877:    [ "$line_start" -lt 1 ] && line_start=1
scripts/bug-locator.sh:881:      --argjson start "$line_start" \
scripts/bug-locator.sh:882:      --argjson end "$line_end" \
scripts/bug-locator.sh:885:    final=$(echo "$final" | jq --argjson c "$candidate" '. + [$c]')
scripts/bug-locator.sh:890:  result=$(jq -n \
scripts/bug-locator.sh:891:    --arg version "1.0" \
scripts/bug-locator.sh:892:    --argjson candidates "$final" \
scripts/bug-locator.sh:925:  if [[ ! -x "$IMPACT_ANALYZER" ]]; then
scripts/bug-locator.sh:934:  if [[ -n "$symbol_id" && "$symbol_id" != "null" ]]; then
scripts/bug-locator.sh:937:  elif [[ -n "$file_path" && "$file_path" != "null" ]]; then
scripts/bug-locator.sh:949:  if [[ -x "$CACHE_MANAGER" ]]; then
scripts/bug-locator.sh:953:    if [[ -n "$cached_result" ]] && echo "$cached_result" | jq -e '.' >/dev/null 2>&1; then
scripts/bug-locator.sh:965:  if command -v timeout &>/dev/null; then
scripts/bug-locator.sh:967:  elif command -v gtimeout &>/dev/null; then
scripts/bug-locator.sh:977:    if [[ -n "$timeout_cmd" ]]; then
scripts/bug-locator.sh:978:      impact_result=$($timeout_cmd "$IMPACT_ANALYZER" analyze "$analysis_target" --depth "$depth" --format json 2>/dev/null) || true
scripts/bug-locator.sh:980:      impact_result=$("$IMPACT_ANALYZER" analyze "$analysis_target" --depth "$depth" --format json 2>/dev/null) || true
scripts/bug-locator.sh:984:    if [[ -n "$timeout_cmd" ]]; then
scripts/bug-locator.sh:985:      impact_result=$($timeout_cmd "$IMPACT_ANALYZER" file "$analysis_target" --depth "$depth" --format json 2>/dev/null) || true
scripts/bug-locator.sh:987:      impact_result=$("$IMPACT_ANALYZER" file "$analysis_target" --depth "$depth" --format json 2>/dev/null) || true
scripts/bug-locator.sh:992:  if [[ -z "$impact_result" ]] || ! echo "$impact_result" | jq -e '.' >/dev/null 2>&1; then
scripts/bug-locator.sh:1000:  if [[ -x "$CACHE_MANAGER" ]]; then
scripts/bug-locator.sh:1027:    file_path=$(echo "$candidate" | jq -r '.file_path // .file // ""')
scripts/bug-locator.sh:1028:    symbol_id=$(echo "$candidate" | jq -r '.symbol // ""')
scripts/bug-locator.sh:1029:    original_score=$(echo "$candidate" | jq -r '.confidence // .score // 0')
scripts/bug-locator.sh:1032:    if [[ $i -lt $top_n ]]; then
scripts/bug-locator.sh:1036:      if [[ -n "$impact_result" && "$impact_result" != '{}' ]]; then
scripts/bug-locator.sh:1039:        total_affected=$(echo "$impact_result" | jq -r '.total_affected // 0')
scripts/bug-locator.sh:1040:        max_depth=$(echo "$impact_result" | jq -r '.depth // 3')
scripts/bug-locator.sh:1044:        [[ "$affected_files" == "null" || -z "$affected_files" ]] && affected_files='[]'
scripts/bug-locator.sh:1048:        if declare -f float_calc &>/dev/null; then
scripts/bug-locator.sh:1056:          [[ $(echo "$normalized_impact > 1" | bc 2>/dev/null || echo 0) -eq 1 ]] && normalized_impact="1.0"
scripts/bug-locator.sh:1063:        if declare -f float_calc &>/dev/null; then
scripts/bug-locator.sh:1071:          --argjson total_affected "$total_affected" \
scripts/bug-locator.sh:1072:          --argjson affected_files "$affected_files" \
scripts/bug-locator.sh:1073:          --argjson max_depth "$max_depth" \
scripts/bug-locator.sh:1074:          --argjson impact_score "$impact_score" \
scripts/bug-locator.sh:1075:          --argjson original_score "$original_score" \
scripts/bug-locator.sh:1076:          --argjson final_score "$final_score" \
scripts/bug-locator.sh:1090:          --argjson original_score "$original_score" \
scripts/bug-locator.sh:1096:        --argjson original_score "$original_score" \
scripts/bug-locator.sh:1100:    result=$(echo "$result" | jq --argjson c "$candidate" '. + [$c]')
scripts/bug-locator.sh:1126:      file_path=$(echo "$candidate" | jq -r '.file_path')
scripts/bug-locator.sh:1127:      confidence=$(echo "$candidate" | jq -r '.confidence')
scripts/bug-locator.sh:1128:      reason=$(echo "$candidate" | jq -r '.reason')
scripts/bug-locator.sh:1129:      is_hotspot=$(echo "$candidate" | jq -r '.is_hotspot')
scripts/bug-locator.sh:1130:      line_range=$(echo "$candidate" | jq -r '.line_range | "\(.[0])-\(.[1])"')
scripts/bug-locator.sh:1161:    result=$(echo "$result" | jq --argjson enhanced "$enhanced_candidates" '.candidates = $enhanced')
scripts/intent-learner.sh:11:#   context save --query <q> --symbols <s1,s2>              - ‰øùÂ≠òÂØπËØù‰∏ä‰∏ãÊñá
scripts/intent-learner.sh:13:#   context apply-weight --results <json>                   - Â∫îÁî®ÂØπËØùËøûÁª≠ÊÄßÂä†ÊùÉ
scripts/intent-learner.sh:44:set -euo pipefail
scripts/intent-learner.sh:110:    if [[ ! -d "$dir" ]]; then
scripts/intent-learner.sh:111:        mkdir -p "$dir"
scripts/intent-learner.sh:125:    if [[ ! -f "$INTENT_HISTORY_PATH" ]]; then
scripts/intent-learner.sh:131:    if [[ ! -s "$INTENT_HISTORY_PATH" ]]; then
scripts/intent-learner.sh:190:    cleaned=$(echo "$history" | jq --argjson cutoff "$cutoff" '
scripts/intent-learner.sh:205:    if [[ "$count" -gt "$INTENT_MAX_ENTRIES" ]]; then
scripts/intent-learner.sh:211:        trimmed=$(echo "$history" | jq --argjson max "$INTENT_MAX_ENTRIES" '
scripts/intent-learner.sh:224:    if command -v uuidgen &>/dev/null; then
scripts/intent-learner.sh:235:    date -u +"%Y-%m-%dT%H:%M:%SZ"
scripts/intent-learner.sh:242:    if [[ ! -d "$dir" ]]; then
scripts/intent-learner.sh:243:        mkdir -p "$dir"
scripts/intent-learner.sh:255:    jq -n \
scripts/intent-learner.sh:256:        --arg session_id "$session_id" \
scripts/intent-learner.sh:257:        --arg started_at "$started_at" \
scripts/intent-learner.sh:273:    if [[ ! -f "$CONVERSATION_CONTEXT_PATH" ]]; then
scripts/intent-learner.sh:274:        jq -n '{
scripts/intent-learner.sh:284:    if [[ ! -s "$CONVERSATION_CONTEXT_PATH" ]]; then
scripts/intent-learner.sh:285:        jq -n '{
scripts/intent-learner.sh:297:        jq -n '{
scripts/intent-learner.sh:321:# ÂèÇÊï∞: --query <q> --symbols <s1,s2> [--query-type <type>] [--results-count <n>]
scripts/intent-learner.sh:329:    while [[ $# -gt 0 ]]; do
scripts/intent-learner.sh:331:            --query)
scripts/intent-learner.sh:335:            --symbols)
scripts/intent-learner.sh:339:            --query-type)
scripts/intent-learner.sh:343:            --results-count)
scripts/intent-learner.sh:353:    if [[ -z "$query" ]]; then
scripts/intent-learner.sh:354:        log_error "Áº∫Â∞ëÂøÖÈúÄÂèÇÊï∞: --query"
scripts/intent-learner.sh:364:    session_id=$(echo "$context" | jq -r '.session_id // empty')
scripts/intent-learner.sh:365:    if [[ -z "$session_id" ]]; then
scripts/intent-learner.sh:370:            --arg session_id "$session_id" \
scripts/intent-learner.sh:371:            --arg started_at "$started_at" \
scripts/intent-learner.sh:385:    if [[ -n "$symbols" ]]; then
scripts/intent-learner.sh:386:        symbols_array=$(echo "$symbols" | tr ',' '\n' | jq -R . | jq -s .)
scripts/intent-learner.sh:393:    new_turn=$(jq -n \
scripts/intent-learner.sh:394:        --argjson turn "$next_turn" \
scripts/intent-learner.sh:395:        --arg timestamp "$timestamp" \
scripts/intent-learner.sh:396:        --arg query "$query" \
scripts/intent-learner.sh:397:        --arg query_type "$query_type" \
scripts/intent-learner.sh:398:        --argjson focus_symbols "$symbols_array" \
scripts/intent-learner.sh:399:        --argjson results_count "$results_count" \
scripts/intent-learner.sh:410:    context=$(echo "$context" | jq --argjson new_turn "$new_turn" '
scripts/intent-learner.sh:415:    context=$(echo "$context" | jq --argjson symbols "$symbols_array" '
scripts/intent-learner.sh:422:    context=$(echo "$context" | jq --argjson max "$max_turns" '
scripts/intent-learner.sh:433:    context=$(echo "$context" | jq --argjson max "$max_focus" '
scripts/intent-learner.sh:451:# ÂèÇÊï∞: --results <json>
scripts/intent-learner.sh:456:    while [[ $# -gt 0 ]]; do
scripts/intent-learner.sh:458:            --results)
scripts/intent-learner.sh:468:    if [[ -z "$results_json" ]]; then
scripts/intent-learner.sh:469:        log_error "Áº∫Â∞ëÂøÖÈúÄÂèÇÊï∞: --results"
scripts/intent-learner.sh:481:    if [[ "$context_len" -eq 0 ]] && [[ "$acc_len" -eq 0 ]]; then
scripts/intent-learner.sh:495:        --argjson context "$context" \
scripts/intent-learner.sh:496:        --argjson w_acc "$weight_accumulated" \
scripts/intent-learner.sh:497:        --argjson w_recent "$weight_recent" \
scripts/intent-learner.sh:498:        --argjson w_file "$weight_same_file" \
scripts/intent-learner.sh:499:        --argjson max_ratio "$max_ratio" \
scripts/intent-learner.sh:548:    jq -n --arg session_id "$session_id" '{
scripts/intent-learner.sh:556:    if [[ $# -lt 1 ]]; then
scripts/intent-learner.sh:568:    current_id=$(echo "$context" | jq -r '.session_id // empty')
scripts/intent-learner.sh:577:    if [[ -z "$current_id" ]]; then
scripts/intent-learner.sh:579:        jq -n '{
scripts/intent-learner.sh:587:    jq -n --arg target_id "$target_id" '{
scripts/intent-learner.sh:600:    session_id=$(echo "$context" | jq -r '.session_id // empty')
scripts/intent-learner.sh:602:    if [[ -z "$session_id" ]]; then
scripts/intent-learner.sh:603:        jq -n '{
scripts/intent-learner.sh:622:    if [[ -f "$CONVERSATION_CONTEXT_PATH" ]]; then
scripts/intent-learner.sh:623:        rm -f "$CONVERSATION_CONTEXT_PATH"
scripts/intent-learner.sh:629:    jq -n '{
scripts/intent-learner.sh:636:    if [[ $# -lt 1 ]]; then
scripts/intent-learner.sh:667:    if [[ $# -lt 1 ]]; then
scripts/intent-learner.sh:698:# ÈÄâÈ°π: --action view|edit|ignore
scripts/intent-learner.sh:700:    if [[ $# -lt 2 ]]; then
scripts/intent-learner.sh:713:    while [[ $# -gt 0 ]]; do
scripts/intent-learner.sh:715:            --action)
scripts/intent-learner.sh:716:                if [[ $# -lt 2 ]]; then
scripts/intent-learner.sh:745:    new_entry=$(jq -n \
scripts/intent-learner.sh:746:        --arg symbol "$symbol" \
scripts/intent-learner.sh:747:        --arg symbol_id "$symbol_id" \
scripts/intent-learner.sh:748:        --arg action "$action" \
scripts/intent-learner.sh:749:        --argjson timestamp "$timestamp" \
scripts/intent-learner.sh:762:    updated=$(echo "$history" | jq --argjson entry "$new_entry" '
scripts/intent-learner.sh:775:# ÈÄâÈ°π: --top <n>     - ËøîÂõûÂâç N ‰∏™ÔºàÈªòËÆ§ 10Ôºâ
scripts/intent-learner.sh:776:# ÈÄâÈ°π: --prefix <path> - ÊåâË∑ØÂæÑÂâçÁºÄËøáÊª§
scripts/intent-learner.sh:782:    while [[ $# -gt 0 ]]; do
scripts/intent-learner.sh:784:            --top)
scripts/intent-learner.sh:785:                if [[ $# -lt 2 ]]; then
scripts/intent-learner.sh:792:            --prefix)
scripts/intent-learner.sh:793:                if [[ $# -lt 2 ]]; then
scripts/intent-learner.sh:821:    preferences=$(echo "$history" | jq --argjson now "$now" --arg prefix "$prefix" --argjson top "$top" '
scripts/intent-learner.sh:825:            elif . == "ignore" then -0.5
scripts/intent-learner.sh:872:# ÈÄâÈ°π: --days <n> - Ê∏ÖÁêÜË∂ÖËøá N Â§©ÁöÑËÆ∞ÂΩïÔºàÈªòËÆ§ 90Ôºâ
scripts/intent-learner.sh:877:    while [[ $# -gt 0 ]]; do
scripts/intent-learner.sh:879:            --days)
scripts/intent-learner.sh:880:                if [[ $# -lt 2 ]]; then
scripts/intent-learner.sh:909:    cleaned=$(echo "$history" | jq --argjson cutoff "$cutoff" '
scripts/intent-learner.sh:920:    if [[ "$removed" -gt 0 ]]; then
scripts/intent-learner.sh:942:      --action    Áî®Êà∑Êìç‰ΩúÁ±ªÂûã (ÈªòËÆ§: view)
scripts/intent-learner.sh:949:      --top <n>       ËøîÂõûÂâç N ‰∏™ÁªìÊûú (ÈªòËÆ§: 10)
scripts/intent-learner.sh:950:      --prefix <path> ÊåâË∑ØÂæÑÂâçÁºÄËøáÊª§
scripts/intent-learner.sh:956:      --days <n>  Ê∏ÖÁêÜË∂ÖËøá N Â§©ÁöÑËÆ∞ÂΩï (ÈªòËÆ§: 90)
scripts/intent-learner.sh:958:  context save --query <q> --symbols <s1,s2> [--query-type <type>]
scripts/intent-learner.sh:962:      --query <q>        Êü•ËØ¢ÂÜÖÂÆπ (ÂøÖÈúÄ)
scripts/intent-learner.sh:963:      --symbols <s1,s2>  ÁÑ¶ÁÇπÁ¨¶Âè∑ÂàóË°®ÔºåÈÄóÂè∑ÂàÜÈöî
scripts/intent-learner.sh:964:      --query-type <t>   Êü•ËØ¢Á±ªÂûã (ÈªòËÆ§: search)
scripts/intent-learner.sh:965:      --results-count <n> ÁªìÊûúÊï∞Èáè
scripts/intent-learner.sh:970:  context apply-weight --results <json>
scripts/intent-learner.sh:974:      --results <json>  ÊêúÁ¥¢ÁªìÊûú JSON Êï∞ÁªÑ
scripts/intent-learner.sh:1016:  intent-learner record handleToolCall src/server.ts::handleToolCall --action view
scripts/intent-learner.sh:1019:  intent-learner get-preferences --top 5
scripts/intent-learner.sh:1022:  intent-learner get-preferences --prefix src/
scripts/intent-learner.sh:1025:  intent-learner cleanup --days 30
scripts/intent-learner.sh:1028:  intent-learner context save --query "find auth module" --symbols "src/auth.ts,src/auth.ts::login"
scripts/intent-learner.sh:1034:  intent-learner context apply-weight --results '[{"symbol":"src/auth.ts::login","score":0.8}]'
scripts/intent-learner.sh:1062:    if declare -f is_feature_enabled &>/dev/null; then
scripts/intent-learner.sh:1070:    if [[ $# -lt 1 ]]; then
scripts/intent-learner.sh:1094:        --help|-h|help)
scripts/llm-providers/ollama.sh:23:  if [[ -n "${LLM_MOCK_RESPONSE:-}" ]]; then
scripts/llm-providers/ollama.sh:25:    if [[ -n "${LLM_MOCK_DELAY_MS:-}" ]]; then
scripts/llm-providers/ollama.sh:27:      [[ "$delay_sec" -gt 0 ]] && sleep "$delay_sec" 2>/dev/null || true
scripts/llm-providers/ollama.sh:31:    if [[ -n "${LLM_MOCK_FAIL_COUNT:-}" && "${LLM_MOCK_FAIL_COUNT}" -gt 0 ]]; then
scripts/llm-providers/ollama.sh:58:  if [[ $mock_status -eq 0 ]]; then
scripts/llm-providers/ollama.sh:61:  elif [[ $mock_status -eq 1 ]]; then
scripts/llm-providers/ollama.sh:81:    file_path=$(echo "$candidate" | jq -r '.file_path // .file // ""')
scripts/llm-providers/ollama.sh:82:    content=$(echo "$candidate" | jq -r '.content // ""' | head -c 500)
scripts/llm-providers/ollama.sh:87:---"
scripts/llm-providers/ollama.sh:111:  if [[ $api_status -ne 0 ]]; then
scripts/llm-providers/ollama.sh:118:  ranked=$(echo "$response" | grep -oE '\[.*\]' | head -1)
scripts/llm-providers/ollama.sh:120:  if [[ -z "$ranked" ]]; then
scripts/llm-providers/ollama.sh:126:  if ! echo "$ranked" | jq -e '.' &>/dev/null; then
scripts/llm-providers/ollama.sh:144:  if [[ $mock_status -eq 0 ]]; then
scripts/llm-providers/ollama.sh:147:  elif [[ $mock_status -eq 1 ]]; then
scripts/llm-providers/ollama.sh:171:  if ! command -v curl &>/dev/null; then
scripts/llm-providers/ollama.sh:175:  curl -s --connect-timeout 2 "${_OLLAMA_ENDPOINT}/api/tags" &>/dev/null
scripts/llm-providers/ollama.sh:185:  if ! command -v curl &>/dev/null; then
scripts/llm-providers/ollama.sh:191:  if ! command -v jq &>/dev/null; then
scripts/llm-providers/ollama.sh:198:  request_body=$(jq -n \
scripts/llm-providers/ollama.sh:199:    --arg model "$_OLLAMA_MODEL" \
scripts/llm-providers/ollama.sh:200:    --arg prompt "$prompt" \
scripts/llm-providers/ollama.sh:209:  response=$(timeout "$_OLLAMA_TIMEOUT_SEC" curl -s \
scripts/llm-providers/ollama.sh:210:    -X POST "${_OLLAMA_ENDPOINT}/api/generate" \
scripts/llm-providers/ollama.sh:211:    -H "Content-Type: application/json" \
scripts/llm-providers/ollama.sh:212:    -d "$request_body" 2>/dev/null)
scripts/llm-providers/ollama.sh:215:  if [[ $exit_code -eq 124 ]]; then
scripts/llm-providers/ollama.sh:221:  if echo "$response" | jq -e '.error' &>/dev/null; then
scripts/llm-providers/ollama.sh:223:    error_msg=$(echo "$response" | jq -r '.error // "Unknown error"')
scripts/llm-providers/ollama.sh:230:  content=$(echo "$response" | jq -r '.response // empty' 2>/dev/null)
scripts/llm-providers/ollama.sh:232:  if [[ -z "$content" ]]; then
scripts/boundary-detector.sh:7:set -euo pipefail
scripts/boundary-detector.sh:34:  --path FILE        Ë¶ÅÊ£ÄÊµãÁöÑÊñá‰ª∂Ë∑ØÂæÑÔºàÂèØÈÄâÔºå‰πüÂèØ‰ª•‰Ωú‰∏∫‰ΩçÁΩÆÂèÇÊï∞Ôºâ
scripts/boundary-detector.sh:35:  --config FILE      Ëá™ÂÆö‰πâÈÖçÁΩÆÊñá‰ª∂Ë∑ØÂæÑ (ÈªòËÆ§: config/boundaries.yaml)
scripts/boundary-detector.sh:36:  --format FORMAT    ËæìÂá∫Ê†ºÂºè: text Êàñ json (ÈªòËÆ§: text)
scripts/boundary-detector.sh:37:  -h, --help         ÊòæÁ§∫Â∏ÆÂä©‰ø°ÊÅØ
scripts/boundary-detector.sh:54:  boundary-detector.sh --path node_modules/lodash/index.js --format json
scripts/boundary-detector.sh:55:  boundary-detector.sh --format json dist/bundle.js
scripts/boundary-detector.sh:56:  boundary-detector.sh --config ./my-boundaries.yaml src/
scripts/boundary-detector.sh:65:while [[ $# -gt 0 ]]; do
scripts/boundary-detector.sh:67:    --config)
scripts/boundary-detector.sh:71:    --format)
scripts/boundary-detector.sh:75:    --path)
scripts/boundary-detector.sh:79:    -h|--help)
scripts/boundary-detector.sh:96:if [[ -z "$TARGET" ]]; then
scripts/boundary-detector.sh:103:  log_error "Êó†ÊïàÁöÑ --format ÂèÇÊï∞: $FORMAT (ÂøÖÈ°ªÊòØ text Êàñ json)"
scripts/boundary-detector.sh:109:declare -a BUILTIN_RULES
scripts/boundary-detector.sh:149:  if [[ ! -f "$yaml_file" ]]; then
scripts/boundary-detector.sh:157:  while IFS= read -r line || [[ -n "$line" ]]; do
scripts/boundary-detector.sh:160:    [[ -z "$line" ]] && continue
scripts/boundary-detector.sh:178:        if [[ -n "$pattern" && -n "$type" ]]; then
scripts/boundary-detector.sh:197:  if [[ -n "$pattern" && -n "$type" ]]; then
scripts/boundary-detector.sh:250:    IFS='|' read -r pattern type confidence reason <<< "$rule"
scripts/boundary-detector.sh:268:  IFS='|' read -r type confidence matched_rule reason <<< "$result"
scripts/boundary-detector.sh:281:  if [[ ! -f "$CONFIG_FILE" ]]; then
scripts/boundary-detector.sh:286:  if [[ -f "$TARGET" ]]; then
scripts/boundary-detector.sh:291:  elif [[ -d "$TARGET" ]]; then
scripts/boundary-detector.sh:298:    find "$TARGET" -type f -not -path "*/.git/*" 2>/dev/null | while read -r file; do
scripts/hotspot-analyzer.sh:10:set -euo pipefail
scripts/hotspot-analyzer.sh:56:  -n, --top, --top-n N  ËøîÂõû Top-N ÁÉ≠ÁÇπÊñá‰ª∂ÔºàÈªòËÆ§: 20Ôºâ
scripts/hotspot-analyzer.sh:57:  --days N              ÁªüËÆ°ÊúÄËøë N Â§©ÁöÑ git logÔºàÈªòËÆ§: 30Ôºâ
scripts/hotspot-analyzer.sh:58:  --format FORMAT       ËæìÂá∫Ê†ºÂºè: text Êàñ jsonÔºàÈªòËÆ§: textÔºâ
scripts/hotspot-analyzer.sh:59:  --path DIR            ÁõÆÊ†áÁõÆÂΩïÔºàÈªòËÆ§: ÂΩìÂâçÁõÆÂΩïÔºâ
scripts/hotspot-analyzer.sh:60:  --with-bug-history    ÂêØÁî® Bug ‰øÆÂ§çÂéÜÂè≤ÊùÉÈáçÂ¢ûÂº∫
scripts/hotspot-analyzer.sh:61:  --bug-weight FLOAT    Bug ‰øÆÂ§çÊùÉÈáçÁ≥ªÊï∞ÔºàÈªòËÆ§: 1.0Ôºâ
scripts/hotspot-analyzer.sh:64:  --weighted            ÂêØÁî®Âä†ÊùÉÂàÜÊï∞ÂÖ¨Âºè
scripts/hotspot-analyzer.sh:65:  --normalized          ÂΩí‰∏ÄÂåñÊâÄÊúâÂõ†Â≠êÂà∞ [0,1] ËåÉÂõ¥
scripts/hotspot-analyzer.sh:66:  --weights W1,W2,W3,W4 Ëá™ÂÆö‰πâÊùÉÈáç (churn,complexity,coupling,age)
scripts/hotspot-analyzer.sh:67:  --recency-boost       ËøëÊúüÂèòÊõ¥Ôºà30Â§©ÂÜÖÔºâËé∑ÂæóÂä†Êàê
scripts/hotspot-analyzer.sh:68:  --coupling            ÂêØÁî®ËÄ¶ÂêàÂ∫¶ÂàÜÊûê
scripts/hotspot-analyzer.sh:70:  -h, --help            ÊòæÁ§∫Â∏ÆÂä©‰ø°ÊÅØ
scripts/hotspot-analyzer.sh:71:  -v, --version         ÊòæÁ§∫ÁâàÊú¨‰ø°ÊÅØ
scripts/hotspot-analyzer.sh:74:  Default (without --weighted):
scripts/hotspot-analyzer.sh:77:  With --weighted (CT-HW-001):
scripts/hotspot-analyzer.sh:79:    All factors normalized to [0,1] when --normalized is used
scripts/hotspot-analyzer.sh:81:  With --with-bug-history:
scripts/hotspot-analyzer.sh:86:  HOTSPOT_WEIGHTS       Ëá™ÂÆö‰πâÊùÉÈáç (Âêå --weights)
scripts/hotspot-analyzer.sh:95:  hotspot-analyzer.sh --top 10 --days 7
scripts/hotspot-analyzer.sh:96:  hotspot-analyzer.sh --format json --path ./src
scripts/hotspot-analyzer.sh:97:  hotspot-analyzer.sh --with-bug-history --bug-weight 1.5
scripts/hotspot-analyzer.sh:98:  hotspot-analyzer.sh --weighted --normalized
scripts/hotspot-analyzer.sh:99:  hotspot-analyzer.sh --weighted --weights 0.5,0.2,0.2,0.1
scripts/hotspot-analyzer.sh:100:  hotspot-analyzer.sh --weighted --recency-boost --coupling
scripts/hotspot-analyzer.sh:112:if [[ -n "${HOTSPOT_WEIGHTS:-}" ]]; then
scripts/hotspot-analyzer.sh:113:  IFS=',' read -r DEFAULT_WEIGHT_CHURN DEFAULT_WEIGHT_COMPLEXITY DEFAULT_WEIGHT_COUPLING DEFAULT_WEIGHT_AGE <<< "$HOTSPOT_WEIGHTS"
scripts/hotspot-analyzer.sh:123:while [[ $# -gt 0 ]]; do
scripts/hotspot-analyzer.sh:125:    -n|--top|--top-n)
scripts/hotspot-analyzer.sh:129:    --days)
scripts/hotspot-analyzer.sh:133:    --format)
scripts/hotspot-analyzer.sh:137:    --path)
scripts/hotspot-analyzer.sh:141:    --with-bug-history)
scripts/hotspot-analyzer.sh:145:    --bug-weight)
scripts/hotspot-analyzer.sh:149:    --weighted)
scripts/hotspot-analyzer.sh:153:    --normalized)
scripts/hotspot-analyzer.sh:157:    --weights)
scripts/hotspot-analyzer.sh:158:      IFS=',' read -r WEIGHT_CHURN WEIGHT_COMPLEXITY WEIGHT_COUPLING WEIGHT_AGE <<< "$2"
scripts/hotspot-analyzer.sh:162:    --recency-boost)
scripts/hotspot-analyzer.sh:166:    --coupling)
scripts/hotspot-analyzer.sh:170:    -h|--help)
scripts/hotspot-analyzer.sh:174:    -v|--version)
scripts/hotspot-analyzer.sh:187:if [[ ! "$TOP_N" =~ ^[0-9]+$ ]] || [[ "$TOP_N" -lt 1 ]]; then
scripts/hotspot-analyzer.sh:188:  log_error "Êó†ÊïàÁöÑ --top ÂèÇÊï∞: $TOP_N"
scripts/hotspot-analyzer.sh:192:if [[ ! "$DAYS" =~ ^[0-9]+$ ]] || [[ "$DAYS" -lt 1 ]]; then
scripts/hotspot-analyzer.sh:193:  log_error "Êó†ÊïàÁöÑ --days ÂèÇÊï∞: $DAYS"
scripts/hotspot-analyzer.sh:198:  log_error "Êó†ÊïàÁöÑ --format ÂèÇÊï∞: $FORMATÔºàÂøÖÈ°ªÊòØ text Êàñ jsonÔºâ"
scripts/hotspot-analyzer.sh:203:if ! command -v git &>/dev/null; then
scripts/hotspot-analyzer.sh:208:if [[ ! -d "$TARGET_PATH/.git" ]] && ! git -C "$TARGET_PATH" rev-parse --git-dir &>/dev/null 2>&1; then
scripts/hotspot-analyzer.sh:219:  if [[ ! -f "$full_path" ]]; then
scripts/hotspot-analyzer.sh:227:  line_count=$(wc -l < "$full_path" 2>/dev/null | tr -d ' ')
scripts/hotspot-analyzer.sh:229:  if [[ -n "$line_count" && "$line_count" =~ ^[0-9]+$ && "$line_count" -gt 0 ]]; then
scripts/hotspot-analyzer.sh:245:  while IFS= read -r message; do
scripts/hotspot-analyzer.sh:246:    [[ -z "$message" ]] && continue
scripts/hotspot-analyzer.sh:248:    if declare -f is_bug_fix_message &>/dev/null; then
scripts/hotspot-analyzer.sh:262:  done < <(git -C "$TARGET_PATH" log --format="%s" --since="$since_date" -- "$file" 2>/dev/null)
scripts/hotspot-analyzer.sh:278:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/hotspot-analyzer.sh:281:  if [[ -n "$rg_cmd" ]]; then
scripts/hotspot-analyzer.sh:285:    coupling=$("$rg_cmd" -l "(import.*['\"].*${basename}|require.*['\"].*${basename})" "$TARGET_PATH" 2>/dev/null | wc -l | tr -d ' ') || coupling=0
scripts/hotspot-analyzer.sh:310:  git -C "$target_path" log --format="%ct" --name-only --since="$since_date" 2>/dev/null | \
scripts/hotspot-analyzer.sh:311:    awk -v now="$NOW_EPOCH" -v default_days="$DAYS" '
scripts/hotspot-analyzer.sh:330:  [[ -n "$FILE_AGE_CACHE_FILE" && -f "$FILE_AGE_CACHE_FILE" ]] && rm -f "$FILE_AGE_CACHE_FILE"
scripts/hotspot-analyzer.sh:342:  [[ -z "$file" ]] && { echo "$DAYS"; return; }
scripts/hotspot-analyzer.sh:345:  if [[ "$FILE_AGE_CACHE_INITIALIZED" == "true" && -f "$FILE_AGE_CACHE_FILE" ]]; then
scripts/hotspot-analyzer.sh:347:    result=$(awk -v f="$file" '$1 == f {print $2; exit}' "$FILE_AGE_CACHE_FILE")
scripts/hotspot-analyzer.sh:348:    if [[ -n "$result" ]]; then
scripts/hotspot-analyzer.sh:364:  if [[ "$max_value" -eq 0 ]] || [[ -z "$max_value" ]]; then
scripts/hotspot-analyzer.sh:369:  awk -v v="$value" -v m="$max_value" 'BEGIN { printf "%.4f", v / m }'
scripts/hotspot-analyzer.sh:381:  awk -v churn="$churn_norm" \
scripts/hotspot-analyzer.sh:382:      -v complexity="$complexity_norm" \
scripts/hotspot-analyzer.sh:383:      -v coupling="$coupling_norm" \
scripts/hotspot-analyzer.sh:384:      -v age="$age_norm" \
scripts/hotspot-analyzer.sh:385:      -v w_churn="$WEIGHT_CHURN" \
scripts/hotspot-analyzer.sh:386:      -v w_complexity="$WEIGHT_COMPLEXITY" \
scripts/hotspot-analyzer.sh:387:      -v w_coupling="$WEIGHT_COUPLING" \
scripts/hotspot-analyzer.sh:388:      -v w_age="$WEIGHT_AGE" \
scripts/hotspot-analyzer.sh:389:      -v recency="$recency_factor" \
scripts/hotspot-analyzer.sh:421:  trap "rm -f '$tmp_freq' '$tmp_result' '$tmp_raw'; cleanup_file_age_cache" EXIT
scripts/hotspot-analyzer.sh:423:  # Ëé∑ÂèñÂèòÊõ¥È¢ëÁéáÔºà‰ΩøÁî® sort | uniq -c Êõø‰ª£ÂÖ≥ËÅîÊï∞ÁªÑÔºâ
scripts/hotspot-analyzer.sh:425:  if date -v-1d &>/dev/null 2>&1; then
scripts/hotspot-analyzer.sh:427:    since_date=$(date -v-"${DAYS}"d +%Y-%m-%d)
scripts/hotspot-analyzer.sh:430:    since_date=$(date -d "${DAYS} days ago" +%Y-%m-%d)
scripts/hotspot-analyzer.sh:433:  git -C "$TARGET_PATH" log --pretty=format: --name-only --since="$since_date" 2>/dev/null | \
scripts/hotspot-analyzer.sh:434:    grep -v '^$' | \
scripts/hotspot-analyzer.sh:435:    grep -E '\.(ts|tsx|js|jsx|py|go|java|c|cpp|h|hpp|rs|rb|php|swift|kt|scala|sh)$' | \
scripts/hotspot-analyzer.sh:436:    sort | uniq -c > "$tmp_freq" || true
scripts/hotspot-analyzer.sh:439:  file_count=$(wc -l < "$tmp_freq" | tr -d ' ')
scripts/hotspot-analyzer.sh:441:  if [[ "$file_count" -eq 0 ]]; then
scripts/hotspot-analyzer.sh:462:    freq_count=$(wc -l < "$tmp_freq" | tr -d ' ')
scripts/hotspot-analyzer.sh:464:    if [[ "$freq_count" -gt 100 ]]; then
scripts/hotspot-analyzer.sh:468:      # macOS: stat -f "%z %N"
scripts/hotspot-analyzer.sh:469:      awk -v prefix="$TARGET_PATH/" '{print prefix $2}' "$tmp_freq" | \
scripts/hotspot-analyzer.sh:470:        xargs stat -f "%z %N" 2>/dev/null | \
scripts/hotspot-analyzer.sh:471:        awk -v target="$TARGET_PATH/" '{
scripts/hotspot-analyzer.sh:480:      # Linux: stat --printf="%s %n\n"
scripts/hotspot-analyzer.sh:481:      awk -v prefix="$TARGET_PATH/" '{print prefix $2}' "$tmp_freq" | \
scripts/hotspot-analyzer.sh:482:        xargs stat --printf="%s %n\n" 2>/dev/null | \
scripts/hotspot-analyzer.sh:483:        awk -v target="$TARGET_PATH/" '{
scripts/hotspot-analyzer.sh:498:    awk -v w_churn="$WEIGHT_CHURN" \
scripts/hotspot-analyzer.sh:499:        -v w_complexity="$WEIGHT_COMPLEXITY" \
scripts/hotspot-analyzer.sh:500:        -v w_coupling="$WEIGHT_COUPLING" \
scripts/hotspot-analyzer.sh:501:        -v w_age="$WEIGHT_AGE" \
scripts/hotspot-analyzer.sh:502:        -v normalized="$NORMALIZED_MODE" \
scripts/hotspot-analyzer.sh:503:        -v recency_boost="$RECENCY_BOOST" \
scripts/hotspot-analyzer.sh:504:        -v recency_threshold="$RECENCY_THRESHOLD_DAYS" \
scripts/hotspot-analyzer.sh:505:        -v recency_factor="$RECENCY_BOOST_FACTOR" \
scripts/hotspot-analyzer.sh:506:        -v default_days="$DAYS" \
scripts/hotspot-analyzer.sh:507:        -v top_n="$TOP_N" \
scripts/hotspot-analyzer.sh:508:        -v format="$FORMAT" \
scripts/hotspot-analyzer.sh:634:    rm -f "$tmp_complexity"
scripts/hotspot-analyzer.sh:638:    while read -r freq file; do
scripts/hotspot-analyzer.sh:639:      if [[ -n "$file" ]]; then
scripts/hotspot-analyzer.sh:650:        if [[ "$freq" -gt 0 ]]; then
scripts/hotspot-analyzer.sh:651:          bug_fix_ratio=$(awk -v bug="$bug_fix_count" -v f="$freq" 'BEGIN { printf "%.4f", bug / f }')
scripts/hotspot-analyzer.sh:656:        score=$(awk -v f="$freq" -v c="$complexity" -v bw="$BUG_WEIGHT" -v br="$bug_fix_ratio" \
scripts/hotspot-analyzer.sh:665:    sorted=$(sort -t'|' -k1 -rn "$tmp_result" | head -n "$TOP_N")
scripts/hotspot-analyzer.sh:677:      while IFS='|' read -r score freq complexity bug_count bug_ratio file; do
scripts/hotspot-analyzer.sh:694:      while IFS='|' read -r score freq complexity bug_count bug_ratio file; do
scripts/hotspot-analyzer.sh:702:    while read -r freq file; do
scripts/hotspot-analyzer.sh:703:      if [[ -n "$file" ]]; then
scripts/hotspot-analyzer.sh:715:    sorted=$(sort -t'|' -k1 -rn "$tmp_result" | head -n "$TOP_N")
scripts/hotspot-analyzer.sh:725:      while IFS='|' read -r score freq complexity file; do
scripts/hotspot-analyzer.sh:742:      while IFS='|' read -r score freq complexity file; do
scripts/llm-providers/anthropic.sh:23:  if [[ -n "${LLM_MOCK_RESPONSE:-}" ]]; then
scripts/llm-providers/anthropic.sh:25:    if [[ -n "${LLM_MOCK_DELAY_MS:-}" ]]; then
scripts/llm-providers/anthropic.sh:27:      [[ "$delay_sec" -gt 0 ]] && sleep "$delay_sec" 2>/dev/null || true
scripts/llm-providers/anthropic.sh:31:    if [[ -n "${LLM_MOCK_FAIL_COUNT:-}" && "${LLM_MOCK_FAIL_COUNT}" -gt 0 ]]; then
scripts/llm-providers/anthropic.sh:58:  if [[ $mock_status -eq 0 ]]; then
scripts/llm-providers/anthropic.sh:61:  elif [[ $mock_status -eq 1 ]]; then
scripts/llm-providers/anthropic.sh:66:  if [[ -z "$_ANTHROPIC_API_KEY" ]]; then
scripts/llm-providers/anthropic.sh:81:    file_path=$(echo "$candidate" | jq -r '.file_path // .file // ""')
scripts/llm-providers/anthropic.sh:82:    content=$(echo "$candidate" | jq -r '.content // ""' | head -c 500)
scripts/llm-providers/anthropic.sh:87:---"
scripts/llm-providers/anthropic.sh:111:  if [[ $api_status -ne 0 ]]; then
scripts/llm-providers/anthropic.sh:118:  ranked=$(echo "$response" | grep -oE '\[.*\]' | head -1)
scripts/llm-providers/anthropic.sh:120:  if [[ -z "$ranked" ]]; then
scripts/llm-providers/anthropic.sh:126:  if ! echo "$ranked" | jq -e '.' &>/dev/null; then
scripts/llm-providers/anthropic.sh:144:  if [[ $mock_status -eq 0 ]]; then
scripts/llm-providers/anthropic.sh:147:  elif [[ $mock_status -eq 1 ]]; then
scripts/llm-providers/anthropic.sh:152:  if [[ -z "$_ANTHROPIC_API_KEY" ]]; then
scripts/llm-providers/anthropic.sh:164:  if [[ -z "$_ANTHROPIC_API_KEY" ]]; then
scripts/llm-providers/anthropic.sh:169:  if command -v curl &>/dev/null; then
scripts/llm-providers/anthropic.sh:172:    response=$(curl -s --connect-timeout 3 \
scripts/llm-providers/anthropic.sh:173:      -H "x-api-key: $_ANTHROPIC_API_KEY" \
scripts/llm-providers/anthropic.sh:174:      -H "anthropic-version: 2023-06-01" \
scripts/llm-providers/anthropic.sh:176:      -X POST \
scripts/llm-providers/anthropic.sh:177:      -d '{"model":"claude-3-haiku-20240307","max_tokens":1,"messages":[{"role":"user","content":"hi"}]}' \
scripts/llm-providers/anthropic.sh:181:    if echo "$response" | jq -e '.error' &>/dev/null; then
scripts/llm-providers/anthropic.sh:183:      error_type=$(echo "$response" | jq -r '.error.type // "unknown"')
scripts/llm-providers/anthropic.sh:202:  if ! command -v curl &>/dev/null; then
scripts/llm-providers/anthropic.sh:208:  if ! command -v jq &>/dev/null; then
scripts/llm-providers/anthropic.sh:215:  request_body=$(jq -n \
scripts/llm-providers/anthropic.sh:216:    --arg model "$_ANTHROPIC_MODEL" \
scripts/llm-providers/anthropic.sh:217:    --arg prompt "$prompt" \
scripts/llm-providers/anthropic.sh:218:    --argjson max_tokens "$_ANTHROPIC_MAX_TOKENS" \
scripts/llm-providers/anthropic.sh:227:  response=$(timeout "$_ANTHROPIC_TIMEOUT_SEC" curl -s \
scripts/llm-providers/anthropic.sh:228:    -X POST "${_ANTHROPIC_API_BASE}/messages" \
scripts/llm-providers/anthropic.sh:229:    -H "Content-Type: application/json" \
scripts/llm-providers/anthropic.sh:230:    -H "x-api-key: $_ANTHROPIC_API_KEY" \
scripts/llm-providers/anthropic.sh:231:    -H "anthropic-version: 2023-06-01" \
scripts/llm-providers/anthropic.sh:232:    -d "$request_body" 2>/dev/null)
scripts/llm-providers/anthropic.sh:235:  if [[ $exit_code -eq 124 ]]; then
scripts/llm-providers/anthropic.sh:241:  if echo "$response" | jq -e '.error' &>/dev/null; then
scripts/llm-providers/anthropic.sh:243:    error_msg=$(echo "$response" | jq -r '.error.message // .error.type // "Unknown error"')
scripts/llm-providers/anthropic.sh:250:  content=$(echo "$response" | jq -r '.content[0].text // empty' 2>/dev/null)
scripts/llm-providers/anthropic.sh:252:  if [[ -z "$content" ]]; then
scripts/context-layer.sh:9:#   context-layer.sh --classify <sha>
scripts/context-layer.sh:10:#   context-layer.sh --classify-batch --since "90 days ago"
scripts/context-layer.sh:11:#   context-layer.sh --bug-history --file <path>
scripts/context-layer.sh:12:#   context-layer.sh --index [--days 90]
scripts/context-layer.sh:13:#   context-layer.sh --help
scripts/context-layer.sh:24:set -euo pipefail
scripts/context-layer.sh:43:if [[ -f "$COMMON_LIB" ]]; then
scripts/context-layer.sh:71:read -r -a GIT_LOG_CMD_ARRAY <<< "$GIT_LOG_CMD"
scripts/context-layer.sh:81:  context-layer.sh --classify <sha>
scripts/context-layer.sh:82:  context-layer.sh --classify-batch --since "90 days ago"
scripts/context-layer.sh:83:  context-layer.sh --bug-history --file <path>
scripts/context-layer.sh:84:  context-layer.sh --index [--days 90]
scripts/context-layer.sh:85:  context-layer.sh --help
scripts/context-layer.sh:88:  --classify <sha>      Classify a single commit by SHA
scripts/context-layer.sh:89:  --classify-batch      Classify multiple commits
scripts/context-layer.sh:90:  --since <date>        Start date for batch classification (default: 90 days ago)
scripts/context-layer.sh:91:  --bug-history         Extract bug fix history
scripts/context-layer.sh:92:  --file <path>         Target file for bug history
scripts/context-layer.sh:93:  --index               Generate context index
scripts/context-layer.sh:94:  --days <n>            Time window in days (default: 90)
scripts/context-layer.sh:95:  --format <type>       Output format: json or text (default: json)
scripts/context-layer.sh:96:  --debug               Enable debug output
scripts/context-layer.sh:97:  --help                Show this help message
scripts/context-layer.sh:106:  context-layer.sh --classify abc123
scripts/context-layer.sh:109:  context-layer.sh --classify-batch --since "30 days ago"
scripts/context-layer.sh:112:  context-layer.sh --bug-history --file src/server.ts
scripts/context-layer.sh:115:  context-layer.sh --index --days 90
scripts/context-layer.sh:133:    if declare -f is_bug_fix_message &>/dev/null; then
scripts/context-layer.sh:194:    message=$(git_log -1 --format="%s" "$sha" 2>/dev/null)
scripts/context-layer.sh:196:    if [[ -z "$message" ]]; then
scripts/context-layer.sh:204:    commit_type=$(echo "$result" | head -1)
scripts/context-layer.sh:206:    confidence=$(echo "$result" | tail -1)
scripts/context-layer.sh:209:        jq -n \
scripts/context-layer.sh:210:            --arg sha "$sha" \
scripts/context-layer.sh:211:            --arg type "$commit_type" \
scripts/context-layer.sh:212:            --arg confidence "$confidence" \
scripts/context-layer.sh:213:            --arg message "$message" \
scripts/context-layer.sh:236:    while IFS= read -r sha; do
scripts/context-layer.sh:237:        [[ -z "$sha" ]] && continue
scripts/context-layer.sh:240:        message=$(git_log -1 --format="%s" "$sha" 2>/dev/null)
scripts/context-layer.sh:241:        [[ -z "$message" ]] && continue
scripts/context-layer.sh:246:        commit_type=$(echo "$result" | head -1)
scripts/context-layer.sh:248:        confidence=$(echo "$result" | tail -1)
scripts/context-layer.sh:250:        results=$(echo "$results" | jq --arg sha "$sha" --arg type "$commit_type" \
scripts/context-layer.sh:251:            --arg confidence "$confidence" --arg message "$message" \
scripts/context-layer.sh:253:    done < <(git_log --format="%H" --since="$since" 2>/dev/null)
scripts/context-layer.sh:256:        jq -n --argjson results "$results" \
scripts/context-layer.sh:257:            --arg schema_version "$SCHEMA_VERSION" \
scripts/context-layer.sh:265:        echo "$results" | jq -r '.[] | "\(.sha[0:7]) \(.type) (\(.confidence)) - \(.message[0:50])"'
scripts/context-layer.sh:281:    if [[ ! -f "$file_path" ]]; then
scripts/context-layer.sh:291:    while IFS= read -r line; do
scripts/context-layer.sh:292:        [[ -z "$line" ]] && continue
scripts/context-layer.sh:295:        sha=$(echo "$line" | cut -d'|' -f1)
scripts/context-layer.sh:297:        date=$(echo "$line" | cut -d'|' -f2)
scripts/context-layer.sh:299:        message=$(echo "$line" | cut -d'|' -f3-)
scripts/context-layer.sh:305:        commit_type=$(echo "$result" | head -1)
scripts/context-layer.sh:309:            bug_fix_commits=$(echo "$bug_fix_commits" | jq --arg sha "$sha" '. + [$sha]')
scripts/context-layer.sh:310:            if [[ -z "$last_bug_fix" ]]; then
scripts/context-layer.sh:314:    done < <(git_log --format="%H|%aI|%s" --since="$days days ago" -- "$file_path" 2>/dev/null)
scripts/context-layer.sh:317:        jq -n \
scripts/context-layer.sh:318:            --arg file "$file_path" \
scripts/context-layer.sh:319:            --argjson bug_fix_count "$bug_fix_count" \
scripts/context-layer.sh:320:            --argjson bug_fix_commits "$bug_fix_commits" \
scripts/context-layer.sh:321:            --arg last_bug_fix "${last_bug_fix:-null}" \
scripts/context-layer.sh:322:            --arg days "$days" \
scripts/context-layer.sh:334:        echo "Bug Fix Commits: $(echo "$bug_fix_commits" | jq -r 'join(", ")')"
scripts/context-layer.sh:352:    indexed_at=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
scripts/context-layer.sh:357:    trap "rm -f '$tmp_file'" EXIT
scripts/context-layer.sh:360:    git_log --name-only --format="" --since="$days days ago" 2>/dev/null | \
scripts/context-layer.sh:361:        grep -v '^$' | sort -u > "$tmp_file" || true
scripts/context-layer.sh:364:    file_count=$(wc -l < "$tmp_file" | tr -d ' ')
scripts/context-layer.sh:368:    while IFS= read -r file_path; do
scripts/context-layer.sh:369:        [[ -z "$file_path" ]] && continue
scripts/context-layer.sh:377:        while IFS= read -r line; do
scripts/context-layer.sh:378:            [[ -z "$line" ]] && continue
scripts/context-layer.sh:381:            sha=$(echo "$line" | cut -d'|' -f1)
scripts/context-layer.sh:383:            date=$(echo "$line" | cut -d'|' -f2)
scripts/context-layer.sh:385:            message=$(echo "$line" | cut -d'|' -f3-)
scripts/context-layer.sh:391:            commit_type=$(echo "$result" | head -1)
scripts/context-layer.sh:394:            commit_types=$(echo "$commit_types" | jq --arg type "$commit_type" \
scripts/context-layer.sh:400:                bug_fix_commits=$(echo "$bug_fix_commits" | jq --arg sha "$sha" '. + [$sha]')
scripts/context-layer.sh:401:                if [[ -z "$last_bug_fix" ]]; then
scripts/context-layer.sh:405:        done < <(git_log --format="%H|%aI|%s" --since="$days days ago" -- "$file_path" 2>/dev/null)
scripts/context-layer.sh:409:            --arg path "$file_path" \
scripts/context-layer.sh:410:            --argjson bug_fix_count "$bug_fix_count" \
scripts/context-layer.sh:411:            --argjson bug_fix_commits "$bug_fix_commits" \
scripts/context-layer.sh:412:            --arg last_bug_fix "${last_bug_fix:-null}" \
scripts/context-layer.sh:413:            --argjson commit_types "$commit_types" \
scripts/context-layer.sh:427:    index_json=$(jq -n \
scripts/context-layer.sh:428:        --arg schema_version "$SCHEMA_VERSION" \
scripts/context-layer.sh:429:        --arg indexed_at "$indexed_at" \
scripts/context-layer.sh:430:        --argjson time_window_days "$days" \
scripts/context-layer.sh:431:        --argjson files "$files" \
scripts/context-layer.sh:442:    mkdir -p "$index_dir" 2>/dev/null
scripts/context-layer.sh:464:    while IFS= read -r line; do
scripts/context-layer.sh:465:        [[ -z "$line" ]] && continue
scripts/context-layer.sh:469:        message=$(echo "$line" | cut -d'|' -f2-)
scripts/context-layer.sh:474:        commit_type=$(echo "$result" | head -1)
scripts/context-layer.sh:479:    done < <(git_log --format="%H|%s" --since="$days days ago" -- "$file_path" 2>/dev/null)
scripts/context-layer.sh:481:    if [[ $total_commits -eq 0 ]]; then
scripts/context-layer.sh:485:        awk -v bug="$bug_fix_count" -v total="$total_commits" 'BEGIN { printf "%.4f", bug / total }'
scripts/context-layer.sh:501:    while [[ $# -gt 0 ]]; do
scripts/context-layer.sh:503:            --classify)
scripts/context-layer.sh:505:                if [[ -n "${2:-}" && ! "$2" =~ ^-- ]]; then
scripts/context-layer.sh:511:            --classify-batch)
scripts/context-layer.sh:515:            --bug-history)
scripts/context-layer.sh:519:            --index)
scripts/context-layer.sh:523:            --file)
scripts/context-layer.sh:527:            --since)
scripts/context-layer.sh:531:            --days)
scripts/context-layer.sh:535:            --format)
scripts/context-layer.sh:539:            --debug)
scripts/context-layer.sh:543:            --help|-h)
scripts/context-layer.sh:549:                if [[ -z "$sha" && "$action" == "classify" ]]; then
scripts/context-layer.sh:558:    if ! command -v git &>/dev/null; then
scripts/context-layer.sh:564:    if ! command -v jq &>/dev/null; then
scripts/context-layer.sh:570:    if ! git rev-parse --is-inside-work-tree &>/dev/null 2>&1; then
scripts/context-layer.sh:577:            if [[ -z "$sha" ]]; then
scripts/context-layer.sh:578:                log_error "Usage: context-layer.sh --classify <sha>"
scripts/context-layer.sh:587:            if [[ -z "$file_path" ]]; then
scripts/context-layer.sh:588:                log_error "Usage: context-layer.sh --bug-history --file <path>"
scripts/llm-providers/mock.sh:17:  if [[ -n "${LLM_MOCK_DELAY_MS:-}" ]]; then
scripts/llm-providers/mock.sh:21:    if [[ "$delay_sec" -gt 0 ]]; then
scripts/llm-providers/mock.sh:25:    if [[ "$delay_ms" -gt 0 ]] && command -v perl &>/dev/null; then
scripts/llm-providers/mock.sh:26:      perl -e "select(undef,undef,undef,$delay_ms/1000)" 2>/dev/null || true
scripts/llm-providers/mock.sh:31:  if [[ -n "${LLM_MOCK_FAIL_COUNT:-}" && "${LLM_MOCK_FAIL_COUNT}" -gt 0 ]]; then
scripts/llm-providers/mock.sh:38:  if [[ -n "${LLM_MOCK_RESPONSE:-}" ]]; then
scripts/llm-providers/mock.sh:62:  if [[ $mock_status -eq 0 ]]; then
scripts/llm-providers/mock.sh:65:  elif [[ $mock_status -eq 1 ]]; then
scripts/llm-providers/mock.sh:73:  if [[ "$count" -eq 0 ]]; then
scripts/llm-providers/mock.sh:83:    [[ $score -lt 1 ]] && score=1
scripts/llm-providers/mock.sh:86:    file_path=$(echo "$candidates" | jq -r ".[$i].file_path // .[$i].file // \"file_$i\"")
scripts/llm-providers/mock.sh:89:      --argjson index "$i" \
scripts/llm-providers/mock.sh:90:      --argjson score "$score" \
scripts/llm-providers/mock.sh:91:      --arg reason "Mock ranking (position $i)" \
scripts/llm-providers/mock.sh:109:  if [[ $mock_status -eq 0 ]]; then
scripts/llm-providers/mock.sh:112:  elif [[ $mock_status -eq 1 ]]; then
scripts/llm-providers/mock.sh:118:  prompt_preview=$(echo "$prompt" | head -c 50)
scripts/llm-providers/mock.sh:175:    [[ $score -lt 1 ]] && score=1
scripts/llm-providers/mock.sh:178:      --argjson index "$i" \
scripts/llm-providers/mock.sh:179:      --argjson score "$score" \
scripts/llm-providers/mock.sh:180:      --arg reason "Generated mock ranking" \
scripts/impact-analyzer.sh:16:set -euo pipefail
scripts/impact-analyzer.sh:38:if [[ -f "$FEATURES_CONFIG" ]]; then
scripts/impact-analyzer.sh:44:    [[ -n "${_config_depth:-}" ]] && DEFAULT_MAX_DEPTH="$_config_depth"
scripts/impact-analyzer.sh:45:    [[ -n "${_config_decay:-}" ]] && DEFAULT_DECAY_FACTOR="$_config_decay"
scripts/impact-analyzer.sh:46:    [[ -n "${_config_threshold:-}" ]] && DEFAULT_THRESHOLD="$_config_threshold"
scripts/impact-analyzer.sh:53:    if [[ ! -f "$GRAPH_DB_PATH" ]]; then
scripts/impact-analyzer.sh:70:    awk -v a="$a" -v b="$b" 'BEGIN { exit !(a >= b) }'
scripts/impact-analyzer.sh:77:    awk -v a="$a" -v b="$b" 'BEGIN { printf "%.6f", a * b }'
scripts/impact-analyzer.sh:84:    awk -v base="$base" -v exp="$exp" 'BEGIN { printf "%.6f", base ^ exp }'
scripts/impact-analyzer.sh:99:        sed 's/|/\t/g' | while IFS=$'\t' read -r id sym file; do
scripts/impact-analyzer.sh:116:        sed 's/|/\t/g' | while IFS=$'\t' read -r id sym file; do
scripts/impact-analyzer.sh:131:        sed 's/|/\t/g' | while IFS=$'\t' read -r id sym kind; do
scripts/impact-analyzer.sh:156:    trap "rm -f '$queue_file' '$visited_file' '$result_file'" EXIT
scripts/impact-analyzer.sh:165:    while [[ -s "$queue_file" ]]; do
scripts/impact-analyzer.sh:168:        current=$(head -1 "$queue_file")
scripts/impact-analyzer.sh:169:        tail -n +2 "$queue_file" > "${queue_file}.tmp"
scripts/impact-analyzer.sh:174:        node_id=$(echo "$current" | cut -d'|' -f1)
scripts/impact-analyzer.sh:175:        depth=$(echo "$current" | cut -d'|' -f2)
scripts/impact-analyzer.sh:176:        impact=$(echo "$current" | cut -d'|' -f3)
scripts/impact-analyzer.sh:179:        if grep -qF "$node_id" "$visited_file" 2>/dev/null; then
scripts/impact-analyzer.sh:191:            if [[ -n "$info" ]]; then
scripts/impact-analyzer.sh:193:                sym=$(echo "$info" | cut -d'|' -f2)
scripts/impact-analyzer.sh:194:                kind=$(echo "$info" | cut -d'|' -f3)
scripts/impact-analyzer.sh:195:                file=$(echo "$info" | cut -d'|' -f4)
scripts/impact-analyzer.sh:201:                echo "$current_result" | jq --arg id "$node_id" \
scripts/impact-analyzer.sh:202:                                            --arg sym "$sym" \
scripts/impact-analyzer.sh:203:                                            --arg kind "$kind" \
scripts/impact-analyzer.sh:204:                                            --arg file "$file" \
scripts/impact-analyzer.sh:205:                                            --argjson depth "$depth" \
scripts/impact-analyzer.sh:206:                                            --argjson impact "$impact" \
scripts/impact-analyzer.sh:214:        if [[ "$depth" -lt "$max_depth" ]]; then
scripts/impact-analyzer.sh:226:                while IFS='|' read -r ds_id ds_sym ds_file; do
scripts/impact-analyzer.sh:227:                    [[ -z "$ds_id" ]] && continue
scripts/impact-analyzer.sh:229:                    if ! grep -qF "$ds_id" "$visited_file" 2>/dev/null; then
scripts/impact-analyzer.sh:260:    trap "rm -f '$queue_file' '$visited_file' '$result_file'" EXIT
scripts/impact-analyzer.sh:268:    while [[ -s "$queue_file" ]]; do
scripts/impact-analyzer.sh:270:        current=$(head -1 "$queue_file")
scripts/impact-analyzer.sh:271:        tail -n +2 "$queue_file" > "${queue_file}.tmp"
scripts/impact-analyzer.sh:275:        node_id=$(echo "$current" | cut -d'|' -f1)
scripts/impact-analyzer.sh:276:        depth=$(echo "$current" | cut -d'|' -f2)
scripts/impact-analyzer.sh:277:        impact=$(echo "$current" | cut -d'|' -f3)
scripts/impact-analyzer.sh:279:        if grep -qF "$node_id" "$visited_file" 2>/dev/null; then
scripts/impact-analyzer.sh:288:            if [[ -n "$info" ]]; then
scripts/impact-analyzer.sh:290:                sym=$(echo "$info" | cut -d'|' -f2)
scripts/impact-analyzer.sh:291:                kind=$(echo "$info" | cut -d'|' -f3)
scripts/impact-analyzer.sh:292:                file=$(echo "$info" | cut -d'|' -f4)
scripts/impact-analyzer.sh:296:                echo "$current_result" | jq --arg id "$node_id" \
scripts/impact-analyzer.sh:297:                                            --arg sym "$sym" \
scripts/impact-analyzer.sh:298:                                            --arg kind "$kind" \
scripts/impact-analyzer.sh:299:                                            --arg file "$file" \
scripts/impact-analyzer.sh:300:                                            --argjson depth "$depth" \
scripts/impact-analyzer.sh:301:                                            --argjson impact "$impact" \
scripts/impact-analyzer.sh:308:        if [[ "$depth" -lt "$max_depth" ]]; then
scripts/impact-analyzer.sh:319:                while IFS='|' read -r us_id us_sym us_file; do
scripts/impact-analyzer.sh:320:                    [[ -z "$us_id" ]] && continue
scripts/impact-analyzer.sh:321:                    if ! grep -qF "$us_id" "$visited_file" 2>/dev/null; then
scripts/impact-analyzer.sh:342:    while [[ $# -gt 0 ]]; do
scripts/impact-analyzer.sh:344:            --depth)
scripts/impact-analyzer.sh:348:            --decay)
scripts/impact-analyzer.sh:352:            --threshold)
scripts/impact-analyzer.sh:356:            --format)
scripts/impact-analyzer.sh:366:                if [[ -z "$symbol" ]]; then
scripts/impact-analyzer.sh:375:    if [[ -z "$symbol" ]]; then
scripts/impact-analyzer.sh:388:    if ! awk -v t="$threshold" 'BEGIN { exit !(t >= 0 && t <= 1) }'; then
scripts/impact-analyzer.sh:407:            jq -n \
scripts/impact-analyzer.sh:408:                --arg root "$symbol" \
scripts/impact-analyzer.sh:409:                --argjson depth "$depth" \
scripts/impact-analyzer.sh:410:                --argjson decay "$decay" \
scripts/impact-analyzer.sh:411:                --argjson threshold "$threshold" \
scripts/impact-analyzer.sh:412:                --argjson affected "$affected_nodes" \
scripts/impact-analyzer.sh:413:                --argjson total "$total_affected" \
scripts/impact-analyzer.sh:446:    while [[ $# -gt 0 ]]; do
scripts/impact-analyzer.sh:448:            --depth)
scripts/impact-analyzer.sh:452:            --decay)
scripts/impact-analyzer.sh:456:            --threshold)
scripts/impact-analyzer.sh:460:            --format)
scripts/impact-analyzer.sh:469:                if [[ -z "$file_path" ]]; then
scripts/impact-analyzer.sh:478:    if [[ -z "$file_path" ]]; then
scripts/impact-analyzer.sh:491:    if [[ -z "$symbols" ]]; then
scripts/impact-analyzer.sh:494:        jq -n \
scripts/impact-analyzer.sh:495:            --arg file "$file_path" \
scripts/impact-analyzer.sh:496:            --argjson depth "$depth" \
scripts/impact-analyzer.sh:511:    while IFS='|' read -r sym_id sym_name sym_kind; do
scripts/impact-analyzer.sh:512:        [[ -z "$sym_id" ]] && continue
scripts/impact-analyzer.sh:518:        while IFS= read -r node; do
scripts/impact-analyzer.sh:519:            [[ -z "$node" || "$node" == "null" ]] && continue
scripts/impact-analyzer.sh:522:            node_id=$(echo "$node" | jq -r '.id')
scripts/impact-analyzer.sh:527:                all_affected=$(echo "$all_affected" | jq --argjson node "$node" '. + [$node]')
scripts/impact-analyzer.sh:529:        done < <(echo "$affected" | jq -c '.[]')
scripts/impact-analyzer.sh:540:            jq -n \
scripts/impact-analyzer.sh:541:                --arg file "$file_path" \
scripts/impact-analyzer.sh:542:                --argjson depth "$depth" \
scripts/impact-analyzer.sh:543:                --argjson decay "$decay" \
scripts/impact-analyzer.sh:544:                --argjson threshold "$threshold" \
scripts/impact-analyzer.sh:545:                --argjson affected "$all_affected" \
scripts/impact-analyzer.sh:546:                --argjson total "$total_affected" \
scripts/impact-analyzer.sh:584:    echo "$affected_nodes" | jq -r '.[] | "\(.symbol)|\(.confidence)|\(.depth)"' | while IFS='|' read -r sym conf dep; do
scripts/impact-analyzer.sh:585:        [[ -z "$sym" ]] && continue
scripts/impact-analyzer.sh:593:        if [[ "$dep" -eq 1 ]]; then
scripts/impact-analyzer.sh:594:            echo "    ${root_name} -->|${conf_display}| ${sym}[${sym}:${conf_display}]"
scripts/impact-analyzer.sh:602:    echo "$affected_nodes" | jq -r 'sort_by(.depth) | .[] | "\(.symbol)|\(.confidence)|\(.depth)"' | while IFS='|' read -r sym conf dep; do
scripts/impact-analyzer.sh:603:        [[ -z "$sym" ]] && continue
scripts/impact-analyzer.sh:608:        if [[ "$dep" -gt 1 && -n "$prev_sym" && "$prev_depth" -eq $((dep - 1)) ]]; then
scripts/impact-analyzer.sh:609:            echo "    ${prev_sym} -->|${conf_display}| ${sym}[${sym}:${conf_display}]"
scripts/impact-analyzer.sh:630:    echo "$affected_nodes" | jq -r '.[] | "| \(.symbol) | \(.file_path) | \(.depth) | \(.confidence) |"'
scripts/impact-analyzer.sh:647:    --depth <n>             ÊúÄÂ§ßÈÅçÂéÜÊ∑±Â∫¶ÔºàÈªòËÆ§ 5Ôºâ
scripts/impact-analyzer.sh:648:    --decay <factor>        Ë°∞ÂáèÁ≥ªÊï∞ÔºàÈªòËÆ§ 0.8Ôºâ
scripts/impact-analyzer.sh:649:    --threshold <t>         ÂΩ±ÂìçÈòàÂÄºÔºàÈªòËÆ§ 0.1Ôºâ
scripts/impact-analyzer.sh:650:    --format <fmt>          ËæìÂá∫Ê†ºÂºè: json | md | mermaidÔºàÈªòËÆ§ jsonÔºâ
scripts/impact-analyzer.sh:653:    --depth <n>             ÊúÄÂ§ßÈÅçÂéÜÊ∑±Â∫¶ÔºàÈªòËÆ§ 5Ôºâ
scripts/impact-analyzer.sh:654:    --decay <factor>        Ë°∞ÂáèÁ≥ªÊï∞ÔºàÈªòËÆ§ 0.8Ôºâ
scripts/impact-analyzer.sh:655:    --threshold <t>         ÂΩ±ÂìçÈòàÂÄºÔºàÈªòËÆ§ 0.1Ôºâ
scripts/impact-analyzer.sh:656:    --format <fmt>          ËæìÂá∫Ê†ºÂºè: json | md | mermaidÔºàÈªòËÆ§ jsonÔºâ
scripts/impact-analyzer.sh:674:    impact-analyzer.sh analyze "sym:func:handleToolCall" --depth 3
scripts/impact-analyzer.sh:677:    impact-analyzer.sh file "src/server.ts" --depth 3
scripts/impact-analyzer.sh:680:    impact-analyzer.sh analyze "sym:func:main" --threshold 0.5
scripts/impact-analyzer.sh:683:    impact-analyzer.sh analyze "sym:func:main" --format mermaid
scripts/benchmark.sh:9:#   benchmark.sh --cache
scripts/benchmark.sh:10:#   benchmark.sh --full
scripts/benchmark.sh:11:#   benchmark.sh --all
scripts/benchmark.sh:16:set -euo pipefail
scripts/benchmark.sh:49:    if [[ -n "${DEVBOOKS_ENABLE_ALL_FEATURES:-}" ]]; then
scripts/benchmark.sh:53:    if [[ ! -f "$FEATURES_CONFIG_FILE" ]]; then
scripts/benchmark.sh:58:    value=$(awk -v feature="$feature" '
scripts/benchmark.sh:89:  benchmark.sh --dataset <self|public> --queries <file> --output <report.json>
scripts/benchmark.sh:90:  benchmark.sh --compare <baseline.json> <current.json>
scripts/benchmark.sh:91:  benchmark.sh --baseline <baseline.json>
scripts/benchmark.sh:94:  --dataset <self|public>  Êï∞ÊçÆÈõÜÁ±ªÂûã
scripts/benchmark.sh:95:  --queries <file>         Êü•ËØ¢ÈõÜÔºàJSONLÔºâ
scripts/benchmark.sh:96:  --output <file>          ËæìÂá∫Êä•ÂëäË∑ØÂæÑ
scripts/benchmark.sh:97:  --baseline <file>        Âü∫Á∫øÊä•ÂëäÔºàJSONÔºâ
scripts/benchmark.sh:98:  --compare <a> <b>        ÂØπÊØî‰∏§‰∏™Êä•ÂëäÂπ∂Ê£ÄÊµãÂõûÂΩí
scripts/benchmark.sh:99:  --enable-all-features    ÂøΩÁï•ÂäüËÉΩÂºÄÂÖ≥ÈÖçÁΩÆÔºåÂº∫Âà∂ÂêØÁî®ÊâÄÊúâÂäüËÉΩ
scripts/benchmark.sh:102:  --cache | --full | --precommit | --all
scripts/benchmark.sh:103:  --iterations <n>
scripts/benchmark.sh:110:    if date +%s%N 2>/dev/null | grep -q 'N'; then
scripts/benchmark.sh:112:        if command -v gdate &>/dev/null; then
scripts/benchmark.sh:114:        elif command -v perl &>/dev/null; then
scripts/benchmark.sh:115:            perl -MTime::HiRes -e 'printf "%d\n", Time::HiRes::time() * 1000'
scripts/benchmark.sh:129:    if [[ $count -lt 1 ]]; then
scripts/benchmark.sh:136:    sorted=$(printf '%s\n' "${values[@]}" | sort -n)
scripts/benchmark.sh:140:    p95_index=$(awk -v n="$count" 'BEGIN { idx = int(0.95 * n); if (0.95 * n > idx) idx++; print idx }')
scripts/benchmark.sh:142:    [[ $p95_index -lt 1 ]] && p95_index=1
scripts/benchmark.sh:143:    [[ $p95_index -gt $count ]] && p95_index=$count
scripts/benchmark.sh:145:    echo "$sorted" | awk -v idx="$p95_index" 'NR == idx { print; exit }'
scripts/benchmark.sh:151:    if [[ -z "$file" || ! -f "$file" ]]; then
scripts/benchmark.sh:169:    if [[ -z "$dataset" ]]; then
scripts/benchmark.sh:184:    if [[ -z "$queries_file" || ! -f "$queries_file" ]]; then
scripts/benchmark.sh:189:    if [[ -z "$output_file" ]]; then
scripts/benchmark.sh:197:    query_count=$(wc -l < "$queries_file" | tr -d ' ')
scripts/benchmark.sh:200:    if [[ "$query_count" -eq 0 ]]; then
scripts/benchmark.sh:211:    while IFS= read -r line; do
scripts/benchmark.sh:212:        [[ -z "$line" ]] && continue
scripts/benchmark.sh:215:        query=$(echo "$line" | jq -r '.query // empty' 2>/dev/null)
scripts/benchmark.sh:216:        [[ -z "$query" ]] && continue
scripts/benchmark.sh:218:        expected_files=$(echo "$line" | jq -r '.expected[]? // empty' 2>/dev/null)
scripts/benchmark.sh:225:            results=$(rg -l "$query" "$PROJECT_ROOT/src" "$PROJECT_ROOT/scripts" 2>/dev/null | head -10 || true)
scripts/benchmark.sh:227:            results=$(rg -l "$query" "$PROJECT_ROOT" 2>/dev/null | head -10 || true)
scripts/benchmark.sh:234:        if [[ -n "$expected_files" ]]; then
scripts/benchmark.sh:240:            retrieved_count=$(echo "$results" | grep -c . 2>/dev/null || echo 0)
scripts/benchmark.sh:241:            retrieved_count=$(echo "$retrieved_count" | tr -d '\n\r ')
scripts/benchmark.sh:243:            while IFS= read -r expected; do
scripts/benchmark.sh:244:                [[ -z "$expected" ]] && continue
scripts/benchmark.sh:248:                while IFS= read -r result; do
scripts/benchmark.sh:249:                    [[ -z "$result" ]] && continue
scripts/benchmark.sh:252:                    if echo "$result" | grep -qF "$expected"; then
scripts/benchmark.sh:262:            if [[ "$found" == "true" && "$rank" -gt 0 ]]; then
scripts/benchmark.sh:264:                rr=$(awk -v r="$rank" 'BEGIN {printf "%.6f", 1.0/r}')
scripts/benchmark.sh:265:                total_rr=$(awk -v t="$total_rr" -v r="$rr" 'BEGIN {printf "%.6f", t+r}')
scripts/benchmark.sh:269:                total_recall=$(awk -v t="$total_recall" 'BEGIN {printf "%.6f", t+1.0}')
scripts/benchmark.sh:272:            if [[ "$retrieved_count" -gt 0 && "$found" == "true" ]]; then
scripts/benchmark.sh:274:                prec=$(awk -v rel="$relevant_count" -v ret="$retrieved_count" 'BEGIN {printf "%.6f", rel/ret}')
scripts/benchmark.sh:275:                total_precision=$(awk -v t="$total_precision" -v p="$prec" 'BEGIN {printf "%.6f", t+p}')
scripts/benchmark.sh:282:    if [[ "$valid_queries" -eq 0 ]]; then
scripts/benchmark.sh:288:    mrr=$(awk -v t="$total_rr" -v n="$valid_queries" 'BEGIN {printf "%.6f", t/n}')
scripts/benchmark.sh:289:    recall=$(awk -v t="$total_recall" -v n="$valid_queries" 'BEGIN {printf "%.6f", t/n}')
scripts/benchmark.sh:290:    precision=$(awk -v t="$total_precision" -v n="$valid_queries" 'BEGIN {printf "%.6f", t/n}')
scripts/benchmark.sh:293:    mkdir -p "$(dirname "$output_file")"
scripts/benchmark.sh:294:    jq -n \
scripts/benchmark.sh:295:        --argjson mrr "$mrr" \
scripts/benchmark.sh:296:        --argjson recall "$recall" \
scripts/benchmark.sh:297:        --argjson precision "$precision" \
scripts/benchmark.sh:298:        --argjson p95 "$p95_latency" \
scripts/benchmark.sh:299:        --argjson queries "$valid_queries" \
scripts/benchmark.sh:320:    if [[ -z "$current_file" || ! -f "$current_file" ]]; then
scripts/benchmark.sh:331:    base_mrr=$(jq -r '.mrr_at_10 // 0' "$baseline_file")
scripts/benchmark.sh:332:    base_recall=$(jq -r '.recall_at_10 // 0' "$baseline_file")
scripts/benchmark.sh:333:    base_p95=$(jq -r '.p95_latency_ms // 0' "$baseline_file")
scripts/benchmark.sh:334:    curr_mrr=$(jq -r '.mrr_at_10 // 0' "$current_file")
scripts/benchmark.sh:335:    curr_recall=$(jq -r '.recall_at_10 // 0' "$current_file")
scripts/benchmark.sh:336:    curr_p95=$(jq -r '.p95_latency_ms // 0' "$current_file")
scripts/benchmark.sh:339:    if [[ -n "${BENCHMARK_REGRESSION_THRESHOLD:-}" ]]; then
scripts/benchmark.sh:342:        if ! echo "$threshold" | grep -qE '^[0-9]+\.?[0-9]*$'; then
scripts/benchmark.sh:346:        mrr_threshold=$(awk -v base="$base_mrr" -v thr="$threshold" 'BEGIN {printf "%.6f", base * (1 - thr)}')
scripts/benchmark.sh:347:        recall_threshold=$(awk -v base="$base_recall" -v thr="$threshold" 'BEGIN {printf "%.6f", base * (1 - thr)}')
scripts/benchmark.sh:348:        p95_threshold=$(awk -v base="$base_p95" -v thr="$threshold" 'BEGIN {printf "%.2f", base * (1 + thr)}')
scripts/benchmark.sh:350:        mrr_threshold=$(awk -v base="$base_mrr" 'BEGIN {printf "%.6f", base * 0.95}')
scripts/benchmark.sh:351:        recall_threshold=$(awk -v base="$base_recall" 'BEGIN {printf "%.6f", base * 0.95}')
scripts/benchmark.sh:352:        p95_threshold=$(awk -v base="$base_p95" 'BEGIN {printf "%.2f", base * 1.10}')
scripts/benchmark.sh:356:    if awk -v curr="$curr_mrr" -v thr="$mrr_threshold" 'BEGIN {exit !(curr < thr)}'; then
scripts/benchmark.sh:359:    if awk -v curr="$curr_recall" -v thr="$recall_threshold" 'BEGIN {exit !(curr < thr)}'; then
scripts/benchmark.sh:362:    if awk -v curr="$curr_p95" -v thr="$p95_threshold" 'BEGIN {exit !(curr > thr)}'; then
scripts/benchmark.sh:384:    if [[ ! -f "$test_file" ]]; then
scripts/benchmark.sh:394:    rm -rf "$CACHE_DIR" 2>/dev/null
scripts/benchmark.sh:395:    mkdir -p "$CACHE_DIR/l2"
scripts/benchmark.sh:398:    "$CACHE_SCRIPT" --set "$test_file" --query "$query_hash" --value "$test_value" 2>/dev/null
scripts/benchmark.sh:407:        "$CACHE_SCRIPT" --get "$test_file" --query "$query_hash" >/dev/null 2>&1 || true
scripts/benchmark.sh:419:    rm -rf "$CACHE_DIR" 2>/dev/null
scripts/benchmark.sh:423:    if [[ $p95 -lt $target ]]; then
scripts/benchmark.sh:449:    rm -rf "$CACHE_DIR" 2>/dev/null
scripts/benchmark.sh:458:        "$CACHE_SCRIPT" --get "$test_file" --query "$query_hash" >/dev/null 2>&1 || true
scripts/benchmark.sh:459:        "$CACHE_SCRIPT" --set "$test_file" --query "$query_hash" --value "result-$i" 2>/dev/null
scripts/benchmark.sh:471:    rm -rf "$CACHE_DIR" 2>/dev/null
scripts/benchmark.sh:475:    if [[ $p95 -lt $target ]]; then
scripts/benchmark.sh:494:    if [[ ! -x "$guard_script" ]]; then
scripts/benchmark.sh:505:        "$guard_script" --pre-commit --format json >/dev/null 2>&1 || true
scripts/benchmark.sh:521:        "$guard_script" --pre-commit --with-deps --format json >/dev/null 2>&1 || true
scripts/benchmark.sh:535:    if [[ $p95_staged -lt $target_staged ]]; then
scripts/benchmark.sh:541:    if [[ $p95_deps -lt $target_deps ]]; then
scripts/benchmark.sh:565:    while [[ $# -gt 0 ]]; do
scripts/benchmark.sh:567:            --dataset)
scripts/benchmark.sh:568:                if [[ -z "${2:-}" || "${2:-}" == --* ]]; then
scripts/benchmark.sh:576:            --queries)
scripts/benchmark.sh:581:            --output)
scripts/benchmark.sh:586:            --baseline)
scripts/benchmark.sh:591:            --compare)
scripts/benchmark.sh:597:            --enable-all-features)
scripts/benchmark.sh:601:            --cache)
scripts/benchmark.sh:605:            --full)
scripts/benchmark.sh:609:            --precommit)
scripts/benchmark.sh:613:            --all)
scripts/benchmark.sh:617:            --iterations)
scripts/benchmark.sh:621:            --help|-h)
scripts/benchmark.sh:632:        if [[ -n "$baseline" ]]; then
scripts/benchmark.sh:638:        if [[ -n "$compare_base" ]]; then
scripts/benchmark.sh:657:    mkdir -p "$EVIDENCE_DIR"
scripts/benchmark.sh:661:    timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
scripts/benchmark.sh:680:                echo "--- Cache Hit Benchmark ---"
scripts/benchmark.sh:683:                echo "--- Full Query Benchmark ---"
scripts/benchmark.sh:686:                echo "--- Pre-commit Benchmark ---"
scripts/call-chain.sh:12:#   call-chain-tracer.sh --symbol "funcName" [ÈÄâÈ°π]
scripts/call-chain.sh:18:set -euo pipefail
scripts/call-chain.sh:23:  if [[ -n "${_TEMP_FILES:-}" ]]; then
scripts/call-chain.sh:25:      [[ -f "$f" ]] && rm -f "$f" 2>/dev/null || true
scripts/call-chain.sh:30:  if declare -f _reset_data_flow_state &>/dev/null; then
scripts/call-chain.sh:44:if [ -f "$COMMON_LIB" ]; then
scripts/call-chain.sh:55:  log_info()  { echo -e "${BLUE}[CallChain]${NC} $1" >&2; }
scripts/call-chain.sh:56:  log_ok()    { echo -e "${GREEN}[CallChain]${NC} $1" >&2; }
scripts/call-chain.sh:57:  log_warn()  { echo -e "${YELLOW}[CallChain]${NC} $1" >&2; }
scripts/call-chain.sh:58:  log_error() { echo -e "${RED}[CallChain]${NC} $1" >&2; }
scripts/call-chain.sh:62:if declare -f check_dependencies &>/dev/null; then
scripts/call-chain.sh:65:  command -v jq &>/dev/null || { log_error "Áº∫Â∞ë‰æùËµñ: jq"; exit 2; }
scripts/call-chain.sh:72:if [ -f "$CORE_MODULE" ]; then
scripts/call-chain.sh:82:if [ -f "$TRACE_MODULE" ]; then
scripts/call-chain.sh:92:if [ -f "$DATAFLOW_MODULE" ]; then
scripts/call-chain.sh:133:    if [[ "${cycle_count:-0}" -gt 0 ]]; then
scripts/call-chain.sh:154:  jq -n \
scripts/call-chain.sh:155:    --arg version "1.0" \
scripts/call-chain.sh:156:    --arg symbol "$SYMBOL" \
scripts/call-chain.sh:157:    --arg direction "$DIRECTION" \
scripts/call-chain.sh:158:    --argjson depth "$DEPTH" \
scripts/call-chain.sh:159:    --argjson cycle "$CYCLE_DETECTED" \
scripts/call-chain.sh:160:    --argjson ckb_available "$CKB_AVAILABLE" \
scripts/call-chain.sh:161:    --argjson call_chain "$call_chain" \
scripts/call-chain.sh:185:  if [ "$current_depth" -ge "$max_depth" ]; then
scripts/call-chain.sh:198:    sym=$(echo "$node" | jq -r '.symbol_id // "?"')
scripts/call-chain.sh:199:    file=$(echo "$node" | jq -r '.file_path // "?"')
scripts/call-chain.sh:200:    line=$(echo "$node" | jq -r '.line // "?"')
scripts/call-chain.sh:208:    if [ "$(echo "$callers" | jq 'length')" -gt 0 ]; then
scripts/call-chain.sh:213:    if [ "$(echo "$callees" | jq 'length')" -gt 0 ]; then
scripts/call-chain.sh:232:      echo "# Mermaid Ê†ºÂºè‰ªÖÊîØÊåÅ --data-flow Ê®°Âºè"
scripts/call-chain.sh:243:      symbol=$(echo "$result" | jq -r '.target_symbol')
scripts/call-chain.sh:244:      direction=$(echo "$result" | jq -r '.direction')
scripts/call-chain.sh:245:      depth=$(echo "$result" | jq -r '.metadata.max_depth')
scripts/call-chain.sh:246:      cycle=$(echo "$result" | jq -r '.cycle_detected')
scripts/call-chain.sh:265:  if [[ "$DATA_FLOW_ENABLED" = true ]] && declare -f is_feature_enabled &>/dev/null; then
scripts/context-compressor.sh:10:set -euo pipefail
scripts/context-compressor.sh:13:declare -a _TEMP_FILES=()
scripts/context-compressor.sh:18:  if [[ ${#_TEMP_FILES[@]} -gt 0 ]]; then
scripts/context-compressor.sh:20:      [[ -f "$f" ]] && rm -f "$f" 2>/dev/null || true
scripts/context-compressor.sh:24:  if [[ -n "${_CACHE_LOCK:-}" ]] && [[ -f "$_CACHE_LOCK" ]]; then
scripts/context-compressor.sh:25:    rm -f "$_CACHE_LOCK" 2>/dev/null || true
scripts/context-compressor.sh:32:if [ -f "$COMMON_LIB" ]; then
scripts/context-compressor.sh:42:if declare -f check_dependencies &>/dev/null; then
scripts/context-compressor.sh:45:  command -v jq &>/dev/null || { log_error "Áº∫Â∞ë‰æùËµñ: jq"; exit 2; }
scripts/context-compressor.sh:67:  --mode <skeleton>           ÂéãÁº©Ê®°ÂºèÔºàÈªòËÆ§: skeletonÔºâ
scripts/context-compressor.sh:68:  --compress <low|medium|high> ÂéãÁº©Á∫ßÂà´ÔºàÈªòËÆ§: mediumÔºâ
scripts/context-compressor.sh:69:  --budget <n>                token È¢ÑÁÆóÔºàÊåâÈùûÁ©∫Ë°åËÆ°Ôºâ
scripts/context-compressor.sh:70:  --hotspot <dir>             ‰ª•ÁÉ≠Â∫¶‰ºòÂÖàÊéíÂ∫èÁõÆÂΩïÊñá‰ª∂
scripts/context-compressor.sh:71:  --cache [dir]               ÂêØÁî®ÁºìÂ≠òÔºàÂèØÈÄâÁõÆÂΩïÔºâ
scripts/context-compressor.sh:72:  --enable-all-features       ÂøΩÁï•ÂäüËÉΩÂºÄÂÖ≥ÈÖçÁΩÆÔºåÂº∫Âà∂ÂêØÁî®ÊâÄÊúâÂäüËÉΩ
scripts/context-compressor.sh:73:  --help                      ÊòæÁ§∫Â∏ÆÂä©
scripts/context-compressor.sh:78:  while [[ $# -gt 0 ]]; do
scripts/context-compressor.sh:80:      --mode)
scripts/context-compressor.sh:84:      --compress)
scripts/context-compressor.sh:88:      --budget)
scripts/context-compressor.sh:92:      --hotspot)
scripts/context-compressor.sh:96:      --cache)
scripts/context-compressor.sh:100:      --enable-all-features)
scripts/context-compressor.sh:104:      --help|-h)
scripts/context-compressor.sh:149:  if stat -f %z "$file" >/dev/null 2>&1; then
scripts/context-compressor.sh:150:    bytes=$(stat -f %z "$file")
scripts/context-compressor.sh:151:  elif stat -c %s "$file" >/dev/null 2>&1; then
scripts/context-compressor.sh:152:    bytes=$(stat -c %s "$file")
scripts/context-compressor.sh:154:    bytes=$(wc -c < "$file" 2>/dev/null || echo 0)
scripts/context-compressor.sh:156:  if [ "$bytes" -le 0 ]; then
scripts/context-compressor.sh:166:  if command -v node >/dev/null 2>&1; then
scripts/context-compressor.sh:167:    if node -e "require('typescript')" >/dev/null 2>&1; then
scripts/context-compressor.sh:186:  [ -z "$content" ] && return 0
scripts/context-compressor.sh:189:  paren_open=$(echo "$content" | tr -cd '(' | wc -c | tr -d ' ')
scripts/context-compressor.sh:190:  paren_close=$(echo "$content" | tr -cd ')' | wc -c | tr -d ' ')
scripts/context-compressor.sh:191:  brace_open=$(echo "$content" | tr -cd '{' | wc -c | tr -d ' ')
scripts/context-compressor.sh:192:  brace_close=$(echo "$content" | tr -cd '}' | wc -c | tr -d ' ')
scripts/context-compressor.sh:194:  if [ "$paren_open" -ne "$paren_close" ] || [ "$brace_open" -ne "$brace_close" ]; then
scripts/context-compressor.sh:204:  if stat -f %m "$path" >/dev/null 2>&1; then
scripts/context-compressor.sh:205:    stat -f %m "$path"
scripts/context-compressor.sh:206:  elif stat -c %Y "$path" >/dev/null 2>&1; then
scripts/context-compressor.sh:207:    stat -c %Y "$path"
scripts/context-compressor.sh:215:  if [ -f "$path" ]; then
scripts/context-compressor.sh:217:  elif [ -d "$path" ]; then
scripts/context-compressor.sh:218:    find "$path" -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" -o -name "*.mjs" -o -name "*.cjs" -o -name "*.py" \) 2>/dev/null
scripts/context-compressor.sh:231:  printf '%s\n' "${with_mtime[@]}" | sort -rn | cut -d'|' -f2
scripts/context-compressor.sh:237:  opens=$(printf '%s' "$line" | tr -cd '{' | wc -c)
scripts/context-compressor.sh:238:  closes=$(printf '%s' "$line" | tr -cd '}' | wc -c)
scripts/context-compressor.sh:324:  while IFS= read -r line || [ -n "$line" ]; do
scripts/context-compressor.sh:340:        if [ "${#decorator_lines[@]}" -gt 0 ]; then
scripts/context-compressor.sh:354:            if [ "$keep_body_lines" -eq 0 ]; then
scripts/context-compressor.sh:363:            if [ "$keep_body_lines" -eq 0 ]; then
scripts/context-compressor.sh:366:            if [ "$skip_depth" -le 0 ]; then
scripts/context-compressor.sh:377:      if [ "$keep_body_lines" -gt 0 ] && [ "$body_kept" -lt "$keep_body_lines" ]; then
scripts/context-compressor.sh:379:        if [[ -n "$line" ]]; then
scripts/context-compressor.sh:387:        if [ -n "$trimmed" ] && [ "$line_indent" -le "$body_indent" ]; then
scripts/context-compressor.sh:402:        if [ "$skip_depth" -le 0 ]; then
scripts/context-compressor.sh:432:        if [ "${#decorator_lines[@]}" -gt 0 ]; then
scripts/context-compressor.sh:445:            if [ "$keep_body_lines" -eq 0 ]; then
scripts/context-compressor.sh:454:            if [ "$keep_body_lines" -eq 0 ]; then
scripts/context-compressor.sh:457:            if [ "$skip_depth" -le 0 ]; then
scripts/context-compressor.sh:467:      if [ "${#decorator_lines[@]}" -gt 0 ]; then
scripts/context-compressor.sh:478:          if [ "$struct_depth" -gt 0 ]; then
scripts/context-compressor.sh:479:            while IFS= read -r inner_line || [ -n "$inner_line" ]; do
scripts/context-compressor.sh:484:              if [ "$struct_depth" -le 0 ]; then
scripts/context-compressor.sh:491:          while IFS= read -r inner_line || [ -n "$inner_line" ]; do
scripts/context-compressor.sh:504:  if [ "$in_signature" = true ] && [ "${#signature_lines[@]}" -gt 0 ]; then
scripts/context-compressor.sh:505:    if [ "${#decorator_lines[@]}" -gt 0 ]; then
scripts/context-compressor.sh:510:  elif [ "${#decorator_lines[@]}" -gt 0 ]; then
scripts/context-compressor.sh:522:  name=$(echo "$line" | sed -nE 's/.*function[[:space:]]+([A-Za-z_][A-Za-z0-9_]*)[^A-Za-z0-9_].*/\1/p')
scripts/context-compressor.sh:523:  if [ -z "$name" ]; then
scripts/context-compressor.sh:525:    name=$(echo "$line" | sed -nE 's/.*(async|public|private|protected|static)[[:space:]]+([A-Za-z_][A-Za-z0-9_]*)[[:space:]]*\(.*/\2/p')
scripts/context-compressor.sh:527:  if [ -z "$name" ] && echo "$line" | grep -q 'constructor[[:space:]]*('; then
scripts/context-compressor.sh:542:  while IFS= read -r line || [ -n "$line" ]; do
scripts/context-compressor.sh:548:        if [ -n "$current_name" ]; then
scripts/context-compressor.sh:550:            --arg name "$current_name" \
scripts/context-compressor.sh:551:            --arg signature "$signature_text" \
scripts/context-compressor.sh:552:            --arg file "$input_file" \
scripts/context-compressor.sh:569:        if [ -n "$current_name" ]; then
scripts/context-compressor.sh:571:            --arg name "$current_name" \
scripts/context-compressor.sh:572:            --arg signature "$signature_text" \
scripts/context-compressor.sh:573:            --arg file "$input_file" \
scripts/context-compressor.sh:589:  if [ -f "$cache_file" ]; then
scripts/context-compressor.sh:599:  mkdir -p "$CACHE_DIR"
scripts/context-compressor.sh:606:  if declare -f is_feature_enabled &>/dev/null; then
scripts/context-compressor.sh:614:  if [ "${#INPUT_PATHS[@]}" -eq 0 ] && [ -n "$HOTSPOT_DIR" ]; then
scripts/context-compressor.sh:618:  if [ "${#INPUT_PATHS[@]}" -eq 0 ]; then
scripts/context-compressor.sh:637:    while IFS= read -r f; do
scripts/context-compressor.sh:638:      [ -n "$f" ] && _MAIN_FILES+=("$f")
scripts/context-compressor.sh:642:  if [ "${#_MAIN_FILES[@]}" -eq 0 ]; then
scripts/context-compressor.sh:647:  if [ -n "$HOTSPOT_DIR" ]; then
scripts/context-compressor.sh:649:    while IFS= read -r f; do
scripts/context-compressor.sh:650:      [ -n "$f" ] && sorted+=("$f")
scripts/context-compressor.sh:669:  if [ "$size_mb" -gt "$CONTEXT_COMPRESSOR_MAX_MB" ]; then
scripts/context-compressor.sh:678:  if [ "$original_count" -eq 0 ]; then
scripts/context-compressor.sh:690:  key_count=$(printf '%s\n' "$content" | grep -cE '^[[:space:]]*(@|export|import|class|interface|type|enum|function|async|public|private|protected|constructor)\b' || true)
scripts/context-compressor.sh:695:  if [ "$CACHE_ENABLED" = true ] && declare -f hash_string_md5 &>/dev/null; then
scripts/context-compressor.sh:731:  if [ -n "$_OUTPUT_COMPRESSED_CONTEXT" ]; then
scripts/context-compressor.sh:732:    compressed_key_lines=$(echo "$_OUTPUT_COMPRESSED_CONTEXT" | grep -cE '^[[:space:]]*(@|export|import|class|interface|type|enum|function|async|public|private|protected|constructor)\b' || true)
scripts/context-compressor.sh:736:  if [ "$_OUTPUT_ORIGINAL_TOKENS" -gt 0 ]; then
scripts/context-compressor.sh:737:    if declare -f float_calc &>/dev/null; then
scripts/context-compressor.sh:740:      compression_ratio=$(awk -v c="$_OUTPUT_COMPRESSED_TOKENS" -v o="$_OUTPUT_ORIGINAL_TOKENS" 'BEGIN {printf "%.2f", (o>0?c/o:0)}')
scripts/context-compressor.sh:745:  if [ "$_OUTPUT_ORIGINAL_KEY_LINES" -gt 0 ]; then
scripts/context-compressor.sh:746:    if declare -f float_calc &>/dev/null; then
scripts/context-compressor.sh:749:      retention_rate=$(awk -v c="$compressed_key_lines" -v o="$_OUTPUT_ORIGINAL_KEY_LINES" 'BEGIN {printf "%.2f", (o>0?c/o:0)}')
scripts/context-compressor.sh:759:  jq -n \
scripts/context-compressor.sh:760:    --rawfile compressed_context "$temp_context_file" \
scripts/context-compressor.sh:761:    --arg mode "$MODE" \
scripts/context-compressor.sh:762:    --arg level "$COMPRESS_LEVEL" \
scripts/context-compressor.sh:763:    --argjson files "$_OUTPUT_FILES_JSON" \
scripts/context-compressor.sh:764:    --argjson preserved_signatures "$_OUTPUT_SIGNATURES_JSON" \
scripts/context-compressor.sh:765:    --argjson original_tokens "$_OUTPUT_ORIGINAL_TOKENS" \
scripts/context-compressor.sh:766:    --argjson compressed_tokens "$_OUTPUT_COMPRESSED_TOKENS" \
scripts/context-compressor.sh:767:    --argjson cache_hits "$_OUTPUT_CACHE_HITS" \
scripts/context-compressor.sh:768:    --argjson file_count "$_OUTPUT_FILE_COUNT" \
scripts/context-compressor.sh:769:    --argjson truncated "$_OUTPUT_TRUNCATED" \
scripts/context-compressor.sh:770:    --argjson budget "${BUDGET:-0}" \
scripts/context-compressor.sh:771:    --argjson compression_ratio "$compression_ratio" \
scripts/context-compressor.sh:772:    --argjson retention_rate "$retention_rate" \
scripts/context-compressor.sh:828:    if [ -z "$compressed_context" ]; then
scripts/context-compressor.sh:837:    if [ "$original_count" -gt 0 ]; then
scripts/context-compressor.sh:838:      if declare -f float_calc &>/dev/null; then
scripts/context-compressor.sh:841:        file_ratio=$(awk -v c="$file_tokens" -v o="$original_count" 'BEGIN {printf "%.2f", (o>0?c/o:0)}')
scripts/context-compressor.sh:845:    if [ -n "$file_sigs" ] && [ "$file_sigs" != "[]" ]; then
scripts/context-compressor.sh:846:      signatures_json=$(echo "$signatures_json" | jq --argjson sigs "$file_sigs" '. + $sigs')
scripts/context-compressor.sh:850:      --arg path "$input" \
scripts/context-compressor.sh:851:      --argjson original_tokens "$original_count" \
scripts/context-compressor.sh:852:      --argjson compressed_tokens "$file_tokens" \
scripts/context-compressor.sh:853:      --argjson compression_ratio "$file_ratio" \
scripts/context-compressor.sh:856:    if [ -n "${BUDGET:-}" ] && [[ "$BUDGET" =~ ^[0-9]+$ ]] && [ "$compressed_tokens" -gt "$BUDGET" ]; then
scripts/context-compressor.sh:862:  if [ -n "${BUDGET:-}" ] && [[ "$BUDGET" =~ ^[0-9]+$ ]] && [ "$compressed_tokens" -gt "$BUDGET" ]; then
scripts/context-compressor.sh:864:    compressed_context=$(printf '%s\n' "$compressed_context" | awk -v limit="$BUDGET" 'NF {count++} count<=limit {print} END {if (count>limit) exit 0}')
scripts/llm-providers/openai.sh:23:  if [[ -n "${LLM_MOCK_RESPONSE:-}" ]]; then
scripts/llm-providers/openai.sh:25:    if [[ -n "${LLM_MOCK_DELAY_MS:-}" ]]; then
scripts/llm-providers/openai.sh:27:      [[ "$delay_sec" -gt 0 ]] && sleep "$delay_sec" 2>/dev/null || true
scripts/llm-providers/openai.sh:31:    if [[ -n "${LLM_MOCK_FAIL_COUNT:-}" && "${LLM_MOCK_FAIL_COUNT}" -gt 0 ]]; then
scripts/llm-providers/openai.sh:58:  if [[ $mock_status -eq 0 ]]; then
scripts/llm-providers/openai.sh:61:  elif [[ $mock_status -eq 1 ]]; then
scripts/llm-providers/openai.sh:66:  if [[ -z "$_OPENAI_API_KEY" ]]; then
scripts/llm-providers/openai.sh:81:    file_path=$(echo "$candidate" | jq -r '.file_path // .file // ""')
scripts/llm-providers/openai.sh:82:    content=$(echo "$candidate" | jq -r '.content // ""' | head -c 500)
scripts/llm-providers/openai.sh:87:---"
scripts/llm-providers/openai.sh:111:  if [[ $api_status -ne 0 ]]; then
scripts/llm-providers/openai.sh:118:  ranked=$(echo "$response" | grep -oE '\[.*\]' | head -1)
scripts/llm-providers/openai.sh:120:  if [[ -z "$ranked" ]]; then
scripts/llm-providers/openai.sh:126:  if ! echo "$ranked" | jq -e '.' &>/dev/null; then
scripts/llm-providers/openai.sh:144:  if [[ $mock_status -eq 0 ]]; then
scripts/llm-providers/openai.sh:147:  elif [[ $mock_status -eq 1 ]]; then
scripts/llm-providers/openai.sh:152:  if [[ -z "$_OPENAI_API_KEY" ]]; then
scripts/llm-providers/openai.sh:164:  if [[ -z "$_OPENAI_API_KEY" ]]; then
scripts/llm-providers/openai.sh:169:  if command -v curl &>/dev/null; then
scripts/llm-providers/openai.sh:171:    response=$(curl -s --connect-timeout 3 \
scripts/llm-providers/openai.sh:172:      -H "Authorization: Bearer $_OPENAI_API_KEY" \
scripts/llm-providers/openai.sh:177:    if echo "$response" | jq -e '.error' &>/dev/null; then
scripts/llm-providers/openai.sh:194:  if ! command -v curl &>/dev/null; then
scripts/llm-providers/openai.sh:200:  if ! command -v jq &>/dev/null; then
scripts/llm-providers/openai.sh:207:  request_body=$(jq -n \
scripts/llm-providers/openai.sh:208:    --arg model "$_OPENAI_MODEL" \
scripts/llm-providers/openai.sh:209:    --arg prompt "$prompt" \
scripts/llm-providers/openai.sh:210:    --argjson max_tokens "$_OPENAI_MAX_TOKENS" \
scripts/llm-providers/openai.sh:219:  response=$(timeout "$_OPENAI_TIMEOUT_SEC" curl -s \
scripts/llm-providers/openai.sh:220:    -X POST "${_OPENAI_API_BASE}/chat/completions" \
scripts/llm-providers/openai.sh:221:    -H "Content-Type: application/json" \
scripts/llm-providers/openai.sh:222:    -H "Authorization: Bearer $_OPENAI_API_KEY" \
scripts/llm-providers/openai.sh:223:    -d "$request_body" 2>/dev/null)
scripts/llm-providers/openai.sh:226:  if [[ $exit_code -eq 124 ]]; then
scripts/llm-providers/openai.sh:232:  if echo "$response" | jq -e '.error' &>/dev/null; then
scripts/llm-providers/openai.sh:234:    error_msg=$(echo "$response" | jq -r '.error.message // .error.type // "Unknown error"')
scripts/llm-providers/openai.sh:241:  content=$(echo "$response" | jq -r '.choices[0].message.content // empty' 2>/dev/null)
scripts/llm-providers/openai.sh:243:  if [[ -z "$content" ]]; then
scripts/cache-utils.sh:13:  mkdir -p "$CACHE_DIR" 2>/dev/null
scripts/cache-utils.sh:23:  if command -v md5sum &>/dev/null; then
scripts/cache-utils.sh:24:    echo "$input" | md5sum | cut -d' ' -f1
scripts/cache-utils.sh:25:  elif command -v md5 &>/dev/null; then
scripts/cache-utils.sh:29:    echo "$input" | cksum | cut -d' ' -f1
scripts/cache-utils.sh:43:  if [ -f "$cache_file" ]; then
scripts/cache-utils.sh:46:    if stat -f %m "$cache_file" &>/dev/null; then
scripts/cache-utils.sh:48:      file_mtime=$(stat -f %m "$cache_file")
scripts/cache-utils.sh:49:    elif stat -c %Y "$cache_file" &>/dev/null; then
scripts/cache-utils.sh:51:      file_mtime=$(stat -c %Y "$cache_file")
scripts/cache-utils.sh:61:    if [ "$age" -lt "$CACHE_TTL" ]; then
scripts/cache-utils.sh:85:  if [ -d "$CACHE_DIR" ]; then
scripts/cache-utils.sh:86:    find "$CACHE_DIR" -type f -mmin +$((CACHE_TTL / 60 + 1)) -delete 2>/dev/null
scripts/cache-utils.sh:93:  if [ -d "$CACHE_DIR" ]; then
scripts/cache-utils.sh:94:    rm -rf "${CACHE_DIR:?}"/* 2>/dev/null
scripts/graph-rag-query.sh:15:  if [ "$char_count" -gt 0 ] && [ "$conservative_estimate" -lt 1 ]; then
scripts/graph-rag-query.sh:27:  if [ -f "$full_path" ]; then
scripts/graph-rag-query.sh:29:    content=$(head -50 "$full_path" 2>/dev/null)
scripts/graph-rag-query.sh:41:  relevance=$(echo "$candidate_json" | jq -r '.relevance // .relevance_score // 0')
scripts/graph-rag-query.sh:42:  hotspot=$(echo "$candidate_json" | jq -r '.hotspot // 0')
scripts/graph-rag-query.sh:43:  distance=$(echo "$candidate_json" | jq -r '.distance // .depth // 1')
scripts/graph-rag-query.sh:45:  if [ -z "$distance" ] || [ "$distance" = "null" ] || [ "$distance" = "0" ]; then
scripts/graph-rag-query.sh:49:  awk -v r="$relevance" -v h="$hotspot" -v d="$distance" \
scripts/graph-rag-query.sh:50:    -v wr="$PRIORITY_WEIGHT_RELEVANCE" -v wh="$PRIORITY_WEIGHT_HOTSPOT" -v wd="$PRIORITY_WEIGHT_DISTANCE" \
scripts/graph-rag-query.sh:83:    file_path=$(echo "$candidate" | jq -r '.file_path')
scripts/graph-rag-query.sh:88:      --argjson priority "$priority" \
scripts/graph-rag-query.sh:89:      --argjson tokens "$tokens" \
scripts/graph-rag-query.sh:92:    result=$(echo "$result" | jq --argjson c "$candidate" '. + [$c]')
scripts/graph-rag-query.sh:107:  if [ "$budget" -lt 0 ]; then
scripts/graph-rag-query.sh:122:  if [ "$budget" -eq 0 ]; then
scripts/graph-rag-query.sh:140:    file_path=$(echo "$candidate" | jq -r '.file_path')
scripts/graph-rag-query.sh:143:    content_tokens=$(echo "$candidate" | jq -r '.tokens // 0')
scripts/graph-rag-query.sh:145:    if [ "$content_tokens" -eq 0 ]; then
scripts/graph-rag-query.sh:149:    if [ "$content_tokens" -gt "$budget" ]; then
scripts/graph-rag-query.sh:155:    if [ $((total_tokens + content_tokens)) -gt "$budget" ]; then
scripts/graph-rag-query.sh:160:    result=$(echo "$result" | jq --argjson c "$candidate" '. + [$c]')
scripts/graph-rag-query.sh:163:  if [ "$(echo "$result" | jq 'length')" -eq 0 ] && [ "$skipped_oversized" -gt 0 ]; then
scripts/graph-rag-query.sh:185:    file_path=$(echo "$candidate" | jq -r '.file_path')
scripts/graph-rag-query.sh:186:    symbol_id=$(echo "$candidate" | jq -r '.symbol_id // empty')
scripts/graph-rag-query.sh:187:    relevance_score=$(echo "$candidate" | jq -r '.relevance_score // 0')
scripts/graph-rag-query.sh:188:    depth=$(echo "$candidate" | jq -r '.depth // 0')
scripts/graph-rag-query.sh:191:    if [ -n "$symbol_id" ] && [ "$symbol_id" != "null" ]; then
scripts/graph-rag-query.sh:197:    nodes=$(echo "$nodes" | jq --arg id "$node_id" --arg file "$file_path" \
scripts/graph-rag-query.sh:198:      --argjson score "$relevance_score" --argjson depth "$depth" \
scripts/graph-rag-query.sh:211:      caller_id=$(echo "$caller" | jq -r '.symbol_id // .file_path // empty')
scripts/graph-rag-query.sh:212:      if [ -n "$caller_id" ] && [ "$caller_id" != "null" ]; then
scripts/graph-rag-query.sh:213:        edges=$(echo "$edges" | jq --arg from "$caller_id" --arg to "$node_id" \
scripts/graph-rag-query.sh:224:      callee_id=$(echo "$callee" | jq -r '.symbol_id // .file_path // empty')
scripts/graph-rag-query.sh:225:      if [ -n "$callee_id" ] && [ "$callee_id" != "null" ]; then
scripts/graph-rag-query.sh:226:        edges=$(echo "$edges" | jq --arg from "$node_id" --arg to "$callee_id" \
scripts/graph-rag-query.sh:232:  jq -n --argjson nodes "$nodes" --argjson edges "$edges" \
scripts/graph-rag-query.sh:253:  if [ -n "$cached" ]; then
scripts/graph-rag-query.sh:264:  [ -z "$vector_candidates" ] && vector_candidates='[]'
scripts/graph-rag-query.sh:269:  [ -z "$keyword_candidates" ] && keyword_candidates='[]'
scripts/graph-rag-query.sh:271:  if [ "$FUSION_DEPTH" -gt 0 ]; then
scripts/graph-rag-query.sh:274:      if [ -z "$graph_candidates" ] || [ "$graph_candidates" = "[]" ]; then
scripts/graph-rag-query.sh:283:    [ -z "$graph_candidates" ] && graph_candidates='[]'
scripts/graph-rag-query.sh:288:    if [ -z "$candidates" ] || [ "$candidates" = "[]" ]; then
scripts/graph-rag-query.sh:293:  if [ -z "$candidates" ] || [ "$candidates" = "[]" ]; then
scripts/graph-rag-query.sh:302:  if [ -n "$MIN_RELEVANCE" ] && [[ "$MIN_RELEVANCE" != "0" ]] && [[ "$MIN_RELEVANCE" != "0.0" ]]; then
scripts/graph-rag-query.sh:303:    candidates=$(echo "$candidates" | jq --argjson threshold "$MIN_RELEVANCE" \
scripts/graph-rag-query.sh:315:    if [[ -f "$rerank_state_file" ]]; then
scripts/graph-rag-query.sh:318:      rm -f "$rerank_state_file"
scripts/graph-rag-query.sh:334:    precomputed_tokens=$(echo "$trimmed" | jq -r ".[$i].tokens // 0")
scripts/graph-rag-query.sh:336:    if [ "$precomputed_tokens" -gt 0 ]; then
scripts/graph-rag-query.sh:340:      file_path=$(echo "$trimmed" | jq -r ".[$i].file_path")
scripts/graph-rag-query.sh:343:      if [ -f "$full_path" ]; then
scripts/graph-rag-query.sh:345:        content=$(head -50 "$full_path" 2>/dev/null)
scripts/graph-rag-query.sh:362:  result=$(jq -n \
scripts/graph-rag-query.sh:363:    --arg version "1.0" \
scripts/graph-rag-query.sh:364:    --arg source "graph-rag" \
scripts/graph-rag-query.sh:365:    --argjson tokens "$total_tokens" \
scripts/graph-rag-query.sh:366:    --argjson subgraph "$subgraph" \
scripts/graph-rag-query.sh:367:    --argjson candidates "$trimmed" \
scripts/graph-rag-query.sh:368:    --argjson ckb_available "$CKB_AVAILABLE" \
scripts/graph-rag-query.sh:369:    --argjson graph_depth "$MAX_DEPTH" \
scripts/graph-rag-query.sh:370:    --argjson fusion_depth "$FUSION_DEPTH" \
scripts/graph-rag-query.sh:371:    --arg fusion_weights "${HYBRID_WEIGHT_KEYWORD},${HYBRID_WEIGHT_VECTOR},${HYBRID_WEIGHT_GRAPH}" \
scripts/graph-rag-query.sh:372:    --argjson boundary_filtered "$BOUNDARY_FILTERED_COUNT" \
scripts/graph-rag-query.sh:373:    --argjson legacy "$LEGACY_MODE" \
scripts/graph-rag-query.sh:374:    --argjson reranked "$RERANK_RESULT_RERANKED" \
scripts/graph-rag-query.sh:375:    --argjson truncated "$RERANK_RESULT_TRUNCATED" \
scripts/graph-rag-query.sh:376:    --arg provider "${RERANK_RESULT_PROVIDER:-}" \
scripts/graph-rag-query.sh:377:    --arg fallback_reason "${RERANK_RESULT_FALLBACK_REASON:-}" \
scripts/graph-rag-query.sh:378:    --arg ckb_fallback_reason "$ckb_fallback_reason" \
scripts/graph-rag-query.sh:379:    --argjson retry_count "${RERANK_RESULT_RETRY_COUNT:-0}" \
scripts/graph-rag-query.sh:380:    --argjson max_candidate_length "${RERANK_RESULT_MAX_CANDIDATE_LENGTH:-0}" \
scripts/graph-rag-query.sh:381:    --argjson graph_candidates_count "$graph_candidates_count" \
scripts/graph-rag-query.sh:430:    [ "$filtered_count" -gt 0 ] && echo "ÔºàÂ∑≤ËøáÊª§ $filtered_count ‰∏™Â∫ì‰ª£Á†ÅÊñá‰ª∂Ôºâ"
scripts/graph-rag-query.sh:433:    if [ "$edge_count" -gt 0 ] && [ "$LEGACY_MODE" = false ]; then
scripts/graph-rag-query.sh:436:      while [ "$j" -lt "$edge_count" ] && [ "$j" -lt 20 ]; do
scripts/graph-rag-query.sh:440:        from=$(echo "$edge" | jq -r '.from')
scripts/graph-rag-query.sh:441:        to=$(echo "$edge" | jq -r '.to')
scripts/graph-rag-query.sh:442:        edge_type=$(echo "$edge" | jq -r '.type')
scripts/graph-rag-query.sh:445:          echo "  $from --calls--> $to"
scripts/graph-rag-query.sh:447:          echo "  $from --refs--> $to"
scripts/graph-rag-query.sh:459:      file_path=$(echo "$candidate" | jq -r '.file_path')
scripts/graph-rag-query.sh:460:      score=$(echo "$candidate" | jq -r '.relevance_score // "N/A"')
scripts/graph-rag-query.sh:465:      if [ -f "$full_path" ]; then
scripts/graph-rag-query.sh:467:        head -10 "$full_path" 2>/dev/null | sed 's/^/  /'
scripts/dependency-guard-rules.sh:19:    if [[ ! -f "$rules_file" ]]; then
scripts/dependency-guard-rules.sh:37:    while IFS= read -r line || [[ -n "$line" ]]; do
scripts/dependency-guard-rules.sh:40:        [[ -z "${line// }" ]] && continue
scripts/dependency-guard-rules.sh:60:                config=$(echo "$config" | jq --arg v "$val" '.on_violation = $v')
scripts/dependency-guard-rules.sh:68:                ignore_list=$(echo "$ignore_list" | jq --arg v "${BASH_REMATCH[1]}" '. + [$v]')
scripts/dependency-guard-rules.sh:77:                    current_rule=$(echo "$current_rule" | jq --argjson ci "$cannot_import_list" '.cannot_import = $ci')
scripts/dependency-guard-rules.sh:78:                    current_rule=$(echo "$current_rule" | jq --argjson wl "$whitelist" '.whitelist = $wl')
scripts/dependency-guard-rules.sh:79:                    rules=$(echo "$rules" | jq --argjson rule "$current_rule" '. + [$rule]')
scripts/dependency-guard-rules.sh:82:                current_rule=$(jq -n --arg name "${BASH_REMATCH[1]}" '{"name": $name}')
scripts/dependency-guard-rules.sh:92:                current_rule=$(echo "$current_rule" | jq --arg v "${BASH_REMATCH[1]}" '.from = $v')
scripts/dependency-guard-rules.sh:96:                current_rule=$(echo "$current_rule" | jq --arg v "${BASH_REMATCH[1]}" '.severity = $v')
scripts/dependency-guard-rules.sh:100:                current_rule=$(echo "$current_rule" | jq --arg v "${BASH_REMATCH[1]}" '.type = $v')
scripts/dependency-guard-rules.sh:104:                current_rule=$(echo "$current_rule" | jq --arg v "${BASH_REMATCH[1]}" '.scope = $v')
scripts/dependency-guard-rules.sh:120:                cannot_import_list=$(echo "$cannot_import_list" | jq --arg v "${BASH_REMATCH[1]}" '. + [$v]')
scripts/dependency-guard-rules.sh:124:                whitelist=$(echo "$whitelist" | jq --arg v "${BASH_REMATCH[1]}" '. + [$v]')
scripts/dependency-guard-rules.sh:131:        current_rule=$(echo "$current_rule" | jq --argjson ci "$cannot_import_list" '.cannot_import = $ci')
scripts/dependency-guard-rules.sh:132:        current_rule=$(echo "$current_rule" | jq --argjson wl "$whitelist" '.whitelist = $wl')
scripts/dependency-guard-rules.sh:133:        rules=$(echo "$rules" | jq --argjson rule "$current_rule" '. + [$rule]')
scripts/dependency-guard-rules.sh:136:    config=$(echo "$config" | jq --argjson ignore "$ignore_list" '.ignore = $ignore')
scripts/dependency-guard-rules.sh:158:    if [[ -z "$patterns_json" || "$patterns_json" == "null" ]]; then
scripts/dependency-guard-rules.sh:162:    while IFS= read -r pattern; do
scripts/dependency-guard-rules.sh:163:        [[ -z "$pattern" ]] && continue
scripts/dependency-guard-rules.sh:167:    done < <(echo "$patterns_json" | jq -r '.[]' 2>/dev/null)
scripts/dependency-guard-rules.sh:190:    while IFS= read -r file; do
scripts/dependency-guard-rules.sh:191:        [[ -n "$file" ]] && files+=("$file")
scripts/dependency-guard-rules.sh:192:    done < <(find "$scope" -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \) 2>/dev/null)
scripts/dependency-guard-rules.sh:203:        while IFS= read -r rule; do
scripts/dependency-guard-rules.sh:204:            [[ -n "$rule" ]] && rules_arr+=("$rule")
scripts/dependency-guard-rules.sh:205:        done < <(echo "$import_rules" | jq -c '.[]' 2>/dev/null)
scripts/dependency-guard-rules.sh:209:            from_pattern=$(echo "$rule" | jq -r '.from // ""')
scripts/dependency-guard-rules.sh:211:            [[ -z "$from_pattern" ]] && continue
scripts/dependency-guard-rules.sh:216:                cannot_import=$(echo "$rule" | jq -c '.cannot_import // []')
scripts/dependency-guard-rules.sh:218:                rule_name=$(echo "$rule" | jq -r '.name')
scripts/dependency-guard-rules.sh:220:                severity=$(echo "$rule" | jq -r '.severity // "error"')
scripts/dependency-guard-rules.sh:228:                while IFS= read -r imp; do
scripts/dependency-guard-rules.sh:229:                    [[ -n "$imp" ]] && imps_arr+=("$imp")
scripts/dependency-guard-rules.sh:230:                done < <(echo "$imports" | jq -c '.[]' 2>/dev/null)
scripts/dependency-guard-rules.sh:234:                    target=$(echo "$imp" | jq -r '.target')
scripts/dependency-guard-rules.sh:236:                    line=$(echo "$imp" | jq -r '.line')
scripts/dependency-guard-rules.sh:240:                    [[ -z "$resolved" ]] && continue
scripts/dependency-guard-rules.sh:250:                    while IFS= read -r pattern; do
scripts/dependency-guard-rules.sh:251:                        [[ -n "$pattern" ]] && patterns_arr+=("$pattern")
scripts/dependency-guard-rules.sh:252:                    done < <(echo "$cannot_import" | jq -r '.[]' 2>/dev/null)
scripts/dependency-guard-rules.sh:259:                                --arg rule "$rule_name" \
scripts/dependency-guard-rules.sh:260:                                --arg severity "$severity" \
scripts/dependency-guard-rules.sh:261:                                --arg source "$rel_path" \
scripts/dependency-guard-rules.sh:262:                                --arg target "$rel_resolved" \
scripts/dependency-guard-rules.sh:263:                                --argjson line "$line" \
scripts/dependency-guard-rules.sh:264:                                --arg msg "Violation of rule '$rule_name': $rel_path imports $rel_resolved" \
scripts/dependency-guard-rules.sh:274:    rm -f "$temp_violations"
scripts/dependency-guard-rules.sh:291:        [[ -f "$file" ]] || continue
scripts/dependency-guard-rules.sh:298:        while IFS= read -r rule; do
scripts/dependency-guard-rules.sh:300:            from_pattern=$(echo "$rule" | jq -r '.from // ""')
scripts/dependency-guard-rules.sh:302:            [[ -z "$from_pattern" ]] && continue
scripts/dependency-guard-rules.sh:306:                cannot_import=$(echo "$rule" | jq -c '.cannot_import // []')
scripts/dependency-guard-rules.sh:308:                rule_name=$(echo "$rule" | jq -r '.name')
scripts/dependency-guard-rules.sh:310:                severity=$(echo "$rule" | jq -r '.severity // "error"')
scripts/dependency-guard-rules.sh:315:                while IFS= read -r imp; do
scripts/dependency-guard-rules.sh:317:                    target=$(echo "$imp" | jq -r '.target')
scripts/dependency-guard-rules.sh:319:                    line=$(echo "$imp" | jq -r '.line')
scripts/dependency-guard-rules.sh:323:                    [[ -z "$resolved" ]] && continue
scripts/dependency-guard-rules.sh:331:                    while IFS= read -r pattern; do
scripts/dependency-guard-rules.sh:334:                                --arg rule "$rule_name" \
scripts/dependency-guard-rules.sh:335:                                --arg severity "$severity" \
scripts/dependency-guard-rules.sh:336:                                --arg source "$rel_path" \
scripts/dependency-guard-rules.sh:337:                                --arg target "$rel_resolved" \
scripts/dependency-guard-rules.sh:338:                                --argjson line "$line" \
scripts/dependency-guard-rules.sh:339:                                --arg msg "Violation of rule '$rule_name': $rel_path imports $rel_resolved" \
scripts/dependency-guard-rules.sh:342:                    done < <(echo "$cannot_import" | jq -r '.[]' 2>/dev/null)
scripts/dependency-guard-rules.sh:343:                done < <(echo "$imports" | jq -c '.[]' 2>/dev/null)
scripts/dependency-guard-rules.sh:345:        done < <(echo "$import_rules" | jq -c '.[]' 2>/dev/null)
scripts/dependency-guard-rules.sh:356:    if [[ ! -f "$rules_file" ]]; then
scripts/entropy-viz.sh:11:#   devbooks-entropy-viz.sh --output <file> [ÈÄâÈ°π]
scripts/entropy-viz.sh:16:set -euo pipefail
scripts/entropy-viz.sh:25:if [ -f "$COMMON_LIB" ]; then
scripts/entropy-viz.sh:37:  log_info()  { echo -e "${BLUE}[EntropyViz]${NC} $1" >&2; }
scripts/entropy-viz.sh:38:  log_ok()    { echo -e "${GREEN}[EntropyViz]${NC} $1" >&2; }
scripts/entropy-viz.sh:39:  log_warn()  { echo -e "${YELLOW}[EntropyViz]${NC} $1" >&2; }
scripts/entropy-viz.sh:40:  log_error() { echo -e "${RED}[EntropyViz]${NC} $1" >&2; }
scripts/entropy-viz.sh:55:if [[ -n "${NO_COLOR:-}" ]]; then
scripts/entropy-viz.sh:67:  devbooks-entropy-viz.sh --output <file> [ÈÄâÈ°π]
scripts/entropy-viz.sh:70:  --output <file>         ËæìÂá∫Êñá‰ª∂Ë∑ØÂæÑÔºàÂøÖÈúÄÔºâ
scripts/entropy-viz.sh:71:  --config <file>         ÈÖçÁΩÆÊñá‰ª∂Ë∑ØÂæÑ
scripts/entropy-viz.sh:72:  --no-visualization      Á¶ÅÁî®ÂèØËßÜÂåñÔºàËæìÂá∫‰º†ÁªüÊ†ºÂºèÔºâ
scripts/entropy-viz.sh:73:  --version               ÊòæÁ§∫ÁâàÊú¨
scripts/entropy-viz.sh:74:  --help                  ÊòæÁ§∫Ê≠§Â∏ÆÂä©
scripts/entropy-viz.sh:82:  devbooks-entropy-viz.sh --output entropy-report.md
scripts/entropy-viz.sh:85:  devbooks-entropy-viz.sh --output report.md --no-visualization
scripts/entropy-viz.sh:88:  devbooks-entropy-viz.sh --config .devbooks/config.yaml --output report.md
scripts/entropy-viz.sh:100:  while [[ $# -gt 0 ]]; do
scripts/entropy-viz.sh:102:      --output)
scripts/entropy-viz.sh:106:      --config)
scripts/entropy-viz.sh:110:      --no-visualization)
scripts/entropy-viz.sh:117:      --version)
scripts/entropy-viz.sh:121:      --help|-h)
scripts/entropy-viz.sh:133:  if [ -z "$OUTPUT_FILE" ]; then
scripts/entropy-viz.sh:134:    log_error "ÂøÖÈ°ªÊèê‰æõ --output ÂèÇÊï∞"
scripts/entropy-viz.sh:142:  if [ -n "$CONFIG_FILE" ] && [ -f "$CONFIG_FILE" ]; then
scripts/entropy-viz.sh:144:    if command -v yq &>/dev/null; then
scripts/entropy-viz.sh:150:      if grep -q 'entropy_visualization: false' "$CONFIG_FILE" 2>/dev/null; then
scripts/entropy-viz.sh:155:      if grep -q 'entropy_mermaid: false' "$CONFIG_FILE" 2>/dev/null; then
scripts/entropy-viz.sh:158:      if grep -q 'entropy_ascii_dashboard: false' "$CONFIG_FILE" 2>/dev/null; then
scripts/entropy-viz.sh:172:  if [[ -n "${MOCK_INSUFFICIENT_HISTORY:-}" ]]; then
scripts/entropy-viz.sh:206:    if [[ "${value:-0}" -ge "${threshold_good:-70}" ]]; then
scripts/entropy-viz.sh:208:    elif [[ "${value:-0}" -ge "${threshold_warn:-50}" ]]; then
scripts/entropy-viz.sh:214:    if [[ "${value:-0}" -ge "${threshold_good:-70}" ]]; then
scripts/entropy-viz.sh:216:    elif [[ "${value:-0}" -ge "${threshold_warn:-50}" ]]; then
scripts/entropy-viz.sh:248:  trend=$(echo "$metrics_json" | jq -r '.trend | @csv' 2>/dev/null | tr ',' ' ')
scripts/entropy-viz.sh:257:  echo "    y-axis \"Health Score\" 0 --> 100"
scripts/entropy-viz.sh:274:  echo "$metrics_json" | jq -r '.hotspots[] | "\(.file)|\(.complexity)|\(.churn)"' 2>/dev/null | while IFS='|' read -r file complexity churn; do
scripts/entropy-viz.sh:290:  health=$(echo "$metrics_json" | jq -r '.overall_health' 2>/dev/null || echo "72")
scripts/entropy-viz.sh:297:  struct_entropy=$(echo "$metrics_json" | jq -r '.metrics.structure_entropy' 2>/dev/null || echo "0.45")
scripts/entropy-viz.sh:299:  change_entropy=$(echo "$metrics_json" | jq -r '.metrics.change_entropy' 2>/dev/null || echo "0.38")
scripts/entropy-viz.sh:301:  test_entropy=$(echo "$metrics_json" | jq -r '.metrics.test_entropy' 2>/dev/null || echo "0.52")
scripts/entropy-viz.sh:303:  dep_entropy=$(echo "$metrics_json" | jq -r '.metrics.dependency_entropy' 2>/dev/null || echo "0.31")
scripts/entropy-viz.sh:327:  history_days=$(echo "$metrics_json" | jq -r '.history_days' 2>/dev/null || echo "30")
scripts/entropy-viz.sh:336:  if [[ "$history_days" -lt 7 ]]; then
scripts/entropy-viz.sh:384:  mkdir -p "$output_dir" 2>/dev/null || true
scripts/graph-rag.sh:12:#   graph-rag-context.sh --query "Êü•ËØ¢ÂÜÖÂÆπ" [ÈÄâÈ°π]
scripts/graph-rag.sh:19:set -euo pipefail
scripts/graph-rag.sh:29:if [ -f "$COMMON_LIB" ]; then
scripts/graph-rag.sh:41:  log_info()  { echo -e "${BLUE}[Graph-RAG]${NC} $1" >&2; }
scripts/graph-rag.sh:42:  log_ok()    { echo -e "${GREEN}[Graph-RAG]${NC} $1" >&2; }
scripts/graph-rag.sh:43:  log_warn()  { echo -e "${YELLOW}[Graph-RAG]${NC} $1" >&2; }
scripts/graph-rag.sh:44:  log_error() { echo -e "${RED}[Graph-RAG]${NC} $1" >&2; }
scripts/graph-rag.sh:48:if declare -f check_dependencies &>/dev/null; then
scripts/graph-rag.sh:51:  command -v jq &>/dev/null || { log_error "Áº∫Â∞ë‰æùËµñ: jq"; exit 2; }
scripts/graph-rag.sh:80:  graph-rag-context.sh --query "Êü•ËØ¢ÂÜÖÂÆπ" [ÈÄâÈ°π]
scripts/graph-rag.sh:83:  --query <text>        Êü•ËØ¢ÂÜÖÂÆπÔºàÂøÖÈúÄÔºâ
scripts/graph-rag.sh:84:  --top-k <n>           ÂêëÈáèÊêúÁ¥¢ËøîÂõûÊï∞ÈáèÔºàÈªòËÆ§: 10Ôºâ
scripts/graph-rag.sh:85:  --depth <n>           ÂõæÈÅçÂéÜÊúÄÂ§ßÊ∑±Â∫¶ 1-5ÔºàÈªòËÆ§: 3Ôºâ
scripts/graph-rag.sh:86:  --fusion-depth <n>    ËûçÂêàÊü•ËØ¢Ê∑±Â∫¶ 0-5ÔºàÈªòËÆ§: 1Ôºå0=‰ªÖÂêëÈáèÊêúÁ¥¢Ôºâ
scripts/graph-rag.sh:87:  --fusion-weights <w>  Ê∑∑ÂêàÊ£ÄÁ¥¢ÊùÉÈáç "keyword,vector,graph"ÔºàÈªòËÆ§: 0.3,0.5,0.2ÔºåÊÄªÂíåÈ°ª=1.0Ôºâ
scripts/graph-rag.sh:88:  --token-budget <n>    Token È¢ÑÁÆóÔºàÈªòËÆ§: 8000Ôºâ
scripts/graph-rag.sh:89:  --budget <n>          Âêå --token-budget
scripts/graph-rag.sh:90:  --min-relevance <n>   ÊúÄ‰ΩéÁõ∏ÂÖ≥Â∫¶ÈòàÂÄºÔºàÈªòËÆ§: 0.0Ôºâ
scripts/graph-rag.sh:91:  --cwd <path>          Â∑•‰ΩúÁõÆÂΩïÔºàÈªòËÆ§: ÂΩìÂâçÁõÆÂΩïÔºâ
scripts/graph-rag.sh:92:  --format <text|json>  ËæìÂá∫Ê†ºÂºèÔºàÈªòËÆ§: textÔºâ
scripts/graph-rag.sh:93:  --rerank              ÂêØÁî® LLM ÈáçÊéíÂ∫èÔºàÈªòËÆ§ÂÖ≥Èó≠Ôºâ
scripts/graph-rag.sh:94:  --no-rerank           Á¶ÅÁî®ÈáçÊéíÂ∫èÔºàCLI Ë¶ÜÁõñÈÖçÁΩÆÔºâ
scripts/graph-rag.sh:95:  --legacy              ‰ΩøÁî®Á∫øÊÄßÂàóË°®ËæìÂá∫ÔºàÂÖºÂÆπÊóßÁâàÊú¨Ôºâ
scripts/graph-rag.sh:96:  --include-virtual     ÂåÖÂê´ËôöÊãüËæπÊü•ËØ¢ÔºàÂÆûÈ™åÊÄßÔºâ
scripts/graph-rag.sh:97:  --enable-all-features ÂøΩÁï•ÂäüËÉΩÂºÄÂÖ≥ÈÖçÁΩÆÔºåÂº∫Âà∂ÂêØÁî®ÊâÄÊúâÂäüËÉΩ
scripts/graph-rag.sh:98:  --mock-embedding      ‰ΩøÁî®Ê®°Êãü Embedding Êï∞ÊçÆÔºàÊµãËØïÁî®Ôºâ
scripts/graph-rag.sh:99:  --mock-ckb            ‰ΩøÁî®Ê®°Êãü CKB Êï∞ÊçÆÔºàÊµãËØïÁî®Ôºâ
scripts/graph-rag.sh:100:  --version             ÊòæÁ§∫ÁâàÊú¨
scripts/graph-rag.sh:101:  --help                ÊòæÁ§∫Ê≠§Â∏ÆÂä©
scripts/graph-rag.sh:105:  graph-rag-context.sh --query "Áî®Êà∑ËÆ§ËØÅÁõ∏ÂÖ≥ÁöÑÂáΩÊï∞"
scripts/graph-rag.sh:108:  graph-rag-context.sh --query "Â§ÑÁêÜÊîØ‰ªòÁöÑ‰ª£Á†Å" --top-k 20 --max-depth 3
scripts/graph-rag.sh:111:  graph-rag-context.sh --query "ÈîôËØØÂ§ÑÁêÜ" --format json
scripts/graph-rag.sh:159:  # Workaround: If first arg doesn't start with --, treat it as query
scripts/graph-rag.sh:160:  # This handles cases where --query flag is dropped by MCP transport
scripts/graph-rag.sh:161:  if [[ $# -gt 0 ]] && [[ "$1" != --* ]]; then
scripts/graph-rag.sh:166:  while [[ $# -gt 0 ]]; do
scripts/graph-rag.sh:168:      --query)
scripts/graph-rag.sh:172:      --top-k)
scripts/graph-rag.sh:176:      --depth|--max-depth)
scripts/graph-rag.sh:180:      --fusion-depth)
scripts/graph-rag.sh:184:      --fusion-weights)
scripts/graph-rag.sh:186:        IFS=',' read -r HYBRID_WEIGHT_KEYWORD HYBRID_WEIGHT_VECTOR HYBRID_WEIGHT_GRAPH <<< "$2"
scripts/graph-rag.sh:188:        if command -v bc >/dev/null 2>&1; then
scripts/graph-rag.sh:191:          diff=$(echo "scale=4; x = $weight_sum - 1.0; if (x < 0) -x else x" | bc)
scripts/graph-rag.sh:193:          if [ "$is_valid" -ne 1 ]; then
scripts/graph-rag.sh:200:          is_valid=$(awk "BEGIN {diff = $weight_sum - 1.0; if (diff < 0) diff = -diff; print (diff < 0.01) ? 1 : 0}")
scripts/graph-rag.sh:201:          if [ "$is_valid" -ne 1 ]; then
scripts/graph-rag.sh:209:      --token-budget|--budget)
scripts/graph-rag.sh:213:      --min-relevance)
scripts/graph-rag.sh:217:      --cwd)
scripts/graph-rag.sh:220:        if [[ -z "${FEATURES_CONFIG:-}" ]]; then
scripts/graph-rag.sh:223:        if [[ -z "${DEVBOOKS_FEATURE_CONFIG:-}" ]]; then
scripts/graph-rag.sh:228:      --format)
scripts/graph-rag.sh:232:      --legacy)
scripts/graph-rag.sh:236:      --rerank)
scripts/graph-rag.sh:241:      --no-rerank)
scripts/graph-rag.sh:247:      --include-virtual)
scripts/graph-rag.sh:251:      --enable-all-features)
scripts/graph-rag.sh:256:      --mock-embedding)
scripts/graph-rag.sh:260:      --mock-ckb)
scripts/graph-rag.sh:264:      --version)
scripts/graph-rag.sh:268:      --help|-h)
scripts/graph-rag.sh:280:  if [ -z "$QUERY" ]; then
scripts/graph-rag.sh:281:    log_error "ÂøÖÈ°ªÊèê‰æõ --query ÂèÇÊï∞"
scripts/graph-rag.sh:289:  elif [ "$MAX_DEPTH" -lt 1 ]; then
scripts/graph-rag.sh:292:  elif [ "$MAX_DEPTH" -gt "$MAX_ALLOWED_DEPTH" ]; then
scripts/graph-rag.sh:302:  elif [ "$FUSION_DEPTH" -lt 0 ]; then
scripts/graph-rag.sh:306:  elif [ "$FUSION_DEPTH" -gt "$MAX_ALLOWED_DEPTH" ]; then
scripts/graph-rag.sh:324:  if [[ "$HYBRID_ENABLED" != "true" ]] && [[ "$FUSION_DEPTH" -gt 0 ]]; then
scripts/cache-manager.sh:9:#   cache-manager.sh --get <file_path> --query <query_hash>
scripts/cache-manager.sh:10:#   cache-manager.sh --set <file_path> --query <query_hash> --value <value>
scripts/cache-manager.sh:11:#   cache-manager.sh --clear-l1
scripts/cache-manager.sh:12:#   cache-manager.sh --stats
scripts/cache-manager.sh:13:#   cache-manager.sh --help
scripts/cache-manager.sh:24:set -euo pipefail
scripts/cache-manager.sh:50:if [[ "${BASH_VERSION%%.*}" -ge 4 ]]; then
scripts/cache-manager.sh:51:    declare -A L1_CACHE=()
scripts/cache-manager.sh:52:    declare -A FILE_MTIME_CACHE=()
scripts/cache-manager.sh:53:    declare -A L1_META_MTIME=()
scripts/cache-manager.sh:54:    declare -A L1_META_BLOB_HASH=()
scripts/cache-manager.sh:86:    if command -v gdate &>/dev/null; then
scripts/cache-manager.sh:88:    elif date +%s%3N 2>/dev/null | grep -qv 'N'; then
scripts/cache-manager.sh:90:    elif command -v perl &>/dev/null; then
scripts/cache-manager.sh:91:        perl -MTime::HiRes=gettimeofday -e 'my ($s, $us) = gettimeofday(); printf "%d%03d\n", $s, $us/1000;'
scripts/cache-manager.sh:98:        if [[ -f "$counter_file" ]]; then
scripts/cache-manager.sh:115:    mkdir -p "$(dirname "$SUBGRAPH_CACHE_DB")" 2>/dev/null || true
scripts/cache-manager.sh:118:    if ! command -v sqlite3 &>/dev/null; then
scripts/cache-manager.sh:126:-- Enable WAL mode for concurrent reads (REQ-SLC-001)
scripts/cache-manager.sh:129:-- Create cache table (REQ-SLC-002)
scripts/cache-manager.sh:130:-- Use 'key' and 'value' column names for test compatibility
scripts/cache-manager.sh:139:-- Create index on access_time for LRU eviction (REQ-SLC-003)
scripts/cache-manager.sh:142:-- Create index on ttl_expires for TTL expiration (MP8.3)
scripts/cache-manager.sh:145:-- Create statistics table for tracking hit/miss (REQ-SLC-009)
scripts/cache-manager.sh:151:-- Initialize statistics
scripts/cache-manager.sh:161:    if [[ ! -f "$SUBGRAPH_CACHE_DB" ]]; then
scripts/cache-manager.sh:188:-- Update access time if key exists (MP8.1: LRU tracking)
scripts/cache-manager.sh:190:-- Get the value
scripts/cache-manager.sh:192:-- Update hit/miss counter
scripts/cache-manager.sh:199:    if [[ -n "$result" ]]; then
scripts/cache-manager.sh:237:    [[ $evict_count -lt 1 ]] && evict_count=1
scripts/cache-manager.sh:244:    if [[ "$current_count" -ge "$max_size" ]]; then
scripts/cache-manager.sh:246:        if [[ -n "${CACHE_EVICTION_LOG:-}" ]]; then
scripts/cache-manager.sh:250:            if [[ -n "$evicted_keys" ]]; then
scripts/cache-manager.sh:265:-- First, clean up expired entries (MP8.3: TTL expiration)
scripts/cache-manager.sh:268:-- Evict oldest 20% if at capacity (MP8.1: LRU eviction)
scripts/cache-manager.sh:269:-- Order by access_time ASC, then created_time ASC (for tie-breaking)
scripts/cache-manager.sh:279:-- Insert or replace (preserving created_time if exists)
scripts/cache-manager.sh:328:    [[ -z "$oldest_access" ]] && oldest_access=0
scripts/cache-manager.sh:329:    [[ -z "$newest_access" ]] && newest_access=0
scripts/cache-manager.sh:330:    [[ -z "$hits" ]] && hits=0
scripts/cache-manager.sh:331:    [[ -z "$misses" ]] && misses=0
scripts/cache-manager.sh:336:    if [[ $total_requests -gt 0 ]]; then
scripts/cache-manager.sh:341:    if [[ -f "$SUBGRAPH_CACHE_DB" ]]; then
scripts/cache-manager.sh:342:        cache_size_bytes=$(stat -c %s "$SUBGRAPH_CACHE_DB" 2>/dev/null || stat -f %z "$SUBGRAPH_CACHE_DB" 2>/dev/null || echo "0")
scripts/cache-manager.sh:348:        jq -n \
scripts/cache-manager.sh:349:            --argjson total_entries "$total_entries" \
scripts/cache-manager.sh:350:            --argjson oldest_access "$oldest_access" \
scripts/cache-manager.sh:351:            --argjson newest_access "$newest_access" \
scripts/cache-manager.sh:352:            --argjson hits "$hits" \
scripts/cache-manager.sh:353:            --argjson misses "$misses" \
scripts/cache-manager.sh:354:            --arg hit_rate "$hit_rate" \
scripts/cache-manager.sh:355:            --argjson cache_size_bytes "$cache_size_bytes" \
scripts/cache-manager.sh:382:  cache-manager.sh --get <file_path> --query <query_hash> [--debug]
scripts/cache-manager.sh:383:  cache-manager.sh --set <file_path> --query <query_hash> --value <value>
scripts/cache-manager.sh:384:  cache-manager.sh --clear-l1
scripts/cache-manager.sh:385:  cache-manager.sh --stats
scripts/cache-manager.sh:386:  cache-manager.sh --help
scripts/cache-manager.sh:396:  --get         Get cached value for file and query
scripts/cache-manager.sh:397:  --set         Set cache value for file and query
scripts/cache-manager.sh:398:  --clear-l1    Clear L1 (memory) cache
scripts/cache-manager.sh:399:  --stats       Show cache statistics (L1/L2)
scripts/cache-manager.sh:400:  --debug       Enable debug output
scripts/cache-manager.sh:401:  --help        Show this help message
scripts/cache-manager.sh:402:  --format      Output format for stats (json or text)
scripts/cache-manager.sh:420:  cache-manager.sh --get src/server.ts --query abc123
scripts/cache-manager.sh:423:  cache-manager.sh --set src/server.ts --query abc123 --value "result data"
scripts/cache-manager.sh:426:  cache-manager.sh --clear-l1
scripts/cache-manager.sh:429:  cache-manager.sh --stats
scripts/cache-manager.sh:434:  cache-manager.sh stats --format json
scripts/cache-manager.sh:447:    if [[ ! -f "$file_path" ]]; then
scripts/cache-manager.sh:453:    if stat -c %Y "$file_path" 2>/dev/null; then
scripts/cache-manager.sh:455:    elif stat -f %m "$file_path" 2>/dev/null; then
scripts/cache-manager.sh:469:    if [[ ! -f "$file_path" ]]; then
scripts/cache-manager.sh:475:    if command -v git &>/dev/null && git rev-parse --is-inside-work-tree &>/dev/null 2>&1; then
scripts/cache-manager.sh:476:        if git ls-files --error-unmatch "$file_path" &>/dev/null 2>&1; then
scripts/cache-manager.sh:485:    if command -v md5sum &>/dev/null; then
scripts/cache-manager.sh:486:        md5sum "$file_path" 2>/dev/null | cut -d' ' -f1
scripts/cache-manager.sh:487:    elif command -v md5 &>/dev/null; then
scripts/cache-manager.sh:488:        md5 -q "$file_path" 2>/dev/null
scripts/cache-manager.sh:491:        cksum "$file_path" 2>/dev/null | cut -d' ' -f1
scripts/cache-manager.sh:506:    if command -v md5sum &>/dev/null; then
scripts/cache-manager.sh:507:        printf '%s' "$combined" | md5sum | cut -d' ' -f1
scripts/cache-manager.sh:508:    elif command -v md5 &>/dev/null; then
scripts/cache-manager.sh:509:        if md5 -q /dev/null >/dev/null 2>&1; then
scripts/cache-manager.sh:510:            printf '%s' "$combined" | md5 -q
scripts/cache-manager.sh:515:        printf '%s' "$combined" | cksum | cut -d' ' -f1
scripts/cache-manager.sh:532:    mkdir -p "$mtime_cache_dir" 2>/dev/null
scripts/cache-manager.sh:536:    safe_name=$(printf '%s' "$file_path" | md5sum 2>/dev/null | cut -d' ' -f1 || printf '%s' "$file_path" | md5 -q 2>/dev/null || echo "default")
scripts/cache-manager.sh:540:    if [[ -f "$mtime_file" ]]; then
scripts/cache-manager.sh:548:    if [[ -z "${L1_CACHE_DISABLED:-}" ]]; then
scripts/cache-manager.sh:556:        if [[ $delta -ge 0 && $delta -lt 1 ]]; then
scripts/cache-manager.sh:572:    if [[ ! -f "$cache_file" ]]; then
scripts/cache-manager.sh:578:    schema_version=$(jq -r '.schema_version // ""' "$cache_file" 2>/dev/null)
scripts/cache-manager.sh:586:    cached_mtime=$(jq -r '.mtime // 0' "$cache_file" 2>/dev/null)
scripts/cache-manager.sh:594:    cached_blob_hash=$(jq -r '.blob_hash // ""' "$cache_file" 2>/dev/null)
scripts/cache-manager.sh:613:    if [[ ! -d "$cache_l2_dir" ]]; then
scripts/cache-manager.sh:619:    current_size_kb=$(du -sk "$cache_l2_dir" 2>/dev/null | cut -f1 || echo "0")
scripts/cache-manager.sh:625:    while [[ $current_size_kb -ge $max_size_kb ]]; do
scripts/cache-manager.sh:630:        total_files=$(find "$cache_l2_dir" -type f -name "*.json" 2>/dev/null | wc -l | tr -d ' ')
scripts/cache-manager.sh:632:        if [[ "$total_files" -lt 1 ]]; then
scripts/cache-manager.sh:638:        [[ $evict_count -lt 1 ]] && evict_count=1
scripts/cache-manager.sh:644:        find "$cache_l2_dir" -type f -name "*.json" -exec sh -c '
scripts/cache-manager.sh:646:                accessed=$(jq -r ".accessed_at // 0" "$f" 2>/dev/null || echo "0")
scripts/cache-manager.sh:649:        ' _ {} + | sort -n | head -n "$evict_count" > "$tmp_file"
scripts/cache-manager.sh:652:        while IFS= read -r line; do
scripts/cache-manager.sh:654:            file_to_delete=$(echo "$line" | cut -d' ' -f2-)
scripts/cache-manager.sh:655:            if [[ -f "$file_to_delete" ]]; then
scripts/cache-manager.sh:656:                rm -f "$file_to_delete"
scripts/cache-manager.sh:661:        rm -f "$tmp_file"
scripts/cache-manager.sh:665:        current_size_kb=$(du -sk "$cache_l2_dir" 2>/dev/null | cut -f1 || echo "0")
scripts/cache-manager.sh:668:        if [[ $current_size_kb -lt $target_size_kb ]]; then
scripts/cache-manager.sh:686:    if [[ -f "$file_path" ]]; then
scripts/cache-manager.sh:694:    if [[ -z "${L1_CACHE_DISABLED:-}" ]] && [[ -n "${L1_CACHE[$l1_key]:-}" ]]; then
scripts/cache-manager.sh:697:        if [[ -n "$cached_mtime" && -n "$cached_blob_hash" ]]; then
scripts/cache-manager.sh:712:    if [[ -z "$current_mtime" ]]; then
scripts/cache-manager.sh:727:    if [[ -z "$current_blob_hash" ]]; then
scripts/cache-manager.sh:737:    if [[ -f "$cache_file" ]]; then
scripts/cache-manager.sh:741:            value=$(jq -r '.value // ""' "$cache_file" 2>/dev/null)
scripts/cache-manager.sh:747:            if jq --arg accessed_at "$current_time" '.accessed_at = ($accessed_at | tonumber)' "$cache_file" > "$tmp_file" 2>/dev/null; then
scripts/cache-manager.sh:748:                mv "$tmp_file" "$cache_file" 2>/dev/null || rm -f "$tmp_file"
scripts/cache-manager.sh:750:                rm -f "$tmp_file" 2>/dev/null
scripts/cache-manager.sh:754:            if [[ -z "${L1_CACHE_DISABLED:-}" ]]; then
scripts/cache-manager.sh:782:    if [[ -f "$file_path" ]]; then
scripts/cache-manager.sh:787:    mkdir -p "${CACHE_DIR}/l2" 2>/dev/null
scripts/cache-manager.sh:806:        if command -v flock &>/dev/null; then
scripts/cache-manager.sh:807:            flock -x 200 2>/dev/null || true
scripts/cache-manager.sh:814:        jq -n \
scripts/cache-manager.sh:815:            --arg schema_version "$CACHE_SCHEMA_VERSION" \
scripts/cache-manager.sh:816:            --arg key "$cache_key" \
scripts/cache-manager.sh:817:            --arg file_path "$file_path" \
scripts/cache-manager.sh:818:            --arg mtime "$mtime" \
scripts/cache-manager.sh:819:            --arg blob_hash "$blob_hash" \
scripts/cache-manager.sh:820:            --arg query_hash "$query_hash" \
scripts/cache-manager.sh:821:            --arg value "$value" \
scripts/cache-manager.sh:822:            --arg created_at "$current_time" \
scripts/cache-manager.sh:823:            --arg accessed_at "$current_time" \
scripts/cache-manager.sh:837:        mv "$tmp_file" "$cache_file" 2>/dev/null || rm -f "$tmp_file"
scripts/cache-manager.sh:845:    if [[ -z "${L1_CACHE_DISABLED:-}" ]]; then
scripts/cache-manager.sh:857:    if [[ -z "${L1_CACHE_DISABLED:-}" ]]; then
scripts/cache-manager.sh:871:    if [[ -z "${L1_CACHE_DISABLED:-}" ]]; then
scripts/cache-manager.sh:878:    if [[ -d "$cache_l2_dir" ]]; then
scripts/cache-manager.sh:879:        l2_entries=$(find "$cache_l2_dir" -type f -name "*.json" 2>/dev/null | wc -l | tr -d ' ')
scripts/cache-manager.sh:880:        size_kb=$(du -sk "$cache_l2_dir" 2>/dev/null | cut -f1 || echo "0")
scripts/cache-manager.sh:884:    jq -n \
scripts/cache-manager.sh:885:        --arg l1_entries "$l1_entries" \
scripts/cache-manager.sh:886:        --arg l2_entries "$l2_entries" \
scripts/cache-manager.sh:887:        --arg size_kb "$size_kb" \
scripts/cache-manager.sh:888:        --arg size_mb "$size_mb" \
scripts/cache-manager.sh:889:        --arg max_size_mb "$CACHE_MAX_SIZE_MB" \
scripts/cache-manager.sh:890:        --arg cache_dir "$CACHE_DIR" \
scripts/cache-manager.sh:891:        --arg schema_version "$CACHE_SCHEMA_VERSION" \
scripts/cache-manager.sh:915:    if [[ $# -gt 0 ]]; then
scripts/cache-manager.sh:919:                if [[ $# -lt 1 ]]; then
scripts/cache-manager.sh:928:                if [[ $# -lt 2 ]]; then
scripts/cache-manager.sh:937:                if [[ $# -lt 1 ]]; then
scripts/cache-manager.sh:951:                # Parse --format option
scripts/cache-manager.sh:952:                while [[ $# -gt 0 ]]; do
scripts/cache-manager.sh:954:                        --format)
scripts/cache-manager.sh:970:    while [[ $# -gt 0 ]]; do
scripts/cache-manager.sh:972:            --get)
scripts/cache-manager.sh:976:            --set)
scripts/cache-manager.sh:980:            --clear-l1)
scripts/cache-manager.sh:984:            --stats)
scripts/cache-manager.sh:988:            --help|-h)
scripts/cache-manager.sh:992:            --debug)
scripts/cache-manager.sh:996:            --query)
scripts/cache-manager.sh:1000:            --value)
scripts/cache-manager.sh:1004:            --format)
scripts/cache-manager.sh:1014:                if [[ -z "$file_path" ]]; then
scripts/cache-manager.sh:1023:    if ! command -v jq &>/dev/null; then
scripts/cache-manager.sh:1030:            if [[ -z "$file_path" ]] || [[ -z "$query_hash" ]]; then
scripts/cache-manager.sh:1031:                log_error "Usage: cache-manager.sh --get <file_path> --query <query_hash>"
scripts/cache-manager.sh:1037:            if [[ -z "$file_path" ]] || [[ -z "$query_hash" ]] || [[ -z "$value" ]]; then
scripts/cache-manager.sh:1038:                log_error "Usage: cache-manager.sh --set <file_path> --query <query_hash> --value <value>"
scripts/reranker.sh:11:#   reranker.sh --query "Êü•ËØ¢ÂÜÖÂÆπ" [ÈÄâÈ°π] < candidates.json
scripts/reranker.sh:12:#   echo '{"candidates":[...]}' | reranker.sh --query "Êü•ËØ¢"
scripts/reranker.sh:20:set -euo pipefail
scripts/reranker.sh:25:  if [[ -n "${_TEMP_FILES:-}" ]]; then
scripts/reranker.sh:27:      [[ -f "$f" ]] && rm -f "$f" 2>/dev/null || true
scripts/reranker.sh:38:if [[ -f "$SCRIPT_DIR/llm-provider.sh" ]]; then
scripts/reranker.sh:44:  if [[ -f "$SCRIPT_DIR/common.sh" ]]; then
scripts/reranker.sh:73:  reranker.sh --query "Êü•ËØ¢ÂÜÖÂÆπ" [ÈÄâÈ°π] < candidates.json
scripts/reranker.sh:74:  echo '{"candidates":[...]}' | reranker.sh --query "Êü•ËØ¢"
scripts/reranker.sh:77:  --query <text>        Êü•ËØ¢ÂÜÖÂÆπÔºàÂøÖÈúÄÔºâ
scripts/reranker.sh:78:  --provider <name>     LLM Provider (anthropic/openai/ollama/mockÔºåÈªòËÆ§Ëá™Âä®Ê£ÄÊµã)
scripts/reranker.sh:79:  --model <name>        ÈáçÊéíÂ∫èÊ®°ÂûãÔºàÈªòËÆ§Ê†πÊçÆ Provider ÂÜ≥ÂÆöÔºâ
scripts/reranker.sh:80:  --input <file>        ËæìÂÖ•Êñá‰ª∂ÔºàÈªòËÆ§: stdinÔºâ
scripts/reranker.sh:81:  --max <n>             ÊúÄÂ§ßÂÄôÈÄâÊï∞ÔºàÈªòËÆ§: 20Ôºâ
scripts/reranker.sh:82:  --rerank-strategy <s> ÈáçÊéíÂ∫èÁ≠ñÁï•: llm | heuristicÔºàÈªòËÆ§: llmÔºâ
scripts/reranker.sh:83:  --timeout-ms <ms>     LLM Ë∂ÖÊó∂ÊØ´ÁßíÔºàÈªòËÆ§: 5000Ôºâ
scripts/reranker.sh:84:  --mock-llm            ‰ΩøÁî® Mock ProviderÔºàÊµãËØïÁî®Ôºâ
scripts/reranker.sh:85:  --version             ÊòæÁ§∫ÁâàÊú¨
scripts/reranker.sh:86:  --help                ÊòæÁ§∫Ê≠§Â∏ÆÂä©
scripts/reranker.sh:124:    reranker.sh --query "ËÆ§ËØÅÂáΩÊï∞"
scripts/reranker.sh:127:  reranker.sh --query "test" --provider openai < candidates.json
scripts/reranker.sh:130:  reranker.sh --query "test" --mock-llm < candidates.json
scripts/reranker.sh:144:  while [[ $# -gt 0 ]]; do
scripts/reranker.sh:146:      --query)
scripts/reranker.sh:150:      --provider)
scripts/reranker.sh:154:      --model)
scripts/reranker.sh:158:      --input)
scripts/reranker.sh:162:      --max)
scripts/reranker.sh:166:      --rerank-strategy)
scripts/reranker.sh:170:      --timeout-ms)
scripts/reranker.sh:174:      --mock-llm)
scripts/reranker.sh:178:      --version)
scripts/reranker.sh:182:      --help|-h)
scripts/reranker.sh:194:  if [[ -z "$QUERY" ]]; then
scripts/reranker.sh:195:    log_error "ÂøÖÈ°ªÊèê‰æõ --query ÂèÇÊï∞"
scripts/reranker.sh:216:  if [[ -n "$INPUT_FILE" ]] && [[ -f "$INPUT_FILE" ]]; then
scripts/reranker.sh:220:    if [[ -t 0 ]]; then
scripts/reranker.sh:222:      log_error "Êú™Êèê‰æõËæìÂÖ•Êï∞ÊçÆ„ÄÇËØ∑‰ΩøÁî® --input <file> ÊàñÈÄöËøáÁÆ°ÈÅìÊèê‰æõ JSON Êï∞ÊçÆ„ÄÇ"
scripts/reranker.sh:223:      log_error "Á§∫‰æã: echo '{\"candidates\":[]}' | reranker.sh --query \"Êü•ËØ¢\""
scripts/reranker.sh:251:    file_path=$(echo "$candidate" | jq -r '.file_path')
scripts/reranker.sh:255:    ranked=$(echo "$ranked" | jq --arg fp "$file_path" --argjson rank "$((i+1))" --argjson score "$score" \
scripts/reranker.sh:266:  if [[ -f "$path" ]]; then
scripts/reranker.sh:267:    if stat -f %m "$path" >/dev/null 2>&1; then
scripts/reranker.sh:268:      stat -f %m "$path"
scripts/reranker.sh:271:    if stat -c %Y "$path" >/dev/null 2>&1; then
scripts/reranker.sh:272:      stat -c %Y "$path"
scripts/reranker.sh:286:    while IFS= read -r hotspot; do
scripts/reranker.sh:287:      [ -n "$hotspot" ] && hotspot_list+=("$hotspot")
scripts/reranker.sh:296:  if [[ "$limit" -gt "$MAX_CANDIDATES" ]]; then
scripts/reranker.sh:302:    candidate=$(echo "$candidates_json" | jq -c ".[$i]")
scripts/reranker.sh:303:    file_path=$(echo "$candidate" | jq -r '.file_path // .file // ""')
scripts/reranker.sh:304:    base_score=$(echo "$candidate" | jq -r '.relevance_score // .score // 0')
scripts/reranker.sh:315:    if [[ -n "$mtime" ]]; then
scripts/reranker.sh:317:      recent_bonus=$(awk -v days="$age_days" 'BEGIN {printf "%.3f", 0.30 / (1 + days)}')
scripts/reranker.sh:323:    if [[ ${#hotspot_list[@]} -gt 0 ]]; then
scripts/reranker.sh:332:    final_score=$(awk -v base="$base_score" -v ext="$ext_bonus" -v recent="$recent_bonus" -v hot="$hotspot_bonus" \
scripts/reranker.sh:336:      --arg fp "$file_path" \
scripts/reranker.sh:337:      --argjson score "$final_score" \
scripts/reranker.sh:338:      --argjson base "$base_score" \
scripts/reranker.sh:339:      --argjson recent "$recent_bonus" \
scripts/reranker.sh:340:      --argjson hot "$hotspot_bonus" \
scripts/reranker.sh:341:      --argjson ext "$ext_bonus" \
scripts/reranker.sh:365:  if ! echo "$input" | jq -e '.candidates' >/dev/null 2>&1; then
scripts/reranker.sh:380:  [[ -n "$PROVIDER" ]] && export LLM_DEFAULT_PROVIDER="$PROVIDER"
scripts/reranker.sh:381:  [[ -n "$MODEL" ]] && export LLM_MODEL="$MODEL"
scripts/reranker.sh:385:  candidates=$(echo "$input" | jq -c '.candidates // []')
scripts/reranker.sh:390:  if [[ "$count" -gt "$MAX_CANDIDATES" ]]; then
scripts/reranker.sh:391:    candidates=$(echo "$candidates" | jq -c ".[0:$MAX_CANDIDATES]")
scripts/reranker.sh:412:          if echo "$result" | jq -e '.success == true' &>/dev/null; then
scripts/reranker.sh:415:            raw_ranked=$(echo "$result" | jq -c '.ranked // []')
scripts/reranker.sh:425:              row=$(echo "$raw_ranked" | jq -c ".[$idx]")
scripts/reranker.sh:426:              orig_index=$(echo "$row" | jq -r '.index // 0')
scripts/reranker.sh:427:              score=$(echo "$row" | jq -r '.score // 5')
scripts/reranker.sh:429:              file_path=$(echo "$candidates" | jq -r ".[$orig_index].file_path // .[$orig_index].file // \"file_$orig_index\"")
scripts/reranker.sh:435:                --arg fp "$file_path" \
scripts/reranker.sh:436:                --argjson rank "$((idx + 1))" \
scripts/reranker.sh:437:                --argjson score "$rerank_score" \
scripts/reranker.sh:464:  jq -n \
scripts/reranker.sh:465:    --arg version "1.0" \
scripts/reranker.sh:466:    --arg provider "$used_provider" \
scripts/reranker.sh:467:    --argjson ranked "$ranked" \
scripts/reranker.sh:484:  if [[ -z "$input" ]]; then
scripts/graph-store.sh.bak:14:set -euo pipefail
scripts/graph-store.sh.bak:59:    if [[ -z "$input" ]]; then
scripts/graph-store.sh.bak:64:    if [[ ${#input} -gt $max_length ]]; then
scripts/graph-store.sh.bak:76:    if printf '%s' "$input" | LC_ALL=C tr -d '[:print:][:space:]' | grep -q .; then
scripts/graph-store.sh.bak:82:    if echo "$input" | grep -qiE "(DROP|DELETE|TRUNCATE|ALTER|EXEC|UNION|INSERT|UPDATE).*TABLE"; then
scripts/graph-store.sh.bak:100:    if [[ ! -d "$db_dir" ]]; then
scripts/graph-store.sh.bak:101:        mkdir -p "$db_dir"
scripts/graph-store.sh.bak:114:    sqlite3 -json "$GRAPH_DB_PATH" "$sql"
scripts/graph-store.sh.bak:122:    if [[ -n "$prefix" ]]; then
scripts/graph-store.sh.bak:133:-- nodes Ë°®
scripts/graph-store.sh.bak:147:-- edges Ë°®ÔºàÊâ©Â±ï AC-G01: ÊîØÊåÅ IMPLEMENTS/EXTENDS/RETURNS_TYPE/ADR_RELATEDÔºâ
scripts/graph-store.sh.bak:164:-- MP4: transitive_closure Ë°®ÔºàÈó≠ÂåÖË°®Ôºâ
scripts/graph-store.sh.bak:179:-- MP4: path_index Ë°®ÔºàË∑ØÂæÑÁ¥¢ÂºïÔºâ
scripts/graph-store.sh.bak:196:-- MP7: user_signals Ë°®Ôºà‰∏ä‰∏ãÊñá‰ø°Âè∑Ôºâ
scripts/graph-store.sh.bak:208:-- virtual_edges Ë°®ÔºàMP5: ËÅîÈÇ¶ËôöÊãüËæπÔºâ
scripts/graph-store.sh.bak:209:-- Trace: AC-F05
scripts/graph-store.sh.bak:233:-- ÁâàÊú¨Ë°®
scripts/graph-store.sh.bak:239:-- ÂÖÉÊï∞ÊçÆË°®ÔºàÁî®‰∫éÂ≠òÂÇ®ÈÖçÁΩÆÂíåÁâàÊú¨Êà≥Ôºâ
scripts/graph-store.sh.bak:246:-- MP2: Schema v3 Êñ∞Â¢ûÁ¥¢Âºï (AC-U03)
scripts/graph-store.sh.bak:259:    if [[ ! -f "$db_path" ]]; then
scripts/graph-store.sh.bak:267:    [[ "$has_tc" -gt 0 && "$has_pi" -gt 0 ]]
scripts/graph-store.sh.bak:343:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh.bak:345:            --skip-precompute) skip_precompute=true; shift ;;
scripts/graph-store.sh.bak:352:    if [[ -f "$GRAPH_DB_PATH" ]]; then
scripts/graph-store.sh.bak:384:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh.bak:386:            --id) id="$2"; shift 2 ;;
scripts/graph-store.sh.bak:387:            --symbol) symbol="$2"; shift 2 ;;
scripts/graph-store.sh.bak:388:            --kind) kind="$2"; shift 2 ;;
scripts/graph-store.sh.bak:389:            --file) file_path="$2"; shift 2 ;;
scripts/graph-store.sh.bak:390:            --line-start) line_start="$2"; shift 2 ;;
scripts/graph-store.sh.bak:391:            --line-end) line_end="$2"; shift 2 ;;
scripts/graph-store.sh.bak:397:    if [[ -z "$id" || -z "$symbol" || -z "$kind" || -z "$file_path" ]]; then
scripts/graph-store.sh.bak:398:        log_error "Missing required fields: --id, --symbol, --kind, --file"
scripts/graph-store.sh.bak:411:    [[ -n "$line_start" ]] && line_start_sql="$line_start"
scripts/graph-store.sh.bak:412:    [[ -n "$line_end" ]] && line_end_sql="$line_end"
scripts/graph-store.sh.bak:430:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh.bak:432:            --source) source_id="$2"; shift 2 ;;
scripts/graph-store.sh.bak:433:            --target) target_id="$2"; shift 2 ;;
scripts/graph-store.sh.bak:434:            --type) edge_type="$2"; shift 2 ;;
scripts/graph-store.sh.bak:435:            --file) file_path="$2"; shift 2 ;;
scripts/graph-store.sh.bak:436:            --line) line="$2"; shift 2 ;;
scripts/graph-store.sh.bak:442:    if [[ -z "$source_id" || -z "$target_id" || -z "$edge_type" ]]; then
scripts/graph-store.sh.bak:443:        log_error "Missing required fields: --source, --target, --type"
scripts/graph-store.sh.bak:465:    [[ -n "$file_path" ]] && file_sql="'$(escape_sql_string "$file_path")'"
scripts/graph-store.sh.bak:466:    [[ -n "$line" ]] && line_sql="$line"
scripts/graph-store.sh.bak:485:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh.bak:487:            --from) from_node="$2"; shift 2 ;;
scripts/graph-store.sh.bak:488:            --to) to_node="$2"; shift 2 ;;
scripts/graph-store.sh.bak:489:            --type) edge_type="$2"; shift 2 ;;
scripts/graph-store.sh.bak:490:            --direction) direction="$2"; shift 2 ;;
scripts/graph-store.sh.bak:497:    if [[ -n "$from_node" ]]; then
scripts/graph-store.sh.bak:501:    if [[ -n "$to_node" ]]; then
scripts/graph-store.sh.bak:505:    if [[ -n "$edge_type" ]]; then
scripts/graph-store.sh.bak:510:    if [[ ${#where_clauses[@]} -gt 0 ]]; then
scripts/graph-store.sh.bak:529:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh.bak:531:            --exclude) exclude_pattern="$2"; shift 2 ;;
scripts/graph-store.sh.bak:538:    if [[ -n "$exclude_pattern" ]]; then
scripts/graph-store.sh.bak:560:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh.bak:562:            --file) input_file="$2"; shift 2 ;;
scripts/graph-store.sh.bak:563:            --skip-precompute) skip_precompute=true; shift ;;
scripts/graph-store.sh.bak:568:    if [[ -z "$input_file" || ! -f "$input_file" ]]; then
scripts/graph-store.sh.bak:585:    if jq -e '.nodes | length > 0' "$input_file" >/dev/null 2>&1; then
scripts/graph-store.sh.bak:586:        while IFS=$'\t' read -r id symbol kind file_path line_start line_end; do
scripts/graph-store.sh.bak:588:            if [[ -z "$id" || "$id" == "null" || "$id" == "NULL" \
scripts/graph-store.sh.bak:589:                || -z "$symbol" || "$symbol" == "null" || "$symbol" == "NULL" \
scripts/graph-store.sh.bak:590:                || -z "$kind" || "$kind" == "null" || "$kind" == "NULL" \
scripts/graph-store.sh.bak:591:                || -z "$file_path" || "$file_path" == "null" || "$file_path" == "NULL" ]]; then
scripts/graph-store.sh.bak:597:            [[ "$line_start" == "null" || "$line_start" == "NULL" || -z "$line_start" ]] && line_start="NULL"
scripts/graph-store.sh.bak:598:            [[ "$line_end" == "null" || "$line_end" == "NULL" || -z "$line_end" ]] && line_end="NULL"
scripts/graph-store.sh.bak:601:        done < <(jq -r '.nodes[] | [.id, .symbol, .kind, .file_path, (.line_start // "NULL"), (.line_end // "NULL")] | @tsv' "$input_file")
scripts/graph-store.sh.bak:605:    if jq -e '.edges | length > 0' "$input_file" >/dev/null 2>&1; then
scripts/graph-store.sh.bak:606:        while IFS=$'\t' read -r source_id target_id edge_type file_path line; do
scripts/graph-store.sh.bak:618:            [[ "$file_path" == "null" || "$file_path" == "NULL" || -z "$file_path" ]] && file_path="NULL" || file_path="'$(echo "$file_path" | sed "s/'/''/g")'"
scripts/graph-store.sh.bak:619:            [[ "$line" == "null" || "$line" == "NULL" || -z "$line" ]] && line="NULL"
scripts/graph-store.sh.bak:623:        done < <(jq -r '.edges[] | [.source_id, .target_id, .edge_type, (.file_path // "NULL"), (.line // "NULL")] | @tsv' "$input_file")
scripts/graph-store.sh.bak:674:    if [[ -z "$sql" ]]; then
scripts/graph-store.sh.bak:687:    if [[ -z "$node_id" ]]; then
scripts/graph-store.sh.bak:702:    if [[ -z "$node_id" ]]; then
scripts/graph-store.sh.bak:721:    if [[ -z "$edge_id" ]]; then
scripts/graph-store.sh.bak:740:    if [[ ! -f "$db_path" ]]; then
scripts/graph-store.sh.bak:764:    if [[ ! -f "$db_path" ]]; then
scripts/graph-store.sh.bak:772:    if [[ -z "$create_sql" ]]; then
scripts/graph-store.sh.bak:790:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh.bak:792:            --check) check_only=true; shift ;;
scripts/graph-store.sh.bak:793:            --apply) apply=true; shift ;;
scripts/graph-store.sh.bak:794:            --status) status_only=true; shift ;;
scripts/graph-store.sh.bak:795:            --skip-precompute) skip_precompute=true; shift ;;
scripts/graph-store.sh.bak:814:        if ! flock -n 200; then
scripts/graph-store.sh.bak:821:        trap "flock -u 200; rm -f '$lock_file'" EXIT
scripts/graph-store.sh.bak:824:    if [[ ! -f "$GRAPH_DB_PATH" ]]; then
scripts/graph-store.sh.bak:855:        if [[ "$needs_migration" == "true" ]] || [[ "$current_version" -lt "$CURRENT_SCHEMA_VERSION" ]]; then
scripts/graph-store.sh.bak:883:        if [[ "$needs_migration" == "true" ]] || [[ "$current_version" -lt "$CURRENT_SCHEMA_VERSION" ]]; then
scripts/graph-store.sh.bak:901:        [[ -f "${GRAPH_DB_PATH}-wal" ]] && cp "${GRAPH_DB_PATH}-wal" "${backup_path}-wal"
scripts/graph-store.sh.bak:902:        [[ -f "${GRAPH_DB_PATH}-shm" ]] && cp "${GRAPH_DB_PATH}-shm" "${backup_path}-shm"
scripts/graph-store.sh.bak:905:        if [[ "$needs_migration" != "true" ]] && [[ "$current_version" -ge "$CURRENT_SCHEMA_VERSION" ]]; then
scripts/graph-store.sh.bak:914:-- MP2.5: ÂêØÁî®Â§ñÈîÆÁ∫¶ÊùüÊ£ÄÊü• (AC-U11)
scripts/graph-store.sh.bak:919:-- 1. ÂØºÂá∫Áé∞ÊúâÊï∞ÊçÆ
scripts/graph-store.sh.bak:923:-- 2. Âà†Èô§ÊóßË°®ÔºàÁ∫ßËÅîÂà†Èô§Á¥¢ÂºïÔºâ
scripts/graph-store.sh.bak:927:-- 3. ÂàõÂª∫Êñ∞ nodes Ë°®
scripts/graph-store.sh.bak:941:-- 4. ÂàõÂª∫Êñ∞ edges Ë°®ÔºàÂ∏¶Êâ©Â±ï CHECK Á∫¶ÊùüÔºâ
scripts/graph-store.sh.bak:958:-- MP2: Êñ∞Â¢û‰∏ìÁî®Á¥¢Âºï (AC-U03)
scripts/graph-store.sh.bak:963:-- MP4: Êñ∞Â¢ûÈó≠ÂåÖË°®‰∏éË∑ØÂæÑÁ¥¢Âºï
scripts/graph-store.sh.bak:994:-- MP7: user_signals Ë°®
scripts/graph-store.sh.bak:1006:-- 5. ÊÅ¢Â§çÊï∞ÊçÆÔºàÂ§ÑÁêÜ v2 Âà∞ v3 ÁöÑÂàóÊò†Â∞ÑÔºâ
scripts/graph-store.sh.bak:1007:-- v2 nodes: (id, type, name, file_path, metadata)
scripts/graph-store.sh.bak:1008:-- v3 nodes: (id, symbol, kind, file_path, line_start, line_end, created_at)
scripts/graph-store.sh.bak:1012:    name as symbol,  -- v2 ÁöÑ name Êò†Â∞ÑÂà∞ v3 ÁöÑ symbol
scripts/graph-store.sh.bak:1013:    type as kind,    -- v2 ÁöÑ type Êò†Â∞ÑÂà∞ v3 ÁöÑ kind
scripts/graph-store.sh.bak:1019:-- v2 edges: (id, source_id, target_id, edge_type, metadata)
scripts/graph-store.sh.bak:1020:-- v3 edges: (id, source_id, target_id, edge_type, file_path, line, created_at)
scripts/graph-store.sh.bak:1023:    hex(randomblob(16)) as id,  -- v2 ‰ΩøÁî® INTEGER AUTOINCREMENTÔºåv3 ‰ΩøÁî® TEXTÔºåÈúÄË¶ÅÈáçÊñ∞ÁîüÊàê
scripts/graph-store.sh.bak:1031:-- 6. Êõ¥Êñ∞ÁâàÊú¨
scripts/graph-store.sh.bak:1034:-- 7. Ê∏ÖÁêÜ‰∏¥Êó∂Ë°®
scripts/graph-store.sh.bak:1054:                [[ -f "${backup_path}-wal" ]] && cp "${backup_path}-wal" "${GRAPH_DB_PATH}-wal"
scripts/graph-store.sh.bak:1055:                [[ -f "${backup_path}-shm" ]] && cp "${backup_path}-shm" "${GRAPH_DB_PATH}-shm"
scripts/graph-store.sh.bak:1069:                [[ -f "${backup_path}-wal" ]] && cp "${backup_path}-wal" "${GRAPH_DB_PATH}-wal"
scripts/graph-store.sh.bak:1070:                [[ -f "${backup_path}-shm" ]] && cp "${backup_path}-shm" "${GRAPH_DB_PATH}-shm"
scripts/graph-store.sh.bak:1078:            if [[ -n "$fk_violations" ]]; then
scripts/graph-store.sh.bak:1082:                [[ -f "${backup_path}-wal" ]] && cp "${backup_path}-wal" "${GRAPH_DB_PATH}-wal"
scripts/graph-store.sh.bak:1083:                [[ -f "${backup_path}-shm" ]] && cp "${backup_path}-shm" "${GRAPH_DB_PATH}-shm"
scripts/graph-store.sh.bak:1095:                [[ -f "${backup_path}-wal" ]] && cp "${backup_path}-wal" "${GRAPH_DB_PATH}-wal"
scripts/graph-store.sh.bak:1096:                [[ -f "${backup_path}-shm" ]] && cp "${backup_path}-shm" "${GRAPH_DB_PATH}-shm"
scripts/graph-store.sh.bak:1110:            [[ -f "${backup_path}-wal" ]] && cp "${backup_path}-wal" "${GRAPH_DB_PATH}-wal"
scripts/graph-store.sh.bak:1111:            [[ -f "${backup_path}-shm" ]] && cp "${backup_path}-shm" "${GRAPH_DB_PATH}-shm"
scripts/graph-store.sh.bak:1123:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh.bak:1125:            --from) from_node="$2"; shift 2 ;;
scripts/graph-store.sh.bak:1126:            --to) to_node="$2"; shift 2 ;;
scripts/graph-store.sh.bak:1127:            --max-depth) max_depth="$2"; shift 2 ;;
scripts/graph-store.sh.bak:1128:            --edge-types) edge_types="$2"; shift 2 ;;
scripts/graph-store.sh.bak:1134:    if [[ -z "$from_node" || -z "$to_node" ]]; then
scripts/graph-store.sh.bak:1135:        log_error "Missing required fields: --from, --to"
scripts/graph-store.sh.bak:1140:    if [[ "$max_depth" -lt 1 || "$max_depth" -gt 10 ]]; then
scripts/graph-store.sh.bak:1146:    if [[ ! -f "$GRAPH_DB_PATH" ]]; then
scripts/graph-store.sh.bak:1157:    if [[ -n "$edge_types" ]]; then
scripts/graph-store.sh.bak:1165:    if [[ -z "$edge_types" ]] && closure_tables_exist "$GRAPH_DB_PATH"; then
scripts/graph-store.sh.bak:1168:        if [[ "$closure_count" -gt 0 ]]; then
scripts/graph-store.sh.bak:1172:            if [[ -z "$closure_depth" ]]; then
scripts/graph-store.sh.bak:1178:            path_row=$(sqlite3 -separator $'\t' "$GRAPH_DB_PATH" "SELECT path, edge_path, depth FROM path_index WHERE source_id='$from_sql' AND target_id='$to_sql' AND depth <= $max_depth LIMIT 1;" 2>/dev/null || true)
scripts/graph-store.sh.bak:1179:            if [[ -n "$path_row" ]]; then
scripts/graph-store.sh.bak:1181:                IFS=$'\t' read -r path_json edge_json depth_val <<< "$path_row"
scripts/graph-store.sh.bak:1182:                [[ -z "$edge_json" ]] && edge_json="[]"
scripts/graph-store.sh.bak:1183:                [[ -z "$depth_val" ]] && depth_val="$closure_depth"
scripts/graph-store.sh.bak:1220:    result=$(sqlite3 -separator $'\t' "$GRAPH_DB_PATH" "$path_sql" 2>/dev/null)
scripts/graph-store.sh.bak:1222:    if [[ -z "$result" ]]; then
scripts/graph-store.sh.bak:1228:    IFS=$'\t' read -r node_id path_str depth <<< "$result"
scripts/graph-store.sh.bak:1231:    path_json=$(printf '%s\n' "$path_str" | tr '>' '\n' | jq -R '.' | jq -s '.')
scripts/graph-store.sh.bak:1235:    IFS='>' read -r -a node_list <<< "$path_str"
scripts/graph-store.sh.bak:1236:    if [ "${#node_list[@]}" -gt 1 ]; then
scripts/graph-store.sh.bak:1243:            edges_json=$(echo "$edges_json" | jq --arg from "$from_id" --arg to "$to_id" --arg type "$edge_type" \
scripts/graph-store.sh.bak:1259:    graph-store.sh --enable-all-features <command> [options]
scripts/graph-store.sh.bak:1277:    --id <id>               ËäÇÁÇπ IDÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh.bak:1278:    --symbol <symbol>       Á¨¶Âè∑ÂêçÁß∞ÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh.bak:1279:    --kind <kind>           ËäÇÁÇπÁ±ªÂûãÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh.bak:1280:    --file <path>           Êñá‰ª∂Ë∑ØÂæÑÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh.bak:1281:    --line-start <n>        Ëµ∑ÂßãË°åÂè∑
scripts/graph-store.sh.bak:1282:    --line-end <n>          ÁªìÊùüË°åÂè∑
scripts/graph-store.sh.bak:1285:    --source <id>           Ê∫êËäÇÁÇπ IDÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh.bak:1286:    --target <id>           ÁõÆÊ†áËäÇÁÇπ IDÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh.bak:1287:    --type <type>           ËæπÁ±ªÂûãÔºàÂøÖÂ°´Ôºâ: DEFINES, IMPORTS, CALLS, MODIFIES, REFERENCES,
scripts/graph-store.sh.bak:1289:    --file <path>           Êñá‰ª∂Ë∑ØÂæÑ
scripts/graph-store.sh.bak:1290:    --line <n>              Ë°åÂè∑
scripts/graph-store.sh.bak:1293:    --skip-precompute       Ë∑≥ËøáÈó≠ÂåÖË°®È¢ÑËÆ°ÁÆó
scripts/graph-store.sh.bak:1296:    --from <id>             Ê∫êËäÇÁÇπ ID
scripts/graph-store.sh.bak:1297:    --to <id>               ÁõÆÊ†áËäÇÁÇπ ID
scripts/graph-store.sh.bak:1298:    --type <type>           ËæπÁ±ªÂûã
scripts/graph-store.sh.bak:1301:    --exclude <pattern>     ÊéíÈô§Ê®°ÂºèÔºàglobÔºâ
scripts/graph-store.sh.bak:1304:    --file <path>           JSON Êñá‰ª∂Ë∑ØÂæÑ
scripts/graph-store.sh.bak:1305:    --skip-precompute       Ë∑≥ËøáÈó≠ÂåÖË°®È¢ÑËÆ°ÁÆó
scripts/graph-store.sh.bak:1308:    --from <id>             Ê∫êËäÇÁÇπ IDÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh.bak:1309:    --to <id>               ÁõÆÊ†áËäÇÁÇπ IDÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh.bak:1310:    --max-depth <n>         ÊúÄÂ§ßÊêúÁ¥¢Ê∑±Â∫¶ÔºàÈªòËÆ§: 10Ôºâ
scripts/graph-store.sh.bak:1311:    --edge-types <types>    ÈÄóÂè∑ÂàÜÈöîÁöÑËæπÁ±ªÂûãËøáÊª§
scripts/graph-store.sh.bak:1314:    --check                 Ê£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅËøÅÁßª
scripts/graph-store.sh.bak:1315:    --apply                 ÊâßË°åËøÅÁßªÔºàËá™Âä®Â§á‰ªΩÔºâ
scripts/graph-store.sh.bak:1316:    --status                ÊòæÁ§∫ÂΩìÂâçÁä∂ÊÄÅ
scripts/graph-store.sh.bak:1317:    --skip-precompute       Ë∑≥ËøáÈó≠ÂåÖË°®È¢ÑËÆ°ÁÆó
scripts/graph-store.sh.bak:1328:    graph-store.sh add-node --id "sym:func:main" --symbol "main" --kind "function" --file "src/index.ts"
scripts/graph-store.sh.bak:1331:    graph-store.sh add-edge --source "sym:func:main" --target "sym:func:helper" --type CALLS
scripts/graph-store.sh.bak:1334:    graph-store.sh query-edges --from "sym:func:main" --type CALLS
scripts/graph-store.sh.bak:1352:    if declare -f is_feature_enabled &>/dev/null; then
scripts/graph-rag-retrieval.sh:18:  if [ ! -f "$index_path" ]; then
scripts/graph-rag-retrieval.sh:23:  if [ -x "$embedding_tool" ]; then
scripts/graph-rag-retrieval.sh:25:    result=$(cd "$CWD" && PROJECT_ROOT="$CWD" "$embedding_tool" search "$query" --top-k "$top_k" 2>/dev/null)
scripts/graph-rag-retrieval.sh:26:    if [ -n "$result" ]; then
scripts/graph-rag-retrieval.sh:27:      echo "$result" | grep -E '^\[' | head -1 | while read -r line; do
scripts/graph-rag-retrieval.sh:32:      done | jq -s '.'
scripts/graph-rag-retrieval.sh:47:  keywords=$(echo "$query" | tr ' ' '\n' | grep -E '^[a-zA-Z]{3,}$' | head -5)
scripts/graph-rag-retrieval.sh:49:  if [ -z "$keywords" ]; then
scripts/graph-rag-retrieval.sh:58:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/graph-rag-retrieval.sh:61:  if [ -z "$rg_cmd" ]; then
scripts/graph-rag-retrieval.sh:66:  while IFS= read -r keyword; do
scripts/graph-rag-retrieval.sh:67:    [ -z "$keyword" ] && continue
scripts/graph-rag-retrieval.sh:69:    files=$("$rg_cmd" -l --max-count=5 -t py -t js -t ts -t go \
scripts/graph-rag-retrieval.sh:72:    while IFS= read -r file; do
scripts/graph-rag-retrieval.sh:73:      [ -z "$file" ] && continue
scripts/graph-rag-retrieval.sh:79:  printf '%s\n' "${results[@]}" | sort -u | head -"$top_k" | \
scripts/graph-rag-retrieval.sh:80:    jq -R -s 'split("\n") | map(select(length > 0)) | to_entries | map({file_path: .value, relevance_score: (1 - .key * 0.1)})'
scripts/graph-rag-retrieval.sh:94:  if [[ "$CKB_AVAILABLE" == "true" && -n "${CKB_MCP_CLIENT:-}" ]]; then
scripts/graph-rag-retrieval.sh:96:    if ckb_result=$(timeout 5s "$CKB_MCP_CLIENT" --file "$file_path" 2>/dev/null); then
scripts/graph-rag-retrieval.sh:97:      if echo "$ckb_result" | jq -e . >/dev/null 2>&1; then
scripts/graph-rag-retrieval.sh:108:  if [ ! -f "$full_path" ]; then
scripts/graph-rag-retrieval.sh:113:  imports=$(grep -E "^import|^from .* import" "$full_path" 2>/dev/null | head -10)
scripts/graph-rag-retrieval.sh:117:  while IFS= read -r import_line; do
scripts/graph-rag-retrieval.sh:118:    [ -z "$import_line" ] && continue
scripts/graph-rag-retrieval.sh:121:    imported=$(echo "$import_line" | grep -oE "'[^']+'" | tr -d "'" | head -1)
scripts/graph-rag-retrieval.sh:122:    [ -z "$imported" ] && imported=$(echo "$import_line" | grep -oE '"[^"]+"' | tr -d '"' | head -1)
scripts/graph-rag-retrieval.sh:124:    if [ -n "$imported" ]; then
scripts/graph-rag-retrieval.sh:127:        graph_results=$(echo "$graph_results" | jq --arg path "$import_path" '. + [{file_path: $path, depth: 1, source: "import"}]')
scripts/graph-rag-retrieval.sh:141:  if [[ -n "${MOCK_CKB_AVAILABLE:-}" ]]; then
scripts/graph-rag-retrieval.sh:144:    keywords=$(echo "$query" | tr ' ' '\n' | head -3)
scripts/graph-rag-retrieval.sh:146:    while IFS= read -r keyword && [[ $idx -lt $top_k ]]; do
scripts/graph-rag-retrieval.sh:147:      [[ -z "$keyword" ]] && continue
scripts/graph-rag-retrieval.sh:150:        --arg file "src/${keyword}.ts" \
scripts/graph-rag-retrieval.sh:151:        --arg symbol "ckb:test:sym:${keyword}_func" \
scripts/graph-rag-retrieval.sh:152:        --argjson score "$score" \
scripts/graph-rag-retrieval.sh:153:        --argjson depth "$((idx % max_depth))" \
scripts/graph-rag-retrieval.sh:182:  if [[ -n "${CKB_MCP_CLIENT:-}" ]]; then
scripts/graph-rag-retrieval.sh:187:      if echo "$ckb_result" | jq -e . >/dev/null 2>&1; then
scripts/graph-rag-retrieval.sh:188:        if echo "$ckb_result" | jq -e '.nodes' >/dev/null 2>&1; then
scripts/graph-rag-retrieval.sh:215:  if [[ -n "${CKB_UNAVAILABLE:-}" ]]; then
scripts/graph-rag-retrieval.sh:234:    file_path=$(echo "$anchor" | jq -r '.file_path')
scripts/graph-rag-retrieval.sh:236:    if echo "$visited" | jq -e --arg p "$file_path" 'index($p)' >/dev/null 2>&1; then
scripts/graph-rag-retrieval.sh:240:    visited=$(echo "$visited" | jq --arg p "$file_path" '. + [$p]')
scripts/graph-rag-retrieval.sh:243:    all_candidates=$(echo "$all_candidates" | jq --argjson a "$anchor" \
scripts/graph-rag-retrieval.sh:246:    if [ "$max_depth" -gt 0 ]; then
scripts/graph-rag-retrieval.sh:250:      if [ -n "$graph_nodes" ] && [ "$graph_nodes" != "[]" ]; then
scripts/graph-rag-retrieval.sh:252:        all_candidates=$(echo "$all_candidates" "$graph_nodes" | jq -s 'add | unique_by(.file_path)')
scripts/dependency-guard-extract.sh:20:    if [[ ! -f "$file" ]]; then
scripts/dependency-guard-extract.sh:29:    trap "rm -f '$temp_imports'" RETURN
scripts/dependency-guard-extract.sh:35:    while IFS= read -r line || [[ -n "$line" ]]; do
scripts/dependency-guard-extract.sh:42:            if [[ -n "$target" ]]; then
scripts/dependency-guard-extract.sh:45:                echo "$current" | jq --arg source "$input_file" --arg target "$target" --argjson line "$line_num" \
scripts/dependency-guard-extract.sh:53:            if [[ -n "$target" ]]; then
scripts/dependency-guard-extract.sh:56:                echo "$current" | jq --arg source "$input_file" --arg target "$target" --argjson line "$line_num" \
scripts/dependency-guard-extract.sh:69:    if [[ ! -f "$file" ]]; then
scripts/dependency-guard-extract.sh:77:    trap "rm -f '$temp_imports'" RETURN
scripts/dependency-guard-extract.sh:83:    while IFS= read -r line || [[ -n "$line" ]]; do
scripts/dependency-guard-extract.sh:90:            if [[ -n "$target" ]]; then
scripts/dependency-guard-extract.sh:93:                echo "$current" | jq --arg source "$input_file" --arg target "$target" --argjson line "$line_num" \
scripts/dependency-guard-extract.sh:148:    if command -v python3 &>/dev/null; then
scripts/dependency-guard-extract.sh:149:        resolved=$(python3 -c "import os.path; print(os.path.normpath('$resolved'))" 2>/dev/null) || resolved="$resolved"
scripts/dependency-guard-extract.sh:150:    elif command -v python &>/dev/null; then
scripts/dependency-guard-extract.sh:151:        resolved=$(python -c "import os.path; print(os.path.normpath('$resolved'))" 2>/dev/null) || resolved="$resolved"
scripts/dependency-guard-extract.sh:154:    if [[ -z "$resolved" ]]; then
scripts/dependency-guard-extract.sh:161:        if [[ -f "$candidate" ]]; then
scripts/dependency-guard-extract.sh:168:    if [[ -d "$resolved" ]]; then
scripts/dependency-guard-extract.sh:171:            if [[ -f "$candidate" ]]; then
scripts/dependency-guard-extract.sh:203:    if command -v python3 &>/dev/null; then
scripts/dependency-guard-extract.sh:204:        python3 -c "import os.path; print(os.path.normpath('$result'))" 2>/dev/null || echo "$result"
scripts/dependency-guard-extract.sh:205:    elif command -v python &>/dev/null; then
scripts/dependency-guard-extract.sh:206:        python -c "import os.path; print(os.path.normpath('$result'))" 2>/dev/null || echo "$result"
scripts/dependency-guard-extract.sh:216:    result=$(realpath --relative-to="$(pwd)" "$path" 2>/dev/null || echo "$path")
scripts/dependency-guard.sh:9:#   dependency-guard.sh --cycles --scope "src/" --format json
scripts/dependency-guard.sh:10:#   dependency-guard.sh --rules <rules.yaml> --format json
scripts/dependency-guard.sh:11:#   dependency-guard.sh --all --scope "src/" --rules <rules.yaml>
scripts/dependency-guard.sh:12:#   dependency-guard.sh --pre-commit [--with-deps]
scripts/dependency-guard.sh:13:#   dependency-guard.sh --help
scripts/dependency-guard.sh:22:set -euo pipefail
scripts/dependency-guard.sh:73:  dependency-guard.sh --cycles --scope "src/" --format json
scripts/dependency-guard.sh:74:  dependency-guard.sh --rules <rules.yaml> --format json
scripts/dependency-guard.sh:75:  dependency-guard.sh --all --scope "src/" --rules <rules.yaml>
scripts/dependency-guard.sh:76:  dependency-guard.sh --orphan-check --scope "src/" --format json
scripts/dependency-guard.sh:77:  dependency-guard.sh --pre-commit [--with-deps]
scripts/dependency-guard.sh:78:  dependency-guard.sh --help
scripts/dependency-guard.sh:81:  --cycles            Detect circular dependencies
scripts/dependency-guard.sh:82:  --rules <file>      Validate architecture rules from file
scripts/dependency-guard.sh:83:  --all               Run both cycle detection and rule validation
scripts/dependency-guard.sh:84:  --orphan-check      Detect orphan modules (no incoming edges, not entry points)
scripts/dependency-guard.sh:85:  --exclude <pattern> Exclude pattern for orphan detection (can be repeated)
scripts/dependency-guard.sh:86:  --scope <pattern>   Scope for cycle detection (default: src/)
scripts/dependency-guard.sh:87:  --format <type>     Output format: text or json (default: json)
scripts/dependency-guard.sh:88:  --pre-commit        Check only staged files
scripts/dependency-guard.sh:89:  --with-deps         Include first-level dependencies
scripts/dependency-guard.sh:90:  --help              Show this help message
scripts/dependency-guard.sh:97:  dependency-guard.sh --cycles --scope "src/" --format json
scripts/dependency-guard.sh:100:  dependency-guard.sh --rules config/arch-rules.yaml
scripts/dependency-guard.sh:103:  dependency-guard.sh --pre-commit --with-deps
scripts/dependency-guard.sh:121:    while [[ $# -gt 0 ]]; do
scripts/dependency-guard.sh:123:            --cycles)
scripts/dependency-guard.sh:127:            --orphan-check)
scripts/dependency-guard.sh:129:                if [[ -z "$mode" ]]; then
scripts/dependency-guard.sh:134:            --exclude)
scripts/dependency-guard.sh:135:                if [[ -n "$exclude_patterns" ]]; then
scripts/dependency-guard.sh:142:            --rules)
scripts/dependency-guard.sh:144:                if [[ -z "$mode" ]]; then
scripts/dependency-guard.sh:149:            --all)
scripts/dependency-guard.sh:153:            --pre-commit)
scripts/dependency-guard.sh:157:            --scope)
scripts/dependency-guard.sh:162:            --path)
scripts/dependency-guard.sh:167:            --format)
scripts/dependency-guard.sh:171:            --with-deps)
scripts/dependency-guard.sh:175:            --debug)
scripts/dependency-guard.sh:179:            --help|-h)
scripts/dependency-guard.sh:190:    if ! command -v jq &>/dev/null; then
scripts/dependency-guard.sh:206:            if [[ -f "$rules_file" ]]; then
scripts/dependency-guard.sh:215:                    rule_scope=$(echo "$cycle_rule" | jq -r '.scope // ""')
scripts/dependency-guard.sh:216:                    if [[ -n "$rule_scope" ]]; then
scripts/dependency-guard.sh:243:                    if [[ $total_cycles -gt 0 ]]; then
scripts/dependency-guard.sh:244:                        echo "--- Cycles ---"
scripts/dependency-guard.sh:245:                        echo "$cycles" | jq -r '.[] | "Cycle: \(.path | join(" -> "))"'
scripts/dependency-guard.sh:248:                    if [[ $(echo "$orphan_summary" | jq '.orphan_count') -gt 0 ]]; then
scripts/dependency-guard.sh:249:                        echo "--- Orphan Modules ---"
scripts/dependency-guard.sh:250:                        echo "$orphans" | jq -r '.[]'
scripts/dependency-guard.sh:253:                    jq -n \
scripts/dependency-guard.sh:254:                        --arg schema_version "$REPORT_SCHEMA_VERSION" \
scripts/dependency-guard.sh:255:                        --argjson cycles "$cycles" \
scripts/dependency-guard.sh:256:                        --argjson orphans "$orphans" \
scripts/dependency-guard.sh:257:                        --argjson total_cycles "$total_cycles" \
scripts/dependency-guard.sh:258:                        --argjson orphan_summary "$orphan_summary" \
scripts/dependency-guard.sh:275:            if [[ -f "$rules_file" ]]; then
scripts/dependency-guard.sh:297:                if [[ "$orphan_count" -gt 0 ]]; then
scripts/dependency-guard.sh:298:                    echo "--- Orphan Modules ---"
scripts/dependency-guard.sh:299:                    echo "$orphan_result" | jq -r '.orphans[]'
scripts/dependency-guard.sh:308:                jq -n \
scripts/dependency-guard.sh:309:                    --arg schema_version "$REPORT_SCHEMA_VERSION" \
scripts/dependency-guard.sh:310:                    --argjson orphans "$orphans" \
scripts/dependency-guard.sh:311:                    --argjson summary "$orphan_summary" \
scripts/dependency-guard.sh:324:            if [[ -f "$rules_file" ]]; then
scripts/dependency-guard.sh:333:                    rule_scope=$(echo "$cycle_rule" | jq -r '.scope // ""')
scripts/dependency-guard.sh:334:                    if [[ -n "$rule_scope" ]]; then
scripts/dependency-guard.sh:346:            if [[ -z "$staged_files" ]]; then
scripts/dependency-guard.sh:353:            while IFS= read -r file; do
scripts/dependency-guard.sh:354:                [[ -n "$file" ]] && files_to_check+=("$file")
scripts/dependency-guard.sh:360:                    while IFS= read -r dep; do
scripts/dependency-guard.sh:361:                        [[ -n "$dep" ]] && files_to_check+=("$dep")
scripts/dependency-guard.sh:369:            if [[ -f "$rules_file" ]]; then
scripts/dependency-guard.sh:381:                [[ -f "$file" ]] || continue
scripts/dependency-guard.sh:391:            while IFS= read -r file; do
scripts/dependency-guard.sh:399:                files_checked=$(echo "$files_checked" | jq --arg f "$file" '. + [$f]')
scripts/dependency-guard.sh:403:            if [[ -n "$rules_json" ]]; then
scripts/dependency-guard.sh:407:            if [[ "${#files_to_check[@]}" -gt 0 ]]; then
scripts/dependency-guard.sh:421:    blocked=$(generate_report "$violations" "$cycles" "json" "$config" "$files_checked" | jq -r '.summary.blocked')
scripts/embedding.sh:14:set -euo pipefail
scripts/embedding.sh:56:log_info()  { [[ "$QUIET_MODE" == "true" ]] && return 0; echo -e "${BLUE}[Embedding]${NC} $1" >&2; }
scripts/embedding.sh:57:log_ok()    { [[ "$QUIET_MODE" == "true" ]] && return 0; echo -e "${GREEN}[Embedding]${NC} $1" >&2; }
scripts/embedding.sh:63:    echo -e "${YELLOW}[Embedding]${NC} $1" >&2
scripts/embedding.sh:66:log_error() { echo -e "${RED}[Embedding]${NC} $1" >&2; }  # ÈîôËØØÂßãÁªàËæìÂá∫
scripts/embedding.sh:69:    echo -e "${CYAN}[Embedding]${NC} $1" >&2
scripts/embedding.sh:79:  if [[ -n "${DEVBOOKS_ENABLE_ALL_FEATURES:-}" ]]; then
scripts/embedding.sh:83:  if [[ ! -f "$FEATURES_CONFIG_FILE" ]]; then
scripts/embedding.sh:128:  if [[ ! -x "$intent_script" ]]; then
scripts/embedding.sh:135:  prefs=$("$intent_script" get-preferences --top 50 2>/dev/null || echo "[]")
scripts/embedding.sh:136:  if ! echo "$prefs" | jq -e '.' >/dev/null 2>&1; then
scripts/embedding.sh:142:  echo "$candidates_json" | jq --argjson prefs "$prefs" '
scripts/embedding.sh:164:  if [[ ! -f "$tsv_file" ]]; then
scripts/embedding.sh:169:  json=$(jq -R -s '
scripts/embedding.sh:177:  echo "$json" | jq -r '.[] | "\(.score)\t\(.file)"' > "$tsv_file"
scripts/embedding.sh:186:  if [[ -n "${OLLAMA_UNAVAILABLE:-}" ]]; then
scripts/embedding.sh:191:  if [[ -n "${MOCK_OLLAMA_AVAILABLE:-}" ]]; then
scripts/embedding.sh:197:  if ! command -v ollama &>/dev/null; then
scripts/embedding.sh:204:  if curl -s --max-time 2 "${endpoint}/api/version" &>/dev/null; then
scripts/embedding.sh:217:  if [[ -n "${OPENAI_API_KEY:-}" ]] || [[ -n "${EMBEDDING_API_KEY:-}" ]]; then
scripts/embedding.sh:284:  if [[ -n "${MOCK_MODEL_NOT_DOWNLOADED:-}" ]]; then
scripts/embedding.sh:290:  if [[ -n "${MOCK_OLLAMA_AVAILABLE:-}" ]]; then
scripts/embedding.sh:301:  request_body=$(jq -n \
scripts/embedding.sh:302:    --arg model "$model" \
scripts/embedding.sh:303:    --arg prompt "$input_text" \
scripts/embedding.sh:309:  response=$(curl -s -w "\n%{http_code}" -X POST "${endpoint}/api/embeddings" \
scripts/embedding.sh:310:    -H "Content-Type: application/json" \
scripts/embedding.sh:311:    --max-time "$timeout" \
scripts/embedding.sh:312:    -d "$request_body" 2>/dev/null)
scripts/embedding.sh:314:  http_code=$(echo "$response" | tail -n1)
scripts/embedding.sh:324:  if echo "$response" | jq -e '.error' >/dev/null 2>&1; then
scripts/embedding.sh:326:    error_msg=$(echo "$response" | jq -r '.error // "Unknown error"')
scripts/embedding.sh:338:  echo "$response" | jq -r '.embedding | @json' > "$output_file"
scripts/embedding.sh:340:  if [[ ! -s "$output_file" ]]; then
scripts/embedding.sh:357:  if ! [[ "$top_k" =~ ^[0-9]+$ ]] || [[ "$top_k" -lt 1 ]]; then
scripts/embedding.sh:369:  if command -v rg &>/dev/null; then
scripts/embedding.sh:370:    while IFS= read -r line && [[ $idx -lt $top_k ]]; do
scripts/embedding.sh:372:      file_path=$(echo "$line" | cut -d':' -f1)
scripts/embedding.sh:373:      if [[ -n "$file_path" ]] && [[ -f "$PROJECT_ROOT/$file_path" ]]; then
scripts/embedding.sh:377:    done < <(rg -l --type-add 'code:*.{ts,tsx,js,jsx,py,go,rs,java,sh}' -t code -i "$query" "$PROJECT_ROOT" 2>/dev/null | head -n "$head_limit" | sed "s|^$PROJECT_ROOT/||")
scripts/embedding.sh:380:    while IFS= read -r line && [[ $idx -lt $top_k ]]; do
scripts/embedding.sh:382:      file_path=$(echo "$line" | cut -d':' -f1)
scripts/embedding.sh:383:      if [[ -n "$file_path" ]] && [[ -f "$PROJECT_ROOT/$file_path" ]]; then
scripts/embedding.sh:387:    done < <(grep -rl --include="*.ts" --include="*.tsx" --include="*.js" --include="*.py" --include="*.go" --include="*.sh" -i "$query" "$PROJECT_ROOT" 2>/dev/null | head -n "$head_limit" | sed "s|^$PROJECT_ROOT/||")
scripts/embedding.sh:390:  # ËæìÂá∫ÁªìÊûú (use ${results[@]+"${results[@]}"} to handle empty array with set -u)
scripts/embedding.sh:401:  if [ ! -f "$file" ]; then
scripts/embedding.sh:407:  sed -e 's/#.*$//' -e '/^[[:space:]]*$/d' "$file" | \
scripts/embedding.sh:408:  while IFS=: read -r key value; do
scripts/embedding.sh:410:    key=$(echo "$key" | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')
scripts/embedding.sh:411:    value=$(echo "$value" | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')
scripts/embedding.sh:423:    if [ -n "$key" ] && [ -n "$value" ]; then
scripts/embedding.sh:451:  if [ ! -f "$CONFIG_FILE" ]; then
scripts/embedding.sh:465:  enabled_val=$(echo "$config" | grep -E "^enabled:" | awk '{print $2}' || true)
scripts/embedding.sh:470:  provider_val=$(echo "$config" | grep -E "^\s*provider:" | head -1 | awk '{print $2}' || true)
scripts/embedding.sh:474:  auto_build_val=$(echo "$config" | grep -E "^\s*auto_build:" | awk '{print $2}' || true)
scripts/embedding.sh:478:  fallback_val=$(echo "$config" | grep -E "^\s*fallback_to_keyword:" | awk '{print $2}' || true)
scripts/embedding.sh:483:  ollama_model_val=$(echo "$config" | grep -A5 "ollama:" | grep "model:" | awk '{print $2}' || true)
scripts/embedding.sh:487:  ollama_endpoint_val=$(echo "$config" | grep -A5 "ollama:" | grep "endpoint:" | awk '{print $2}' || true)
scripts/embedding.sh:491:  ollama_timeout_val=$(echo "$config" | grep -A5 "ollama:" | grep "timeout:" | awk '{print $2}' || true)
scripts/embedding.sh:496:  api_model_val=$(echo "$config" | grep -A5 "openai:" | grep "model:" | awk '{print $2}' || true)
scripts/embedding.sh:500:  api_key_val=$(echo "$config" | grep -E "^\s*api_key:" | awk '{print $2}' || true)
scripts/embedding.sh:501:  if [[ -n "$api_key_val" ]]; then
scripts/embedding.sh:506:  api_base_val=$(echo "$config" | grep -E "^\s*base_url:" | awk '{print $2}' || true)
scripts/embedding.sh:510:  api_timeout_val=$(echo "$config" | grep -E "^\s*timeout:" | head -1 | awk '{print $2}' || true)
scripts/embedding.sh:514:  batch_size_val=$(echo "$config" | grep -E "^\s*batch_size:" | awk '{print $2}' || true)
scripts/embedding.sh:518:  storage_path=$(echo "$config" | grep -E "^\s*storage_path:" | awk '{print $2}' || true)
scripts/embedding.sh:522:  dimension_val=$(echo "$config" | grep -E "^\s*dimension:" | awk '{print $2}' || true)
scripts/embedding.sh:526:  index_type_val=$(echo "$config" | grep -E "^\s*index_type:" | awk '{print $2}' || true)
scripts/embedding.sh:530:  top_k_val=$(echo "$config" | grep -E "^\s*top_k:" | awk '{print $2}' || true)
scripts/embedding.sh:534:  threshold_val=$(echo "$config" | grep -E "^\s*similarity_threshold:" | awk '{print $2}' || true)
scripts/embedding.sh:538:  log_level_val=$(echo "$config" | grep -E "^\s*level:" | awk '{print $2}' || true)
scripts/embedding.sh:557:  if [ -z "$API_KEY" ]; then
scripts/embedding.sh:575:  local request_body=$(jq -n \
scripts/embedding.sh:576:    --arg model "$API_MODEL" \
scripts/embedding.sh:577:    --arg input "$input_text" \
scripts/embedding.sh:581:  local response=$(curl -s -X POST "$api_endpoint" \
scripts/embedding.sh:582:    -H "Content-Type: application/json" \
scripts/embedding.sh:583:    -H "Authorization: Bearer $API_KEY" \
scripts/embedding.sh:584:    --max-time "$API_TIMEOUT" \
scripts/embedding.sh:585:    -d "$request_body")
scripts/embedding.sh:588:  if echo "$response" | jq -e '.error' >/dev/null 2>&1; then
scripts/embedding.sh:589:    local error_msg=$(echo "$response" | jq -r '.error.message')
scripts/embedding.sh:595:  echo "$response" | jq -r '.data[0].embedding | @json' > "$output_file"
scripts/embedding.sh:597:  if [ ! -s "$output_file" ]; then
scripts/embedding.sh:611:  mkdir -p "$output_dir"
scripts/embedding.sh:613:  local total_lines=$(wc -l < "$input_file")
scripts/embedding.sh:648:  while IFS=$'\t' read -r file_path text; do
scripts/embedding.sh:662:      echo -e "$file_path\t$hash" >> "$output_dir/index.tsv"
scripts/embedding.sh:686:  while IFS=$'\t' read -r file_path text; do
scripts/embedding.sh:691:    if [ ${#batch_items[@]} -ge $BATCH_SIZE ] || [ $line_num -eq $total_lines ]; then
scripts/embedding.sh:696:      local inputs_json=$(printf '%s\n' "${batch_items[@]}" | awk -F'|' '{print $2}' | jq -R -s -c 'split("\n") | map(select(length > 0))')
scripts/embedding.sh:698:      local request_body=$(jq -n \
scripts/embedding.sh:699:        --arg model "$API_MODEL" \
scripts/embedding.sh:700:        --argjson inputs "$inputs_json" \
scripts/embedding.sh:704:      local response=$(curl -s -X POST "${API_BASE_URL}/embeddings" \
scripts/embedding.sh:705:        -H "Content-Type: application/json" \
scripts/embedding.sh:706:        -H "Authorization: Bearer $API_KEY" \
scripts/embedding.sh:707:        --max-time "$API_TIMEOUT" \
scripts/embedding.sh:708:        -d "$request_body")
scripts/embedding.sh:711:      if echo "$response" | jq -e '.error' >/dev/null 2>&1; then
scripts/embedding.sh:712:        local error_msg=$(echo "$response" | jq -r '.error.message')
scripts/embedding.sh:721:        local vector=$(echo "$response" | jq -r ".data[$idx].embedding | @json")
scripts/embedding.sh:724:        if [[ -z "$vector" ]] || [[ "$vector" == "null" ]]; then
scripts/embedding.sh:734:        echo -e "$file_path\t$hash" >> "$output_dir/index.tsv"
scripts/embedding.sh:762:  find "$PROJECT_ROOT" -type f \
scripts/embedding.sh:763:    \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \
scripts/embedding.sh:764:       -o -name "*.py" -o -name "*.go" -o -name "*.rs" -o -name "*.java" \
scripts/embedding.sh:765:       -o -name "*.md" \) \
scripts/embedding.sh:766:    ! -path "*/node_modules/*" \
scripts/embedding.sh:767:    ! -path "*/dist/*" \
scripts/embedding.sh:768:    ! -path "*/build/*" \
scripts/embedding.sh:769:    ! -path "*/.git/*" \
scripts/embedding.sh:770:    ! -path "*/__pycache__/*" \
scripts/embedding.sh:771:    ! -path "*/venv/*" \
scripts/embedding.sh:772:    ! -path "*/.venv/*" \
scripts/embedding.sh:773:    ! -path "*/target/*" \
scripts/embedding.sh:774:    ! -path "*/.next/*" \
scripts/embedding.sh:775:    ! -name "*.test.ts" \
scripts/embedding.sh:776:    ! -name "*.spec.ts" \
scripts/embedding.sh:777:    ! -name "*.test.js" \
scripts/embedding.sh:778:    ! -name "*.min.js" \
scripts/embedding.sh:779:    2>/dev/null | while read -r file; do
scripts/embedding.sh:785:    if [ -f "$file" ] && [ $(wc -c < "$file") -lt 1000000 ]; then
scripts/embedding.sh:786:      local content=$(cat "$file" | tr '\n' ' ' | head -c 10000)
scripts/embedding.sh:787:      echo -e "$rel_path\t$content" >> "$output_file"
scripts/embedding.sh:791:  local file_count=$(wc -l < "$output_file")
scripts/embedding.sh:801:  mkdir -p "$VECTOR_DB_DIR"
scripts/embedding.sh:809:  "created_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
scripts/embedding.sh:810:  "updated_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
scripts/embedding.sh:835:  if [ ! -s "$code_files" ]; then
scripts/embedding.sh:844:  local file_count=$(wc -l < "$VECTOR_DB_DIR/index.tsv")
scripts/embedding.sh:846:    --arg updated "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
scripts/embedding.sh:847:    --arg count "$file_count" \
scripts/embedding.sh:860:  if [ ! -f "$VECTOR_DB_DIR/index.tsv" ]; then
scripts/embedding.sh:871:  local index_mtime=$(stat -f %m "$VECTOR_DB_DIR/index.tsv" 2>/dev/null || stat -c %Y "$VECTOR_DB_DIR/index.tsv" 2>/dev/null)
scripts/embedding.sh:876:  while IFS=$'\t' read -r file_path content; do
scripts/embedding.sh:878:    if [ -f "$full_path" ]; then
scripts/embedding.sh:879:      local file_mtime=$(stat -f %m "$full_path" 2>/dev/null || stat -c %Y "$full_path" 2>/dev/null)
scripts/embedding.sh:880:      if [ "$file_mtime" -gt "$index_mtime" ]; then
scripts/embedding.sh:881:        echo -e "$file_path\t$content" >> "$modified_files"
scripts/embedding.sh:886:  local modified_count=$(wc -l < "$modified_files" 2>/dev/null || echo 0)
scripts/embedding.sh:888:  if [ "$modified_count" -eq 0 ]; then
scripts/embedding.sh:896:  while IFS=$'\t' read -r file_path hash; do
scripts/embedding.sh:897:    rm -f "$VECTOR_DB_DIR/$hash.json"
scripts/embedding.sh:898:  done < <(grep -Ff <(cut -f1 "$modified_files") "$VECTOR_DB_DIR/index.tsv" 2>/dev/null || true)
scripts/embedding.sh:914:  if command -v python3 &>/dev/null; then
scripts/embedding.sh:915:    python3 -c "
scripts/embedding.sh:1046:  if [[ -n "${MOCK_OLLAMA_AVAILABLE:-}" ]] || [[ "$API_KEY" == "sk-test-mock-key"* ]]; then
scripts/embedding.sh:1047:    if [ ! -f "$VECTOR_DB_DIR/index.tsv" ]; then
scripts/embedding.sh:1049:      mkdir -p "$VECTOR_DB_DIR"
scripts/embedding.sh:1055:        local hash="mock_$(echo "$file" | md5sum 2>/dev/null | cut -d' ' -f1 || echo "$idx")"
scripts/embedding.sh:1056:        echo -e "${file}\t${hash}" >> "$VECTOR_DB_DIR/index.tsv"
scripts/embedding.sh:1065:  if [ ! -f "$VECTOR_DB_DIR/index.tsv" ]; then
scripts/embedding.sh:1099:  while IFS=$'\t' read -r file_path hash; do
scripts/embedding.sh:1102:    if [ ! -f "$vector_file" ]; then
scripts/embedding.sh:1112:    if (( $(echo "$similarity >= $SIMILARITY_THRESHOLD" | bc -l 2>/dev/null || echo 1) )); then
scripts/embedding.sh:1113:      echo -e "$similarity\t$file_path" >> "$results"
scripts/embedding.sh:1118:  if [ -s "$results" ]; then
scripts/embedding.sh:1120:    LC_ALL=C sort -rn "$results" | head -n "$top_k" > "$TEMP_DIR/final_results.tsv"
scripts/embedding.sh:1147:    if [[ ${#items[@]} -gt 0 ]]; then
scripts/embedding.sh:1148:      candidates_json=$(printf '%s\n' "${items[@]}" | jq -s '.')
scripts/embedding.sh:1150:  elif [ -f "$TEMP_DIR/final_results.tsv" ]; then
scripts/embedding.sh:1153:    while IFS=$'\t' read -r score file; do
scripts/embedding.sh:1156:    if [[ ${#items[@]} -gt 0 ]]; then
scripts/embedding.sh:1157:      candidates_json=$(printf '%s\n' "${items[@]}" | jq -s '.')
scripts/embedding.sh:1167:  if [[ ${#COLLECTED_WARNINGS[@]} -gt 0 ]]; then
scripts/embedding.sh:1168:    warnings_json=$(printf '%s\n' "${COLLECTED_WARNINGS[@]}" | jq -R -s -c 'split("\n") | map(select(length > 0))')
scripts/embedding.sh:1172:  jq -n \
scripts/embedding.sh:1173:    --arg schema_version "1.0" \
scripts/embedding.sh:1174:    --arg query "$query" \
scripts/embedding.sh:1175:    --arg source "$source" \
scripts/embedding.sh:1176:    --arg model "$model" \
scripts/embedding.sh:1177:    --argjson candidates "$candidates_json" \
scripts/embedding.sh:1178:    --argjson latency_ms "$latency_ms" \
scripts/embedding.sh:1179:    --argjson warnings "$warnings_json" \
scripts/embedding.sh:1199:  if [[ "$ENABLE_CONTEXT_SIGNALS" == "true" ]] && [ -f "$TEMP_DIR/final_results.tsv" ]; then
scripts/embedding.sh:1210:      if [ -f "$full_path" ]; then
scripts/embedding.sh:1212:        head -n 10 "$full_path" | sed 's/^/  /'
scripts/embedding.sh:1216:  elif [ -f "$TEMP_DIR/final_results.tsv" ]; then
scripts/embedding.sh:1217:    log_ok "ÊâæÂà∞ $(wc -l < "$TEMP_DIR/final_results.tsv") ‰∏™Áõ∏ÂÖ≥ÁªìÊûú"
scripts/embedding.sh:1218:    while IFS=$'\t' read -r score file; do
scripts/embedding.sh:1221:      if [ -f "$full_path" ]; then
scripts/embedding.sh:1223:        head -n 10 "$full_path" | sed 's/^/  /'
scripts/embedding.sh:1253:  --provider <Á±ªÂûã>     Provider Á±ªÂûã: auto|ollama|openai|keyword
scripts/embedding.sh:1258:  --ollama-model <Âêç>   Ollama Ê®°ÂûãÂêçÁß∞ÔºàÈªòËÆ§: nomic-embed-textÔºâ
scripts/embedding.sh:1259:  --ollama-endpoint <URL> Ollama API Á´ØÁÇπÔºàÈªòËÆ§: http://localhost:11434Ôºâ
scripts/embedding.sh:1260:  --timeout <Áßí>        API Ë∂ÖÊó∂Êó∂Èó¥ÔºàÈªòËÆ§: 30Ôºâ
scripts/embedding.sh:1261:  --format <Ê†ºÂºè>       ËæìÂá∫Ê†ºÂºè: text|jsonÔºàÈªòËÆ§: textÔºâ
scripts/embedding.sh:1262:  --top-k <Êï∞Èáè>        ËøîÂõûÁªìÊûúÊï∞ÔºàÈªòËÆ§: 5Ôºâ
scripts/embedding.sh:1263:  --threshold <ÂÄº>      Áõ∏‰ººÂ∫¶ÈòàÂÄºÔºàÈªòËÆ§: 0.7Ôºâ
scripts/embedding.sh:1264:  --enable-context-signals  ÂêØÁî®‰∏ä‰∏ãÊñá‰ø°Âè∑Âä†ÊùÉÔºàÈúÄ intent-learnerÔºâ
scripts/embedding.sh:1267:  --config <Êñá‰ª∂>       ÊåáÂÆöÈÖçÁΩÆÊñá‰ª∂ÔºàÈªòËÆ§: .devbooks/config.yamlÔºâ
scripts/embedding.sh:1268:  --debug              ÂêØÁî®Ë∞ÉËØïÊ®°Âºè
scripts/embedding.sh:1269:  --enable-all-features ÂøΩÁï•ÂäüËÉΩÂºÄÂÖ≥ÈÖçÁΩÆÔºåÂº∫Âà∂ÂêØÁî®ÊâÄÊúâÂäüËÉΩ
scripts/embedding.sh:1279:  $0 search "authentication" --provider ollama --format json
scripts/embedding.sh:1282:  $0 search "test" --provider ollama --ollama-model mxbai-embed-large
scripts/embedding.sh:1285:  $0 search "test" --provider openai --format json
scripts/embedding.sh:1288:  $0 search "error" --provider keyword
scripts/embedding.sh:1291:  $0 search "Â§ÑÁêÜÊîØ‰ªòÁöÑ‰ª£Á†Å" --format json --top-k 10
scripts/embedding.sh:1326:  if [ ! -f "$VECTOR_DB_DIR/metadata.json" ]; then
scripts/embedding.sh:1335:  echo "  Ê®°Âûã: $(echo "$metadata" | jq -r '.model')"
scripts/embedding.sh:1336:  echo "  ÂêëÈáèÁª¥Â∫¶: $(echo "$metadata" | jq -r '.dimension')"
scripts/embedding.sh:1337:  echo "  Á¥¢ÂºïÁ±ªÂûã: $(echo "$metadata" | jq -r '.index_type')"
scripts/embedding.sh:1338:  echo "  Êñá‰ª∂Êï∞Èáè: $(echo "$metadata" | jq -r '.file_count // 0')"
scripts/embedding.sh:1339:  echo "  ÂàõÂª∫Êó∂Èó¥: $(echo "$metadata" | jq -r '.created_at')"
scripts/embedding.sh:1340:  echo "  Êõ¥Êñ∞Êó∂Èó¥: $(echo "$metadata" | jq -r '.updated_at')"
scripts/embedding.sh:1344:  if [ -d "$VECTOR_DB_DIR" ]; then
scripts/embedding.sh:1345:    local size=$(du -sh "$VECTOR_DB_DIR" | awk '{print $1}')
scripts/embedding.sh:1375:  if [ -d "$VECTOR_DB_DIR" ]; then
scripts/embedding.sh:1376:    rm -rf "$VECTOR_DB_DIR"
scripts/embedding.sh:1386:  if [ -z "$input_file" ] || [ ! -f "$input_file" ]; then
scripts/embedding.sh:1392:  total_queries=$(wc -l < "$input_file" | tr -d ' ')
scripts/embedding.sh:1402:  mkdir -p "$TEMP_DIR"
scripts/embedding.sh:1403:  trap "rm -rf '$TEMP_DIR'" EXIT
scripts/embedding.sh:1413:    --benchmark|benchmark)
scripts/embedding.sh:1423:      if [ -z "$1" ]; then
scripts/embedding.sh:1432:      while [[ $# -gt 0 ]]; do
scripts/embedding.sh:1434:          --provider)
scripts/embedding.sh:1438:          --ollama-model)
scripts/embedding.sh:1442:          --ollama-endpoint)
scripts/embedding.sh:1446:          --timeout)
scripts/embedding.sh:1450:          --format)
scripts/embedding.sh:1454:          --top-k)
scripts/embedding.sh:1458:          --threshold)
scripts/embedding.sh:1462:          --enable-context-signals)
scripts/embedding.sh:1466:          --enable-all-features)
scripts/embedding.sh:1470:          --debug)
scripts/embedding.sh:1505:while [[ $# -gt 0 ]]; do
scripts/embedding.sh:1507:    --config)
scripts/embedding.sh:1511:    --provider)
scripts/embedding.sh:1515:    --ollama-model)
scripts/embedding.sh:1519:    --ollama-endpoint)
scripts/embedding.sh:1523:    --timeout)
scripts/embedding.sh:1527:    --format)
scripts/embedding.sh:1531:    --top-k)
scripts/embedding.sh:1535:    --threshold)
scripts/embedding.sh:1539:    --debug)
scripts/federation-lite-virtual.sh:10:[[ -n "${FEDERATION_LITE_VIRTUAL_LOADED:-}" ]] && return 0
scripts/federation-lite-virtual.sh:58:    if [[ -n "$local_base" ]] && [[ -n "$remote_base" ]]; then
scripts/federation-lite-virtual.sh:71:    if [[ $local_len -eq 0 ]] || [[ $remote_len -eq 0 ]]; then
scripts/federation-lite-virtual.sh:79:    while [[ $i -lt $local_len ]]; do
scripts/federation-lite-virtual.sh:89:    [[ $remote_len -gt $max_len ]] && max_len=$remote_len
scripts/federation-lite-virtual.sh:92:    if command -v bc &>/dev/null; then
scripts/federation-lite-virtual.sh:101:    if command -v bc &>/dev/null; then
scripts/federation-lite-virtual.sh:155:    if [[ -n "$local_verb" ]] && [[ "$local_verb" == "$remote_verb" ]]; then
scripts/federation-lite-virtual.sh:163:    local_nouns=$(echo "$local_lower" | sed 's/[A-Z]/ &/g' | tr '[:upper:]' '[:lower:]' | grep -oE '[a-z]{3,}' | sort -u)
scripts/federation-lite-virtual.sh:166:    remote_nouns=$(echo "$remote_lower" | sed 's/[A-Z]/ &/g' | tr '[:upper:]' '[:lower:]' | grep -oE '[a-z]{3,}' | sort -u)
scripts/federation-lite-virtual.sh:170:    while IFS= read -r noun; do
scripts/federation-lite-virtual.sh:171:        [[ -z "$noun" ]] && continue
scripts/federation-lite-virtual.sh:172:        if echo "$remote_nouns" | grep -q "^${noun}$"; then
scripts/federation-lite-virtual.sh:177:    if [[ $common_nouns -gt 0 ]]; then
scripts/federation-lite-virtual.sh:193:    if command -v bc &>/dev/null; then
scripts/federation-lite-virtual.sh:207:    if command -v bc &>/dev/null; then
scripts/federation-lite-virtual.sh:238:    if [[ ! -f "$FEDERATION_INDEX" ]]; then
scripts/federation-lite-virtual.sh:239:        log_error "Federation index not found. Run --update first."
scripts/federation-lite-virtual.sh:244:    if [[ ! -f "$db_path" ]]; then
scripts/federation-lite-virtual.sh:246:        mkdir -p "$(dirname "$db_path")"
scripts/federation-lite-virtual.sh:304:    while IFS= read -r local_sym; do
scripts/federation-lite-virtual.sh:305:        [[ -z "$local_sym" ]] && continue
scripts/federation-lite-virtual.sh:309:        local_name=$(echo "$local_sym" | jq -r '.name')
scripts/federation-lite-virtual.sh:311:        local_file=$(echo "$local_sym" | jq -r '.file')
scripts/federation-lite-virtual.sh:321:            remote_repo_name=$(echo "$index" | jq -r ".repositories[$i].name")
scripts/federation-lite-virtual.sh:322:            remote_repo_path=$(echo "$index" | jq -r ".repositories[$i].path")
scripts/federation-lite-virtual.sh:332:                contract_type=$(echo "$index" | jq -r ".repositories[$i].contracts[$j].type")
scripts/federation-lite-virtual.sh:333:                contract_path=$(echo "$index" | jq -r ".repositories[$i].contracts[$j].path")
scripts/federation-lite-virtual.sh:341:                while IFS= read -r remote_symbol; do
scripts/federation-lite-virtual.sh:342:                    [[ -z "$remote_symbol" ]] && continue
scripts/federation-lite-virtual.sh:363:                    if command -v bc &>/dev/null; then
scripts/federation-lite-virtual.sh:393:                        if [[ "$exists" -gt 0 ]]; then
scripts/federation-lite-virtual.sh:403:                done < <(echo "$remote_symbols" | jq -r '.[]' 2>/dev/null)
scripts/federation-lite-virtual.sh:406:    done < <(echo "$local_symbols" | jq -c '.[]' 2>/dev/null)
scripts/federation-lite-virtual.sh:419:    jq -n \
scripts/federation-lite-virtual.sh:420:        --argjson created "$edges_created" \
scripts/federation-lite-virtual.sh:421:        --argjson updated "$edges_updated" \
scripts/federation-lite-virtual.sh:422:        --argjson skipped "$edges_skipped" \
scripts/federation-lite-virtual.sh:423:        --argjson total "$total_edges" \
scripts/federation-lite-virtual.sh:424:        --arg db_path "$db_path" \
scripts/federation-lite-virtual.sh:447:    if [[ ! -f "$db_path" ]]; then
scripts/federation-lite-virtual.sh:481:    if [[ -z "$results" ]] || [[ "$results" == "[]" ]] || [[ "$results" == "null" ]]; then
scripts/federation-lite-virtual.sh:489:        jq -n \
scripts/federation-lite-virtual.sh:490:            --arg symbol "$symbol" \
scripts/federation-lite-virtual.sh:491:            --argjson results "$results" \
scripts/federation-lite-virtual.sh:492:            --argjson count "$count" \
scripts/federation-lite-virtual.sh:503:        if [[ "$count" -gt 0 ]]; then
scripts/federation-lite-virtual.sh:504:            echo "$results" | jq -r '.[] | "  \(.source_symbol) -> \(.target_symbol) [\(.contract_type)]"'
scripts/federation-lite-virtual.sh:505:            echo "$results" | jq -r '.[] | "    Confidence: \(.confidence) (\(.confidence_level))"'
scripts/federation-lite-virtual.sh:506:            echo "$results" | jq -r '.[] | "    From: \(.source_repo) -> \(.target_repo)"'
scripts/drift-detector.sh:10:set -euo pipefail
scripts/drift-detector.sh:15:  if [[ -n "${_TEMP_FILES:-}" ]]; then
scripts/drift-detector.sh:17:      [[ -f "$f" ]] && rm -f "$f" 2>/dev/null || true
scripts/drift-detector.sh:21:  if [[ -n "${_SNAPSHOT_LOCK:-}" ]] && [[ -f "$_SNAPSHOT_LOCK" ]]; then
scripts/drift-detector.sh:22:    rm -f "$_SNAPSHOT_LOCK" 2>/dev/null || true
scripts/drift-detector.sh:29:if [ -f "$COMMON_LIB" ]; then
scripts/drift-detector.sh:39:if declare -f check_dependencies &>/dev/null; then
scripts/drift-detector.sh:42:  command -v jq &>/dev/null || { log_error "Áº∫Â∞ë‰æùËµñ: jq"; exit 2; }
scripts/drift-detector.sh:62:  drift-detector.sh --compare <baseline.json> <current.json>
scripts/drift-detector.sh:63:  drift-detector.sh --diff <baseline.json> <current.json>
scripts/drift-detector.sh:64:  drift-detector.sh --snapshot <project-dir> --output <snapshot.json>
scripts/drift-detector.sh:65:  drift-detector.sh --rules <arch-rules.yaml> <project-dir>
scripts/drift-detector.sh:66:  drift-detector.sh --report <snapshots-dir> --period weekly
scripts/drift-detector.sh:67:  drift-detector.sh --c4 <c4.md> --code <project-dir>
scripts/drift-detector.sh:68:  drift-detector.sh --parse-c4 <c4.md>
scripts/drift-detector.sh:69:  drift-detector.sh --scan-code <project-dir>
scripts/drift-detector.sh:70:  drift-detector.sh --enable-all-features --compare <baseline.json> <current.json>
scripts/drift-detector.sh:71:  drift-detector.sh --help
scripts/drift-detector.sh:76:  while [[ $# -gt 0 ]]; do
scripts/drift-detector.sh:78:      --compare)
scripts/drift-detector.sh:80:        if [[ $# -ge 3 ]]; then
scripts/drift-detector.sh:90:      --diff)
scripts/drift-detector.sh:92:        if [[ $# -ge 3 ]]; then
scripts/drift-detector.sh:102:      --snapshot)
scripts/drift-detector.sh:107:      --output)
scripts/drift-detector.sh:111:      --rules)
scripts/drift-detector.sh:117:      --report)
scripts/drift-detector.sh:122:      --c4)
scripts/drift-detector.sh:126:      --code)
scripts/drift-detector.sh:130:      --parse-c4)
scripts/drift-detector.sh:135:      --scan-code)
scripts/drift-detector.sh:140:      --period)
scripts/drift-detector.sh:144:      --enable-all-features)
scripts/drift-detector.sh:148:      --help|-h)
scripts/drift-detector.sh:160:  if [ -z "$MODE" ] && [ -n "$C4_FILE" ] && [ -n "$CODE_ROOT" ]; then
scripts/drift-detector.sh:174:  value=$(echo "$value" | sed -E 's/`//g; s/\\*//g')
scripts/drift-detector.sh:184:  while IFS= read -r line; do
scripts/drift-detector.sh:197:        IFS='|' read -r _ col1 col2 col3 col4 col5 _ <<< "$line"
scripts/drift-detector.sh:205:        if [ -z "$name" ] || [ "$name" = "Container" ]; then
scripts/drift-detector.sh:210:          --arg name "$name" \
scripts/drift-detector.sh:211:          --arg path "$path" \
scripts/drift-detector.sh:212:          --arg type "$type" \
scripts/drift-detector.sh:213:          --arg responsibility "$responsibility" \
scripts/drift-detector.sh:214:          --arg tech "$tech" \
scripts/drift-detector.sh:233:  while IFS= read -r line; do
scripts/drift-detector.sh:247:        IFS='|' read -r _ col1 _ col3 _ <<< "$line"
scripts/drift-detector.sh:252:        if [ -z "$component" ] || [ "$component" = "Component" ]; then
scripts/drift-detector.sh:257:        dep_list=$(echo "$deps_raw" | sed -E 's/[Ôºå„ÄÅ;+]/,/g')
scripts/drift-detector.sh:259:        IFS=',' read -r -a dep_items <<< "$dep_list"
scripts/drift-detector.sh:270:            --arg from "$component" \
scripts/drift-detector.sh:271:            --arg to "$dep" \
scripts/drift-detector.sh:293:  jq -n \
scripts/drift-detector.sh:294:    --argjson components "$components" \
scripts/drift-detector.sh:295:    --argjson dependencies "$dependencies" \
scripts/drift-detector.sh:303:  if command -v realpath &>/dev/null; then
scripts/drift-detector.sh:308:  if command -v python3 &>/dev/null; then
scripts/drift-detector.sh:317:  if command -v node &>/dev/null; then
scripts/drift-detector.sh:318:    node -e 'const path=require("path"); console.log(path.resolve(process.argv[1], process.argv[2]));' "$base" "$rel"
scripts/drift-detector.sh:344:    if [ -f "$candidate" ]; then
scripts/drift-detector.sh:350:  if [ -d "$resolved" ]; then
scripts/drift-detector.sh:359:      if [ -f "$index_candidate" ]; then
scripts/drift-detector.sh:379:    if [ -d "$dir" ]; then
scripts/drift-detector.sh:380:      while IFS= read -r -d '' file; do
scripts/drift-detector.sh:382:      done < <(find "$dir" -type f \( -name "*.sh" -o -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" -o -name "*.mjs" -o -name "*.cjs" \) -print0 2>/dev/null)
scripts/drift-detector.sh:398:      --arg path "$rel_path" \
scripts/drift-detector.sh:399:      --arg name "$(basename "$rel_path")" \
scripts/drift-detector.sh:400:      --arg type "$type" \
scripts/drift-detector.sh:405:      [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/drift-detector.sh:407:    [ -z "$rg_cmd" ] && rg_cmd=$(command -v rg 2>/dev/null || true)
scripts/drift-detector.sh:411:      if [ -n "$rg_cmd" ]; then
scripts/drift-detector.sh:412:        source_lines=$("$rg_cmd" -n "(^|[[:space:]])(source|\\.)[[:space:]]+['\"][^'\"]+['\"]" "$file" 2>/dev/null || true)
scripts/drift-detector.sh:414:        source_lines=$(grep -nE "(^|[[:space:]])(source|\\.)[[:space:]]+['\"][^'\"]+['\"]" "$file" 2>/dev/null || true)
scripts/drift-detector.sh:418:      while IFS= read -r line; do
scripts/drift-detector.sh:419:        [ -z "$line" ] && continue
scripts/drift-detector.sh:421:        dep_path=$(echo "$line" | sed -E "s/.*(source|\\.)[[:space:]]+['\"]([^'\"]+)['\"].*/\\2/")
scripts/drift-detector.sh:434:          --arg from "$rel_path" \
scripts/drift-detector.sh:435:          --arg to "$rel_dep" \
scripts/drift-detector.sh:436:          --arg dtype "source" \
scripts/drift-detector.sh:441:      if [ -n "$rg_cmd" ]; then
scripts/drift-detector.sh:442:        import_lines=$("$rg_cmd" -n "from[[:space:]]+['\"][^'\"]+['\"]|require\\(['\"][^'\"]+['\"]\\)" "$file" 2>/dev/null || true)
scripts/drift-detector.sh:444:        import_lines=$(grep -nE "from[[:space:]]+['\"][^'\"]+['\"]|require\\(['\"][^'\"]+['\"]\\)" "$file" 2>/dev/null || true)
scripts/drift-detector.sh:448:      while IFS= read -r line; do
scripts/drift-detector.sh:449:        [ -z "$line" ] && continue
scripts/drift-detector.sh:451:        import_path=$(echo "$line" | sed -E "s/.*from[[:space:]]+['\"]([^'\"]+)['\"].*/\\1/;s/.*require\\(['\"]([^'\"]+)['\"]\\).*/\\1/")
scripts/drift-detector.sh:465:          --arg from "$rel_path" \
scripts/drift-detector.sh:466:          --arg to "$rel_dep" \
scripts/drift-detector.sh:467:          --arg dtype "import" \
scripts/drift-detector.sh:473:  jq -n \
scripts/drift-detector.sh:474:    --argjson components "$components" \
scripts/drift-detector.sh:475:    --argjson dependencies "$dependencies" \
scripts/drift-detector.sh:490:  added=$(jq -n --argjson code "$code_components" --argjson c4 "$c4_components" \
scripts/drift-detector.sh:492:  removed=$(jq -n --argjson code "$code_components" --argjson c4 "$c4_components" \
scripts/drift-detector.sh:499:  if [ "$add_count" -gt 0 ]; then
scripts/drift-detector.sh:501:    while IFS= read -r item; do
scripts/drift-detector.sh:502:      [ -z "$item" ] && continue
scripts/drift-detector.sh:504:      change=$(jq -n --arg type "component_added" --arg component "$item" '{type: $type, component: $component}')
scripts/drift-detector.sh:506:    done <<< "$(echo "$added" | jq -r '.[]')"
scripts/drift-detector.sh:511:  if [ "$remove_count" -gt 0 ]; then
scripts/drift-detector.sh:513:    while IFS= read -r item; do
scripts/drift-detector.sh:514:      [ -z "$item" ] && continue
scripts/drift-detector.sh:516:      change=$(jq -n --arg type "component_removed" --arg component "$item" '{type: $type, component: $component}')
scripts/drift-detector.sh:518:    done <<< "$(echo "$removed" | jq -r '.[]')"
scripts/drift-detector.sh:539:  modified=$(jq -n --argjson c4 "$c4_entries" --argjson code "$code_entries" '
scripts/drift-detector.sh:546:  if [ "$mod_count" -gt 0 ]; then
scripts/drift-detector.sh:548:    while IFS= read -r item; do
scripts/drift-detector.sh:549:      [ -z "$item" ] && continue
scripts/drift-detector.sh:551:      change=$(jq -n \
scripts/drift-detector.sh:552:        --arg type "component_responsibility_changed" \
scripts/drift-detector.sh:553:        --arg base "$(echo "$item" | jq -r '.base')" \
scripts/drift-detector.sh:554:        --arg expected "$(echo "$item" | jq -r '.expected')" \
scripts/drift-detector.sh:557:    done <<< "$(echo "$modified" | jq -c '.[]')"
scripts/drift-detector.sh:578:  new_deps=$(jq -n --argjson code "$code_deps" --argjson c4 "$c4_deps" \
scripts/drift-detector.sh:583:  if [ "$dep_count" -gt 0 ]; then
scripts/drift-detector.sh:585:    while IFS= read -r item; do
scripts/drift-detector.sh:586:      [ -z "$item" ] && continue
scripts/drift-detector.sh:591:      change=$(jq -n --arg type "dependency_added" --arg from "$from" --arg to "$to" '{type: $type, from: $from, to: $to}')
scripts/drift-detector.sh:593:    done <<< "$(echo "$new_deps" | jq -r '.[]')"
scripts/drift-detector.sh:634:  if [ "$score" -ge 50 ]; then
scripts/drift-detector.sh:636:  elif [ "$score" -ge 20 ]; then
scripts/drift-detector.sh:641:  if [ "$score" -gt 0 ]; then
scripts/drift-detector.sh:645:  jq -n \
scripts/drift-detector.sh:646:    --argjson drift_detected "$drift_detected" \
scripts/drift-detector.sh:647:    --argjson score "$score" \
scripts/drift-detector.sh:648:    --arg severity "$severity" \
scripts/drift-detector.sh:649:    --argjson changes "$changes" \
scripts/drift-detector.sh:650:    --argjson recommendations "$recommendations" \
scripts/drift-detector.sh:663:  jq -r ".metrics.${key} // 0" "$file" 2>/dev/null
scripts/drift-detector.sh:669:  if [ "$base" -le 0 ]; then
scripts/drift-detector.sh:673:  awk -v b="$base" -v c="$current" 'BEGIN {printf "%.2f", ((c-b)/b)*100}'
scripts/drift-detector.sh:679:  echo "$changes" | jq --argjson c "$change" '. + [$c]'
scripts/drift-detector.sh:685:  echo "$recs" | jq --arg r "$rec" '. + [$r]'
scripts/drift-detector.sh:704:  if awk -v v="$coupling_change" 'BEGIN {exit !(v>=10)}'; then
scripts/drift-detector.sh:706:    change=$(jq -n \
scripts/drift-detector.sh:707:      --arg type "coupling_increase" \
scripts/drift-detector.sh:708:      --argjson from "$base_coupling" \
scripts/drift-detector.sh:709:      --argjson to "$current_coupling" \
scripts/drift-detector.sh:710:      --argjson change_percent "$coupling_change" \
scripts/drift-detector.sh:734:  if [ "$current_violations" -gt "$base_violations" ]; then
scripts/drift-detector.sh:736:    change=$(jq -n \
scripts/drift-detector.sh:737:      --arg type "dependency_violation_increase" \
scripts/drift-detector.sh:738:      --argjson from "$base_violations" \
scripts/drift-detector.sh:739:      --argjson to "$current_violations" \
scripts/drift-detector.sh:750:  if awk -v b="$base_boundary" -v c="$current_boundary" 'BEGIN {exit !((b-c)>=0.10)}'; then
scripts/drift-detector.sh:752:    change=$(jq -n \
scripts/drift-detector.sh:753:      --arg type "boundary_blur" \
scripts/drift-detector.sh:754:      --argjson from "$base_boundary" \
scripts/drift-detector.sh:755:      --argjson to "$current_boundary" \
scripts/drift-detector.sh:756:      --argjson drop "$(awk -v b="$base_boundary" -v c="$current_boundary" 'BEGIN {printf "%.2f", (b-c)}')" \
scripts/drift-detector.sh:780:  if [ "$current_cycles" -gt "$base_cycles" ]; then
scripts/drift-detector.sh:782:    change=$(jq -n \
scripts/drift-detector.sh:783:      --arg type "cyclic_dependency_increase" \
scripts/drift-detector.sh:784:      --argjson from "$base_cycles" \
scripts/drift-detector.sh:785:      --argjson to "$current_cycles" \
scripts/drift-detector.sh:794:  hotspot_paths=$(jq -r '.hotspot_files[]?.path' "$baseline" 2>/dev/null || true)
scripts/drift-detector.sh:795:  if [ -n "$hotspot_paths" ]; then
scripts/drift-detector.sh:797:    while IFS= read -r path; do
scripts/drift-detector.sh:798:      [ -z "$path" ] && continue
scripts/drift-detector.sh:800:      base_value=$(jq -r --arg p "$path" '.hotspot_files[]? | select(.path==$p) | .coupling // 0' "$baseline" | head -1)
scripts/drift-detector.sh:801:      current_value=$(jq -r --arg p "$path" '.hotspot_files[]? | select(.path==$p) | .coupling // 0' "$current" | head -1)
scripts/drift-detector.sh:802:      if [ -z "$current_value" ]; then
scripts/drift-detector.sh:805:      if [ "$current_value" -gt "$base_value" ]; then
scripts/drift-detector.sh:807:        if [ "$delta" -ge 10 ]; then
scripts/drift-detector.sh:809:          change=$(jq -n \
scripts/drift-detector.sh:810:            --arg type "hotspot_coupling_increase" \
scripts/drift-detector.sh:811:            --arg file "$path" \
scripts/drift-detector.sh:812:            --argjson from "$base_value" \
scripts/drift-detector.sh:813:            --argjson to "$current_value" \
scripts/drift-detector.sh:855:  if [ "$score" -ge 40 ]; then
scripts/drift-detector.sh:857:  elif [ "$score" -ge 20 ]; then
scripts/drift-detector.sh:864:  if [ "$change_count" -gt 0 ]; then
scripts/drift-detector.sh:868:  jq -n \
scripts/drift-detector.sh:869:    --argjson drift_detected "$drift_detected" \
scripts/drift-detector.sh:870:    --argjson score "$score" \
scripts/drift-detector.sh:871:    --arg severity "$severity" \
scripts/drift-detector.sh:872:    --argjson changes "$changes" \
scripts/drift-detector.sh:873:    --argjson recommendations "$recommendations" \
scripts/drift-detector.sh:890:  while IFS= read -r line; do
scripts/drift-detector.sh:893:        if [ -n "$from" ] && [ -n "$to" ]; then
scripts/drift-detector.sh:896:        from=$(echo "$line" | sed -E 's/.*from:[[:space:]]*//;s/"//g')
scripts/drift-detector.sh:902:        if [ -n "$from" ] && [ -n "$to" ]; then
scripts/drift-detector.sh:911:        from=$(echo "$line" | sed -E 's/.*from:[[:space:]]*//;s/"//g')
scripts/drift-detector.sh:914:        to=$(echo "$line" | sed -E 's/.*to:[[:space:]]*//;s/"//g')
scripts/drift-detector.sh:917:        allow=$(echo "$line" | sed -E 's/.*allow:[[:space:]]*//;s/"//g')
scripts/drift-detector.sh:920:        reason=$(echo "$line" | sed -E 's/.*reason:[[:space:]]*//;s/"//g')
scripts/drift-detector.sh:925:  if [ -n "$from" ] && [ -n "$to" ]; then
scripts/drift-detector.sh:932:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/drift-detector.sh:934:  [ -z "$rg_cmd" ] && rg_cmd=$(command -v rg 2>/dev/null || true)
scripts/drift-detector.sh:937:  files=$(find "$target" -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \) 2>/dev/null)
scripts/drift-detector.sh:943:    file_module=$(echo "$rel_file" | cut -d'/' -f1)
scripts/drift-detector.sh:946:    if [ -n "$rg_cmd" ]; then
scripts/drift-detector.sh:947:      imports=$("$rg_cmd" -n "from[[:space:]]+['\"][^'\"]+['\"]|require\\(['\"][^'\"]+['\"]\\)" "$file" 2>/dev/null || true)
scripts/drift-detector.sh:949:      imports=$(grep -nE "from[[:space:]]+['\"][^'\"]+['\"]|require\\(['\"][^'\"]+['\"]\\)" "$file" 2>/dev/null || true)
scripts/drift-detector.sh:952:    while IFS= read -r line; do
scripts/drift-detector.sh:953:      [ -z "$line" ] && continue
scripts/drift-detector.sh:955:      import_path=$(echo "$line" | sed -E "s/.*from[[:space:]]+['\"]([^'\"]+)['\"].*/\1/;s/.*require\\(['\"]([^'\"]+)['\"]\\).*/\1/")
scripts/drift-detector.sh:961:        cleaned=$(echo "$import_path" | sed -E 's#^\.\./+##')
scripts/drift-detector.sh:963:        import_module=$(echo "$cleaned" | cut -d'/' -f1)
scripts/drift-detector.sh:967:          IFS='|' read -r rule_from rule_to rule_allow rule_reason <<< "$rule"
scripts/drift-detector.sh:970:            violation=$(jq -n \
scripts/drift-detector.sh:971:              --arg type "dependency_violation" \
scripts/drift-detector.sh:972:              --arg from "$rule_from" \
scripts/drift-detector.sh:973:              --arg to "$rule_to" \
scripts/drift-detector.sh:974:              --arg file "${file#"$target"/}" \
scripts/drift-detector.sh:975:              --arg path "$import_path" \
scripts/drift-detector.sh:976:              --arg reason "$rule_reason" \
scripts/drift-detector.sh:978:            violations=$(echo "$violations" | jq --argjson v "$violation" '. + [$v]')
scripts/drift-detector.sh:985:  jq -n --argjson violations "$violations" '{violations: $violations}'
scripts/drift-detector.sh:994:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/drift-detector.sh:996:  [ -z "$rg_cmd" ] && rg_cmd=$(command -v rg 2>/dev/null || true)
scripts/drift-detector.sh:999:  if [ -n "$rg_cmd" ]; then
scripts/drift-detector.sh:1001:    rg_output=$("$rg_cmd" -c "from[[:space:]]+['\"][^'\"]+['\"]|require\\(['\"][^'\"]+['\"]\\)" "$target" 2>/dev/null || true)
scripts/drift-detector.sh:1002:    total_coupling=$(echo "$rg_output" | awk -F: '{sum+=$2} END {print sum+0}')
scripts/drift-detector.sh:1005:    grep_output=$(grep -R -cE "from[[:space:]]+['\"][^'\"]+['\"]|require\\(['\"][^'\"]+['\"]\\)" "$target" 2>/dev/null || true)
scripts/drift-detector.sh:1006:    total_coupling=$(echo "$grep_output" | awk -F: '{sum+=$2} END {print sum+0}')
scripts/drift-detector.sh:1010:  snapshot=$(jq -n \
scripts/drift-detector.sh:1011:    --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
scripts/drift-detector.sh:1012:    --arg version "1.0.0" \
scripts/drift-detector.sh:1013:    --argjson total_coupling "$total_coupling" \
scripts/drift-detector.sh:1026:  if [ -n "$output" ]; then
scripts/drift-detector.sh:1027:    mkdir -p "$(dirname "$output")"
scripts/drift-detector.sh:1040:  if [ -z "$snapshots" ]; then
scripts/drift-detector.sh:1046:  first=$(echo "$snapshots" | head -1)
scripts/drift-detector.sh:1047:  last=$(echo "$snapshots" | tail -1)
scripts/drift-detector.sh:1054:  if [ "$last_coupling" -gt "$first_coupling" ]; then
scripts/drift-detector.sh:1056:  elif [ "$last_coupling" -lt "$first_coupling" ]; then
scripts/drift-detector.sh:1060:  jq -n \
scripts/drift-detector.sh:1061:    --arg period "$period" \
scripts/drift-detector.sh:1062:    --arg trend "$trend" \
scripts/drift-detector.sh:1063:    --argjson first "$first_coupling" \
scripts/drift-detector.sh:1064:    --argjson last "$last_coupling" \
scripts/drift-detector.sh:1082:  if declare -f is_feature_enabled &>/dev/null; then
scripts/drift-detector.sh:1092:      if [ -z "$BASELINE" ] || [ -z "$CURRENT" ]; then
scripts/drift-detector.sh:1099:      if [ -z "$BASELINE" ] || [ -z "$CURRENT" ]; then
scripts/drift-detector.sh:1105:      jq -n \
scripts/drift-detector.sh:1106:        --argjson before "$(cat "$BASELINE")" \
scripts/drift-detector.sh:1107:        --argjson after "$(cat "$CURRENT")" \
scripts/drift-detector.sh:1108:        --argjson changes "$(echo "$changes" | jq '.changes')" \
scripts/drift-detector.sh:1116:      if [ -z "$SNAPSHOT_DIR" ]; then
scripts/drift-detector.sh:1120:      if [ -z "$SNAPSHOT_OUTPUT" ]; then
scripts/drift-detector.sh:1121:        log_error "snapshot ÈúÄË¶Å --output"
scripts/drift-detector.sh:1127:      if [ -z "$RULES_FILE" ] || [ -z "$RULES_TARGET" ]; then
scripts/drift-detector.sh:1134:      if [ -z "$REPORT_DIR" ]; then
scripts/drift-detector.sh:1141:      if [ -z "$C4_FILE" ]; then
scripts/drift-detector.sh:1148:      if [ -z "$CODE_ROOT" ]; then
scripts/drift-detector.sh:1155:      if [ -z "$C4_FILE" ] || [ -z "$CODE_ROOT" ]; then
scripts/drift-detector.sh:1156:        log_error "c4-drift ÈúÄË¶Å --c4 Âíå --code"
scripts/graph-rag-core.sh:75:  while kill -0 $pid 2>/dev/null; do
scripts/graph-rag-core.sh:76:    if [ $count -ge $timeout_sec ]; then
scripts/graph-rag-core.sh:77:      kill -9 $pid 2>/dev/null
scripts/graph-rag-core.sh:79:      rm -f "$output_file" "$pid_file" "$pid_file.exit"
scripts/graph-rag-core.sh:88:  if [ -f "$pid_file.exit" ]; then
scripts/graph-rag-core.sh:93:  rm -f "$output_file" "$pid_file" "$pid_file.exit"
scripts/graph-rag-core.sh:99:  if [[ -n "${CKB_UNAVAILABLE:-}" ]]; then
scripts/graph-rag-core.sh:109:  if [[ "$MOCK_CKB" = true || -n "${MOCK_CKB_AVAILABLE:-}" ]]; then
scripts/graph-rag-core.sh:114:  if [[ -n "${CKB_MCP_CLIENT:-}" ]]; then
scripts/graph-rag-core.sh:115:    if [[ ! -x "$CKB_MCP_CLIENT" ]]; then
scripts/graph-rag-core.sh:122:    ckb_hash=$(echo "$CKB_MCP_CLIENT" | md5sum 2>/dev/null | cut -d' ' -f1 || echo "$CKB_MCP_CLIENT" | md5 2>/dev/null || echo "default")
scripts/graph-rag-core.sh:126:    if [[ -f "$cooldown_file" ]]; then
scripts/graph-rag-core.sh:133:      if [[ "$elapsed" -lt "$cooldown_period" ]]; then
scripts/graph-rag-core.sh:150:  if [[ -n "${CKB_MCP_CLIENT:-}" ]]; then
scripts/graph-rag-core.sh:152:    ckb_hash=$(echo "$CKB_MCP_CLIENT" | md5sum 2>/dev/null | cut -d' ' -f1 || echo "$CKB_MCP_CLIENT" | md5 2>/dev/null || echo "default")
scripts/graph-rag-core.sh:162:  if [[ -n "${FEATURES_CONFIG:-}" && -f "$FEATURES_CONFIG" ]]; then
scripts/graph-rag-core.sh:167:  if [[ -n "${DEVBOOKS_FEATURE_CONFIG:-}" && -f "$DEVBOOKS_FEATURE_CONFIG" ]]; then
scripts/graph-rag-core.sh:172:  if [[ -f "$CWD/config/features.yaml" ]]; then
scripts/graph-rag-core.sh:177:  if [[ -f "$PROJECT_ROOT/config/features.yaml" ]]; then
scripts/graph-rag-core.sh:190:  if [[ -z "$config_file" || ! -f "$config_file" ]]; then
scripts/graph-rag-core.sh:197:  while IFS= read -r line || [[ -n "$line" ]]; do
scripts/graph-rag-core.sh:199:    [[ -z "$line" ]] && continue
scripts/graph-rag-core.sh:239:  if [[ -z "$config_file" || ! -f "$config_file" ]]; then
scripts/graph-rag-core.sh:247:  while IFS= read -r line || [[ -n "$line" ]]; do
scripts/graph-rag-core.sh:249:    [[ -z "$line" ]] && continue
scripts/graph-rag-core.sh:311:  if [[ -n "${DEVBOOKS_ENABLE_ALL_FEATURES:-}" ]]; then
scripts/graph-rag-core.sh:319:  if declare -f hash_string_md5 &>/dev/null; then
scripts/graph-rag-core.sh:321:  elif command -v md5sum &>/dev/null; then
scripts/graph-rag-core.sh:322:    printf '%s' "$1" | md5sum 2>/dev/null | cut -d' ' -f1
scripts/graph-rag-core.sh:323:  elif command -v md5 &>/dev/null; then
scripts/graph-rag-core.sh:324:    if md5 -q /dev/null >/dev/null 2>&1; then
scripts/graph-rag-core.sh:325:      printf '%s' "$1" | md5 -q 2>/dev/null
scripts/graph-rag-core.sh:330:    printf '%s' "$1" | cksum 2>/dev/null | cut -d' ' -f1
scripts/graph-rag-core.sh:345:    if [[ -f "$candidate" ]]; then
scripts/graph-rag-core.sh:359:  if [[ "$GRAPH_RAG_CACHE_ENABLED" == "true" ]] && [[ -x "$CACHE_MANAGER" ]]; then
scripts/graph-rag-core.sh:364:    if [[ -n "$cache_anchor" ]]; then
scripts/graph-rag-core.sh:365:      cache_result=$("$CACHE_MANAGER" --get "$cache_anchor" --query "$query_hash" 2>/dev/null)
scripts/graph-rag-core.sh:370:    if [[ -n "$cache_result" ]] && echo "$cache_result" | jq -e '.schema_version' &>/dev/null; then
scripts/graph-rag-core.sh:379:  if [ -f "$cache_file" ]; then
scripts/graph-rag-core.sh:382:    mtime=$(stat -f %m "$cache_file" 2>/dev/null || stat -c %Y "$cache_file" 2>/dev/null || echo 0)
scripts/graph-rag-core.sh:384:    if [ "${age:-0}" -lt "${CACHE_TTL:-300}" ]; then
scripts/graph-rag-core.sh:398:  if [[ "$GRAPH_RAG_CACHE_ENABLED" == "true" ]] && [[ -x "$CACHE_MANAGER" ]]; then
scripts/graph-rag-core.sh:401:    if [[ -n "$cache_anchor" ]]; then
scripts/graph-rag-core.sh:402:      "$CACHE_MANAGER" --set "$cache_anchor" --query "$query_hash" --value "$value" 2>/dev/null || true
scripts/graph-rag-core.sh:407:  mkdir -p "$CACHE_DIR" 2>/dev/null
scripts/graph-rag-core.sh:426:  if [ -x "$BOUNDARY_DETECTOR" ]; then
scripts/graph-rag-core.sh:428:    result=$("$BOUNDARY_DETECTOR" --format json "$file_path" 2>/dev/null) || true
scripts/graph-rag-core.sh:430:    if [ -n "$result" ]; then
scripts/graph-rag-core.sh:432:      boundary_type=$(echo "$result" | jq -r '.type // "user"' 2>/dev/null)
scripts/graph-rag-core.sh:456:    file_path=$(echo "$candidate" | jq -r '.file_path')
scripts/graph-rag-core.sh:459:      result=$(echo "$result" | jq --argjson c "$candidate" '. + [$c]')
scripts/dependency-guard-orphan.sh:44:    if [[ -n "$exclude_patterns" ]]; then
scripts/dependency-guard-orphan.sh:45:        while IFS= read -r pattern; do
scripts/dependency-guard-orphan.sh:46:            [[ -z "$pattern" ]] && continue
scripts/dependency-guard-orphan.sh:62:    if [[ -n "${FEATURES_CONFIG:-}" && -f "$FEATURES_CONFIG" ]]; then
scripts/dependency-guard-orphan.sh:64:        enabled=$(grep -A1 "orphan_detection:" "$FEATURES_CONFIG" 2>/dev/null | grep "enabled:" | grep -o "false" || true)
scripts/dependency-guard-orphan.sh:72:    temp_dir=$(mktemp -d)
scripts/dependency-guard-orphan.sh:83:    while IFS= read -r -d '' file; do
scripts/dependency-guard-orphan.sh:93:        while IFS= read -r imp; do
scripts/dependency-guard-orphan.sh:94:            [[ -z "$imp" ]] && continue
scripts/dependency-guard-orphan.sh:96:            target=$(echo "$imp" | jq -r '.target' 2>/dev/null)
scripts/dependency-guard-orphan.sh:97:            [[ -z "$target" ]] && continue
scripts/dependency-guard-orphan.sh:101:            [[ -z "$resolved" || ! -f "$resolved" ]] && continue
scripts/dependency-guard-orphan.sh:106:        done < <(echo "$imports" | jq -c '.[]' 2>/dev/null)
scripts/dependency-guard-orphan.sh:107:    done < <(find "$scope" -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \) -print0 2>/dev/null)
scripts/dependency-guard-orphan.sh:109:    if [[ $file_count -eq 0 ]]; then
scripts/dependency-guard-orphan.sh:110:        rm -rf "$temp_dir"
scripts/dependency-guard-orphan.sh:119:    while IFS= read -r node; do
scripts/dependency-guard-orphan.sh:120:        [[ -z "$node" ]] && continue
scripts/dependency-guard-orphan.sh:123:        if grep -qF "$node" "$incoming_file" 2>/dev/null; then
scripts/dependency-guard-orphan.sh:137:        orphans=$(echo "$orphans" | jq --arg file "$node" '. + [$file]')
scripts/dependency-guard-orphan.sh:143:    if [[ $file_count -gt 0 ]]; then
scripts/dependency-guard-orphan.sh:144:        orphan_ratio=$(awk -v oc="$orphan_count" -v fc="$file_count" 'BEGIN { printf "%.4f", oc / fc }')
scripts/dependency-guard-orphan.sh:147:    rm -rf "$temp_dir"
scripts/dependency-guard-orphan.sh:149:    jq -n \
scripts/dependency-guard-orphan.sh:150:        --argjson orphans "$orphans" \
scripts/dependency-guard-orphan.sh:151:        --argjson total_nodes "$file_count" \
scripts/dependency-guard-orphan.sh:152:        --argjson orphan_count "$orphan_count" \
scripts/dependency-guard-orphan.sh:153:        --arg orphan_ratio "$orphan_ratio" \
scripts/llm-provider.sh:16:set -euo pipefail
scripts/llm-provider.sh:23:if [[ -f "$SCRIPT_DIR/common.sh" ]]; then
scripts/llm-provider.sh:59:  if [[ ! -f "$config_file" ]]; then
scripts/llm-provider.sh:99:  awk -v provider="$provider" -v key="$key" '
scripts/llm-provider.sh:120:  if [[ -f "$config_file" ]]; then
scripts/llm-provider.sh:149:  if [[ -z "$provider" ]]; then
scripts/llm-provider.sh:153:  if [[ -z "$provider" ]]; then
scripts/llm-provider.sh:159:  if [[ -n "${LLM_MOCK_MODE:-}" ]]; then
scripts/llm-provider.sh:163:    if [[ -n "$env_key" ]] && [[ "$env_key" != "null" ]] && [[ -z "${!env_key:-}" ]]; then
scripts/llm-provider.sh:173:  if [[ -z "$script" ]]; then
scripts/llm-provider.sh:180:  if [[ ! -f "$script_path" ]]; then
scripts/llm-provider.sh:201:  if [[ -n "${LLM_PROVIDER:-}" ]]; then
scripts/llm-provider.sh:205:  if [[ -n "${LLM_DEFAULT_PROVIDER:-}" ]]; then
scripts/llm-provider.sh:211:  if [[ -n "${LLM_MOCK_RESPONSE:-}" ]]; then
scripts/llm-provider.sh:217:  if [[ -n "${ANTHROPIC_API_KEY:-}" ]]; then
scripts/llm-provider.sh:223:  if [[ -n "${OPENAI_API_KEY:-}" ]]; then
scripts/llm-provider.sh:232:  if command -v curl &>/dev/null; then
scripts/llm-provider.sh:233:    if curl -s --connect-timeout 1 "$ollama_endpoint/api/tags" &>/dev/null; then
scripts/llm-provider.sh:263:  if [[ -z "$query" ]]; then
scripts/llm-provider.sh:268:  if [[ -z "$candidates" ]]; then
scripts/llm-provider.sh:276:  if date +%s%3N 2>/dev/null | grep -q 'N'; then
scripts/llm-provider.sh:286:    if date +%s%3N 2>/dev/null | grep -q 'N'; then
scripts/llm-provider.sh:294:    jq -n \
scripts/llm-provider.sh:295:      --argjson result "$result" \
scripts/llm-provider.sh:296:      --arg provider "$_LLM_CURRENT_PROVIDER" \
scripts/llm-provider.sh:297:      --argjson latency "$latency_ms" \
scripts/llm-provider.sh:306:    jq -n \
scripts/llm-provider.sh:307:      --arg provider "$_LLM_CURRENT_PROVIDER" \
scripts/llm-provider.sh:308:      --arg error "$error_msg" \
scripts/llm-provider.sh:326:  if [[ -z "$prompt" ]]; then
scripts/llm-provider.sh:334:  if date +%s%3N 2>/dev/null | grep -q 'N'; then
scripts/llm-provider.sh:343:    if date +%s%3N 2>/dev/null | grep -q 'N'; then
scripts/llm-provider.sh:351:    jq -n \
scripts/llm-provider.sh:352:      --arg result "$result" \
scripts/llm-provider.sh:353:      --arg provider "$_LLM_CURRENT_PROVIDER" \
scripts/llm-provider.sh:354:      --argjson latency "$latency_ms" \
scripts/llm-provider.sh:363:    jq -n \
scripts/llm-provider.sh:364:      --arg provider "$_LLM_CURRENT_PROVIDER" \
scripts/llm-provider.sh:365:      --arg error "$error_msg" \
scripts/llm-provider.sh:388:    if [[ -n "$env_key" ]]; then
scripts/llm-provider.sh:389:      if [[ -z "${!env_key:-}" ]]; then
scripts/llm-provider.sh:410:  if [[ -z "$env_key" ]] || [[ -n "${!env_key:-}" ]]; then
scripts/llm-provider.sh:414:  jq -n \
scripts/llm-provider.sh:415:    --arg provider "$_LLM_CURRENT_PROVIDER" \
scripts/llm-provider.sh:416:    --arg script "$_LLM_PROVIDER_SCRIPT" \
scripts/llm-provider.sh:417:    --arg env_key "$env_key" \
scripts/llm-provider.sh:418:    --arg default_model "$default_model" \
scripts/llm-provider.sh:419:    --arg endpoint "$endpoint" \
scripts/llm-provider.sh:420:    --argjson api_key_configured "$api_key_configured" \
scripts/llm-provider.sh:439:  if [[ -z "$new_provider" ]]; then
scripts/llm-provider.sh:465:  if [[ -n "${LLM_MOCK_RESPONSE:-}" ]]; then
scripts/llm-provider.sh:523:  --provider <name>    ÊåáÂÆö Provider (anthropic/openai/ollama/mock)
scripts/llm-provider.sh:524:  --model <name>       ÊåáÂÆöÊ®°Âûã
scripts/llm-provider.sh:525:  --timeout <ms>       Ë∂ÖÊó∂ÊØ´ÁßíÊï∞ÔºàÈªòËÆ§ 2000Ôºâ
scripts/llm-provider.sh:526:  --help               ÊòæÁ§∫Ê≠§Â∏ÆÂä©
scripts/llm-provider.sh:527:  --version            ÊòæÁ§∫ÁâàÊú¨
scripts/llm-provider.sh:547:  echo '{"query":"test","candidates":[...]}' | ./llm-provider.sh rerank --provider anthropic
scripts/llm-provider.sh:550:  echo "ÂàÜÊûêËøôÊÆµ‰ª£Á†Å" | ./llm-provider.sh call --provider openai
scripts/llm-provider.sh:566:  while [[ $# -gt 0 ]]; do
scripts/llm-provider.sh:572:      --provider)
scripts/llm-provider.sh:576:      --model)
scripts/llm-provider.sh:580:      --timeout)
scripts/llm-provider.sh:584:      --help|-h)
scripts/llm-provider.sh:588:      --version)
scripts/llm-provider.sh:594:        if [[ -z "$command" ]]; then
scripts/llm-provider.sh:605:  [[ -n "$provider" ]] && LLM_DEFAULT_PROVIDER="$provider"
scripts/llm-provider.sh:606:  [[ -n "$model" ]] && LLM_DEFAULT_MODEL="$model"
scripts/llm-provider.sh:607:  [[ -n "$timeout" ]] && LLM_TIMEOUT_MS="$timeout"
scripts/llm-provider.sh:632:      query=$(echo "$input" | jq -r '.query // empty')
scripts/llm-provider.sh:633:      candidates=$(echo "$input" | jq -c '.candidates // []')
scripts/common.sh:8:if [ -z "${NO_COLOR:-}" ] && [ -t 2 ]; then
scripts/common.sh:29:log_info()  { echo -e "${BLUE}[${LOG_PREFIX}]${NC} $1" >&2; }
scripts/common.sh:30:log_ok()    { echo -e "${GREEN}[${LOG_PREFIX}]${NC} $1" >&2; }
scripts/common.sh:31:log_warn()  { echo -e "${YELLOW}[${LOG_PREFIX}]${NC} $1" >&2; }
scripts/common.sh:32:log_error() { echo -e "${RED}[${LOG_PREFIX}]${NC} $1" >&2; }
scripts/common.sh:39:  if command -v "$cmd" &>/dev/null; then
scripts/common.sh:57:  if [ ${#missing[@]} -gt 0 ]; then
scripts/common.sh:72:    if [ -n "$fallback_msg" ]; then
scripts/common.sh:100:  if command -v md5sum &>/dev/null; then
scripts/common.sh:101:    printf '%s' "$input" | md5sum 2>/dev/null | cut -d' ' -f1
scripts/common.sh:102:  elif command -v md5 &>/dev/null; then
scripts/common.sh:103:    if md5 -q /dev/null >/dev/null 2>&1; then
scripts/common.sh:104:      printf '%s' "$input" | md5 -q 2>/dev/null
scripts/common.sh:109:    printf '%s' "$input" | cksum 2>/dev/null | cut -d' ' -f1
scripts/common.sh:172:      echo "$input" | grep -qiE "$CODE_INTENT_PATTERN"
scripts/common.sh:181:  echo "$1" | grep -qiE "$NON_CODE_PATTERN"
scripts/common.sh:192:  if [[ -z "$input" ]] || [[ "$input" =~ ^[[:space:]]*$ ]] || [[ ! "$input" =~ [a-zA-Z] ]]; then
scripts/common.sh:203:  if echo "$lower_input" | grep -qiE "$INTENT_DEBUG_PATTERN"; then
scripts/common.sh:209:  if echo "$lower_input" | grep -qiE "$INTENT_REFACTOR_PATTERN"; then
scripts/common.sh:215:  if echo "$lower_input" | grep -qiE "$INTENT_DOCS_PATTERN"; then
scripts/common.sh:264:  if [[ ! -f "$config_file" ]]; then
scripts/common.sh:271:  IFS='.' read -ra parts <<< "$key"
scripts/common.sh:274:  if [[ $depth -eq 2 ]]; then
scripts/common.sh:280:    awk -v section="$section" -v subkey="$subkey" '
scripts/common.sh:299:  elif [[ $depth -eq 3 ]]; then
scripts/common.sh:305:    awk -v section="$section" -v subsection="$subsection" -v subkey="$subkey" '
scripts/common.sh:352:  if [[ -n "$DEVBOOKS_CONFIG_FILE" && -f "$DEVBOOKS_CONFIG_FILE" ]]; then
scripts/common.sh:355:    if [[ -n "$value" ]]; then
scripts/common.sh:364:  if [[ -n "$def_value" ]]; then
scripts/common.sh:370:  if [[ -n "$default" ]]; then
scripts/common.sh:388:  if command -v git &>/dev/null && [[ -d "$project_root/.git" ]]; then
scripts/common.sh:389:    git -C "$project_root" log --pretty=format: --name-only --since="30 days ago" 2>/dev/null | \
scripts/common.sh:390:      grep -v '^$' | \
scripts/common.sh:391:      sort | uniq -c | sort -rn | \
scripts/common.sh:396:    find "$project_root" -type f \( -name "*.ts" -o -name "*.js" -o -name "*.py" -o -name "*.go" \) \
scripts/common.sh:397:      -not -path "*/node_modules/*" -not -path "*/.git/*" \
scripts/common.sh:398:      -mtime -30 2>/dev/null | head -"$limit"
scripts/common.sh:406:if [[ -z "${DEVBOOKS_FEATURE_CONFIG:-}" ]]; then
scripts/common.sh:411:# ‰∏ÄÈîÆÂêØÁî®ÊâÄÊúâÂäüËÉΩÂºÄÂÖ≥ÔºàCLI --enable-all-features ÂèØËÆæÁΩÆÔºâ
scripts/common.sh:421:  if [[ -n "${DEVBOOKS_ENABLE_ALL_FEATURES:-}" ]]; then
scripts/common.sh:426:  if [[ ! -f "$config_file" ]]; then
scripts/common.sh:432:  value=$(awk -v feature="$feature" '
scripts/common.sh:468:  if [[ ! -f "$config_file" ]]; then
scripts/common.sh:475:  value=$(awk -v feature="$feature" '
scripts/common.sh:488:  if [[ -n "$value" ]]; then
scripts/common.sh:508:  if [[ ! -f "$config_file" ]]; then
scripts/common.sh:515:  value=$(awk -v key="$key" '
scripts/common.sh:531:  if [[ -n "$value" ]]; then
scripts/common.sh:542:  if [[ -n "${LLM_MOCK_RESPONSE:-}" ]]; then
scripts/common.sh:552:      [[ -n "${ANTHROPIC_API_KEY:-}" ]] && return 0
scripts/common.sh:555:      [[ -n "${OPENAI_API_KEY:-}" ]] && return 0
scripts/common.sh:560:      if command -v curl &>/dev/null; then
scripts/common.sh:561:        curl -s --connect-timeout 1 "$endpoint/api/tags" &>/dev/null && return 0
scripts/common.sh:582:  if [[ -z "$prompt" ]]; then
scripts/common.sh:597:  if [[ -n "${LLM_MOCK_RESPONSE:-}" ]] || [[ -n "${LLM_MOCK_DELAY_MS:-}" ]]; then
scripts/common.sh:599:    if [[ -n "${LLM_MOCK_DELAY_MS:-}" ]]; then
scripts/common.sh:602:      if [[ "$delay_ms" -gt "$timeout_ms" ]]; then
scripts/common.sh:606:      [[ "$delay_sec" -gt 0 ]] && sleep "$delay_sec" 2>/dev/null || true
scripts/common.sh:610:    if [[ -n "${LLM_MOCK_FAIL_COUNT:-}" && "${LLM_MOCK_FAIL_COUNT}" -gt 0 ]]; then
scripts/common.sh:628:  if ! command -v curl &>/dev/null; then
scripts/common.sh:652:  if [[ $exit_code -ne 0 ]]; then
scripts/common.sh:671:  request_body=$(jq -n \
scripts/common.sh:672:    --arg model "$model" \
scripts/common.sh:673:    --arg prompt "$prompt" \
scripts/common.sh:674:    --argjson max_tokens "$max_tokens" \
scripts/common.sh:683:  response=$(timeout "$timeout_sec" curl -s \
scripts/common.sh:684:    -X POST "https://api.anthropic.com/v1/messages" \
scripts/common.sh:685:    -H "Content-Type: application/json" \
scripts/common.sh:686:    -H "x-api-key: $api_key" \
scripts/common.sh:687:    -H "anthropic-version: 2023-06-01" \
scripts/common.sh:688:    -d "$request_body" 2>/dev/null)
scripts/common.sh:691:  if [[ $exit_code -eq 124 ]]; then
scripts/common.sh:696:  if command -v jq &>/dev/null; then
scripts/common.sh:697:    echo "$response" | jq -r '.content[0].text // .error.message // .' 2>/dev/null
scripts/common.sh:714:  request_body=$(jq -n \
scripts/common.sh:715:    --arg model "$model" \
scripts/common.sh:716:    --arg prompt "$prompt" \
scripts/common.sh:717:    --argjson max_tokens "$max_tokens" \
scripts/common.sh:726:  response=$(timeout "$timeout_sec" curl -s \
scripts/common.sh:727:    -X POST "https://api.openai.com/v1/chat/completions" \
scripts/common.sh:728:    -H "Content-Type: application/json" \
scripts/common.sh:729:    -H "Authorization: Bearer $api_key" \
scripts/common.sh:730:    -d "$request_body" 2>/dev/null)
scripts/common.sh:733:  if [[ $exit_code -eq 124 ]]; then
scripts/common.sh:738:  if command -v jq &>/dev/null; then
scripts/common.sh:739:    echo "$response" | jq -r '.choices[0].message.content // .error.message // .' 2>/dev/null
scripts/common.sh:754:  request_body=$(jq -n \
scripts/common.sh:755:    --arg model "$model" \
scripts/common.sh:756:    --arg prompt "$prompt" \
scripts/common.sh:765:  response=$(timeout "$timeout_sec" curl -s \
scripts/common.sh:766:    -X POST "$endpoint/api/generate" \
scripts/common.sh:767:    -H "Content-Type: application/json" \
scripts/common.sh:768:    -d "$request_body" 2>/dev/null)
scripts/common.sh:771:  if [[ $exit_code -eq 124 ]]; then
scripts/common.sh:776:  if command -v jq &>/dev/null; then
scripts/common.sh:777:    echo "$response" | jq -r '.response // .error // .' 2>/dev/null
scripts/common.sh:804:  if [[ -n "$_DEVBOOKS_ROOT" && $((now - _DEVBOOKS_CACHE_TIME)) -lt $_DEVBOOKS_CACHE_TTL ]]; then
scripts/common.sh:812:  if [[ -f "$project_root/.devbooks/config.yaml" ]]; then
scripts/common.sh:815:    root_value=$(grep -E "^root:" "$project_root/.devbooks/config.yaml" 2>/dev/null | head -1 | sed 's/^root:[[:space:]]*//' | sed 's/[[:space:]]*$//' | sed 's/#.*//')
scripts/common.sh:816:    if [[ -n "$root_value" && "$root_value" != "null" ]]; then
scripts/common.sh:828:  elif [[ -f "$project_root/dev-playbooks/project.md" ]]; then
scripts/common.sh:831:  elif [[ -f "$project_root/openspec/project.md" ]]; then
scripts/common.sh:834:  elif [[ -f "$project_root/.openspec/project.md" ]]; then
scripts/common.sh:853:  if [[ ! -f "$profile_file" ]]; then
scripts/common.sh:867:  while IFS= read -r line; do
scripts/common.sh:872:      if [[ -n "$tech_value" ]]; then
scripts/common.sh:878:          [[ -n "$item" ]] && tech_stack=$(echo "$tech_stack" | jq --arg item "$item" '. + [$item]')
scripts/common.sh:887:  if [[ "$(echo "$tech_stack" | jq -r 'length')" -eq 0 ]]; then
scripts/common.sh:889:    while IFS= read -r line; do
scripts/common.sh:900:        tech_name=$(echo "$line" | awk -F'|' '{gsub(/^[[:space:]]+|[[:space:]]+$/, "", $3); print $3}')
scripts/common.sh:901:        if [[ -n "$tech_name" && "$tech_name" != "ÊäÄÊúØ" && "$tech_name" != "-" ]]; then
scripts/common.sh:902:          tech_stack=$(echo "$tech_stack" | jq --arg item "$tech_name" '. + [$item]')
scripts/common.sh:910:  while IFS= read -r line; do
scripts/common.sh:921:      con_id=$(echo "$line" | awk -F'|' '{gsub(/^[[:space:]]+|[[:space:]]+$/, "", $2); print $2}')
scripts/common.sh:922:      con_desc=$(echo "$line" | awk -F'|' '{gsub(/^[[:space:]]+|[[:space:]]+$/, "", $3); print $3}')
scripts/common.sh:923:      if [[ -n "$con_id" && -n "$con_desc" && "$con_id" != "Á∫¶Êùü ID" ]]; then
scripts/common.sh:925:        constraints=$(echo "$constraints" | jq --arg item "$full_constraint" '. + [$item]')
scripts/common.sh:932:  while IFS= read -r line; do
scripts/common.sh:943:      cmd_raw=$(echo "$line" | awk -F'|' '{gsub(/^[[:space:]]+|[[:space:]]+$/, "", $2); print $2}')
scripts/common.sh:944:      cmd_desc=$(echo "$line" | awk -F'|' '{gsub(/^[[:space:]]+|[[:space:]]+$/, "", $3); print $3}')
scripts/common.sh:946:      cmd_name=$(echo "$cmd_raw" | tr -d '`')
scripts/common.sh:947:      if [[ -n "$cmd_name" && -n "$cmd_desc" && "$cmd_name" != "ÂëΩ‰ª§" ]]; then
scripts/common.sh:951:        [[ -n "$key_simple" ]] && key_commands=$(echo "$key_commands" | jq --arg k "$key_simple" --arg v "$cmd_name" '. + {($k): $v}')
scripts/common.sh:956:  jq -n \
scripts/common.sh:957:    --argjson tech_stack "$tech_stack" \
scripts/common.sh:958:    --argjson constraints "$constraints" \
scripts/common.sh:959:    --argjson key_commands "$key_commands" \
scripts/common.sh:974:  if [[ ! -f "$c4_file" ]]; then
scripts/common.sh:985:  while IFS= read -r line; do
scripts/common.sh:996:      if [[ -n "$item" ]]; then
scripts/common.sh:1001:        if [[ "$extracted" != "$item" && -n "$extracted" ]]; then
scripts/common.sh:1004:        architectural=$(echo "$architectural" | jq --arg item "$item" '. + [$item]')
scripts/common.sh:1009:  jq -n \
scripts/common.sh:1010:    --argjson architectural "$architectural" \
scripts/common.sh:1011:    --argjson security "$security" \
scripts/common.sh:1025:  if [[ ! -d "$changes_dir" ]]; then
scripts/common.sh:1034:    [[ -d "$change_dir" ]] || continue
scripts/common.sh:1036:    [[ -f "$proposal_file" ]] || continue
scripts/common.sh:1040:    change_status=$(grep -E "^\*\*Status\*\*:|^Status:" "$proposal_file" 2>/dev/null | head -1 | sed 's/.*:[[:space:]]*//' | sed 's/[[:space:]]*$//')
scripts/common.sh:1049:      title=$(grep -E "^#[^#]" "$proposal_file" 2>/dev/null | head -1 | sed 's/^#[[:space:]]*//')
scripts/common.sh:1052:        --arg id "$change_id" \
scripts/common.sh:1053:        --arg status "$change_status" \
scripts/common.sh:1054:        --arg title "$title" \
scripts/common.sh:1073:  if [[ -z "$devbooks_rel" ]]; then
scripts/common.sh:1076:    jq -n '{
scripts/common.sh:1098:  jq -n \
scripts/common.sh:1099:    --argjson profile "$profile" \
scripts/common.sh:1100:    --argjson constraints "$constraints" \
scripts/common.sh:1101:    --argjson active_changes "$active_changes" \
scripts/common.sh:1102:    --arg devbooks_root "$devbooks_rel" \
scripts/graph-store.sh:14:set -euo pipefail
scripts/graph-store.sh:59:    if [[ -z "$input" ]]; then
scripts/graph-store.sh:64:    if [[ ${#input} -gt $max_length ]]; then
scripts/graph-store.sh:76:    if printf '%s' "$input" | LC_ALL=C tr -d '[:print:][:space:]' | grep -q .; then
scripts/graph-store.sh:82:    if echo "$input" | grep -qiE "(DROP|DELETE|TRUNCATE|ALTER|EXEC|UNION|INSERT|UPDATE).*TABLE"; then
scripts/graph-store.sh:100:    if [[ ! -d "$db_dir" ]]; then
scripts/graph-store.sh:101:        mkdir -p "$db_dir"
scripts/graph-store.sh:114:    sqlite3 -json "$GRAPH_DB_PATH" "$sql"
scripts/graph-store.sh:122:    if [[ -n "$prefix" ]]; then
scripts/graph-store.sh:133:-- nodes Ë°®
scripts/graph-store.sh:147:-- edges Ë°®ÔºàÊâ©Â±ï AC-G01: ÊîØÊåÅ IMPLEMENTS/EXTENDS/RETURNS_TYPE/ADR_RELATEDÔºâ
scripts/graph-store.sh:164:-- MP4: transitive_closure Ë°®ÔºàÈó≠ÂåÖË°®Ôºâ
scripts/graph-store.sh:179:-- MP4: path_index Ë°®ÔºàË∑ØÂæÑÁ¥¢ÂºïÔºâ
scripts/graph-store.sh:196:-- MP7: user_signals Ë°®Ôºà‰∏ä‰∏ãÊñá‰ø°Âè∑Ôºâ
scripts/graph-store.sh:208:-- virtual_edges Ë°®ÔºàMP5: ËÅîÈÇ¶ËôöÊãüËæπÔºâ
scripts/graph-store.sh:209:-- Trace: AC-F05
scripts/graph-store.sh:233:-- ÁâàÊú¨Ë°®
scripts/graph-store.sh:239:-- ÂÖÉÊï∞ÊçÆË°®ÔºàÁî®‰∫éÂ≠òÂÇ®ÈÖçÁΩÆÂíåÁâàÊú¨Êà≥Ôºâ
scripts/graph-store.sh:246:-- MP2: Schema v3 Êñ∞Â¢ûÁ¥¢Âºï (AC-U03)
scripts/graph-store.sh:259:    if [[ ! -f "$db_path" ]]; then
scripts/graph-store.sh:267:    [[ "$has_tc" -gt 0 && "$has_pi" -gt 0 ]]
scripts/graph-store.sh:356:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh:358:            --skip-precompute) skip_precompute=true; shift ;;
scripts/graph-store.sh:365:    if [[ -f "$GRAPH_DB_PATH" ]]; then
scripts/graph-store.sh:397:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh:399:            --id) id="$2"; shift 2 ;;
scripts/graph-store.sh:400:            --symbol) symbol="$2"; shift 2 ;;
scripts/graph-store.sh:401:            --kind) kind="$2"; shift 2 ;;
scripts/graph-store.sh:402:            --file) file_path="$2"; shift 2 ;;
scripts/graph-store.sh:403:            --line-start) line_start="$2"; shift 2 ;;
scripts/graph-store.sh:404:            --line-end) line_end="$2"; shift 2 ;;
scripts/graph-store.sh:410:    if [[ -z "$id" || -z "$symbol" || -z "$kind" || -z "$file_path" ]]; then
scripts/graph-store.sh:411:        log_error "Missing required fields: --id, --symbol, --kind, --file"
scripts/graph-store.sh:424:    [[ -n "$line_start" ]] && line_start_sql="$line_start"
scripts/graph-store.sh:425:    [[ -n "$line_end" ]] && line_end_sql="$line_end"
scripts/graph-store.sh:443:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh:445:            --source) source_id="$2"; shift 2 ;;
scripts/graph-store.sh:446:            --target) target_id="$2"; shift 2 ;;
scripts/graph-store.sh:447:            --type) edge_type="$2"; shift 2 ;;
scripts/graph-store.sh:448:            --file) file_path="$2"; shift 2 ;;
scripts/graph-store.sh:449:            --line) line="$2"; shift 2 ;;
scripts/graph-store.sh:455:    if [[ -z "$source_id" || -z "$target_id" || -z "$edge_type" ]]; then
scripts/graph-store.sh:456:        log_error "Missing required fields: --source, --target, --type"
scripts/graph-store.sh:478:    [[ -n "$file_path" ]] && file_sql="'$(escape_sql_string "$file_path")'"
scripts/graph-store.sh:479:    [[ -n "$line" ]] && line_sql="$line"
scripts/graph-store.sh:498:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh:500:            --from) from_node="$2"; shift 2 ;;
scripts/graph-store.sh:501:            --to) to_node="$2"; shift 2 ;;
scripts/graph-store.sh:502:            --type) edge_type="$2"; shift 2 ;;
scripts/graph-store.sh:503:            --direction) direction="$2"; shift 2 ;;
scripts/graph-store.sh:510:    if [[ -n "$from_node" ]]; then
scripts/graph-store.sh:514:    if [[ -n "$to_node" ]]; then
scripts/graph-store.sh:518:    if [[ -n "$edge_type" ]]; then
scripts/graph-store.sh:523:    if [[ ${#where_clauses[@]} -gt 0 ]]; then
scripts/graph-store.sh:542:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh:544:            --exclude) exclude_pattern="$2"; shift 2 ;;
scripts/graph-store.sh:551:    if [[ -n "$exclude_pattern" ]]; then
scripts/graph-store.sh:573:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh:575:            --file) input_file="$2"; shift 2 ;;
scripts/graph-store.sh:576:            --skip-precompute) skip_precompute=true; shift ;;
scripts/graph-store.sh:581:    if [[ -z "$input_file" || ! -f "$input_file" ]]; then
scripts/graph-store.sh:598:    if jq -e '.nodes | length > 0' "$input_file" >/dev/null 2>&1; then
scripts/graph-store.sh:599:        while IFS=$'\t' read -r id symbol kind file_path line_start line_end; do
scripts/graph-store.sh:601:            if [[ -z "$id" || "$id" == "null" || "$id" == "NULL" \
scripts/graph-store.sh:602:                || -z "$symbol" || "$symbol" == "null" || "$symbol" == "NULL" \
scripts/graph-store.sh:603:                || -z "$kind" || "$kind" == "null" || "$kind" == "NULL" \
scripts/graph-store.sh:604:                || -z "$file_path" || "$file_path" == "null" || "$file_path" == "NULL" ]]; then
scripts/graph-store.sh:610:            [[ "$line_start" == "null" || "$line_start" == "NULL" || -z "$line_start" ]] && line_start="NULL"
scripts/graph-store.sh:611:            [[ "$line_end" == "null" || "$line_end" == "NULL" || -z "$line_end" ]] && line_end="NULL"
scripts/graph-store.sh:614:        done < <(jq -r '.nodes[] | [.id, .symbol, .kind, .file_path, (.line_start // "NULL"), (.line_end // "NULL")] | @tsv' "$input_file")
scripts/graph-store.sh:618:    if jq -e '.edges | length > 0' "$input_file" >/dev/null 2>&1; then
scripts/graph-store.sh:619:        while IFS=$'\t' read -r source_id target_id edge_type file_path line; do
scripts/graph-store.sh:631:            [[ "$file_path" == "null" || "$file_path" == "NULL" || -z "$file_path" ]] && file_path="NULL" || file_path="'$(echo "$file_path" | sed "s/'/''/g")'"
scripts/graph-store.sh:632:            [[ "$line" == "null" || "$line" == "NULL" || -z "$line" ]] && line="NULL"
scripts/graph-store.sh:636:        done < <(jq -r '.edges[] | [.source_id, .target_id, .edge_type, (.file_path // "NULL"), (.line // "NULL")] | @tsv' "$input_file")
scripts/graph-store.sh:688:    if [[ -z "$sql" ]]; then
scripts/graph-store.sh:701:    if [[ -z "$node_id" ]]; then
scripts/graph-store.sh:716:    if [[ -z "$node_id" ]]; then
scripts/graph-store.sh:735:    if [[ -z "$edge_id" ]]; then
scripts/graph-store.sh:754:    if [[ ! -f "$db_path" ]]; then
scripts/graph-store.sh:778:    if [[ ! -f "$db_path" ]]; then
scripts/graph-store.sh:786:    if [[ -z "$create_sql" ]]; then
scripts/graph-store.sh:804:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh:806:            --check) check_only=true; shift ;;
scripts/graph-store.sh:807:            --apply) apply=true; shift ;;
scripts/graph-store.sh:808:            --status) status_only=true; shift ;;
scripts/graph-store.sh:809:            --skip-precompute) skip_precompute=true; shift ;;
scripts/graph-store.sh:828:        if ! flock -n 200; then
scripts/graph-store.sh:835:        trap "flock -u 200; rm -f '$lock_file'" EXIT
scripts/graph-store.sh:838:    if [[ ! -f "$GRAPH_DB_PATH" ]]; then
scripts/graph-store.sh:869:        if [[ "$needs_migration" == "true" ]] || [[ "$current_version" -lt "$CURRENT_SCHEMA_VERSION" ]]; then
scripts/graph-store.sh:897:        if [[ "$needs_migration" == "true" ]] || [[ "$current_version" -lt "$CURRENT_SCHEMA_VERSION" ]]; then
scripts/graph-store.sh:915:        [[ -f "${GRAPH_DB_PATH}-wal" ]] && cp "${GRAPH_DB_PATH}-wal" "${backup_path}-wal"
scripts/graph-store.sh:916:        [[ -f "${GRAPH_DB_PATH}-shm" ]] && cp "${GRAPH_DB_PATH}-shm" "${backup_path}-shm"
scripts/graph-store.sh:919:        if [[ "$needs_migration" != "true" ]] && [[ "$current_version" -ge "$CURRENT_SCHEMA_VERSION" ]]; then
scripts/graph-store.sh:928:-- MP2.5: ÂêØÁî®Â§ñÈîÆÁ∫¶ÊùüÊ£ÄÊü• (AC-U11)
scripts/graph-store.sh:933:-- 1. ÂØºÂá∫Áé∞ÊúâÊï∞ÊçÆ
scripts/graph-store.sh:937:-- 2. Âà†Èô§ÊóßË°®ÔºàÁ∫ßËÅîÂà†Èô§Á¥¢ÂºïÔºâ
scripts/graph-store.sh:941:-- 3. ÂàõÂª∫Êñ∞ nodes Ë°®
scripts/graph-store.sh:955:-- 4. ÂàõÂª∫Êñ∞ edges Ë°®ÔºàÂ∏¶Êâ©Â±ï CHECK Á∫¶ÊùüÔºâ
scripts/graph-store.sh:972:-- MP2: Êñ∞Â¢û‰∏ìÁî®Á¥¢Âºï (AC-U03)
scripts/graph-store.sh:977:-- MP4: Êñ∞Â¢ûÈó≠ÂåÖË°®‰∏éË∑ØÂæÑÁ¥¢Âºï
scripts/graph-store.sh:1008:-- MP7: user_signals Ë°®
scripts/graph-store.sh:1020:-- 5. ÊÅ¢Â§çÊï∞ÊçÆÔºàÂ§ÑÁêÜ v2 Âà∞ v3 ÁöÑÂàóÊò†Â∞ÑÔºâ
scripts/graph-store.sh:1021:-- v2 nodes: (id, type, name, file_path, metadata)
scripts/graph-store.sh:1022:-- v3 nodes: (id, symbol, kind, file_path, line_start, line_end, created_at)
scripts/graph-store.sh:1026:    name as symbol,  -- v2 ÁöÑ name Êò†Â∞ÑÂà∞ v3 ÁöÑ symbol
scripts/graph-store.sh:1027:    type as kind,    -- v2 ÁöÑ type Êò†Â∞ÑÂà∞ v3 ÁöÑ kind
scripts/graph-store.sh:1033:-- v2 edges: (id, source_id, target_id, edge_type, metadata)
scripts/graph-store.sh:1034:-- v3 edges: (id, source_id, target_id, edge_type, file_path, line, created_at)
scripts/graph-store.sh:1037:    hex(randomblob(16)) as id,  -- v2 ‰ΩøÁî® INTEGER AUTOINCREMENTÔºåv3 ‰ΩøÁî® TEXTÔºåÈúÄË¶ÅÈáçÊñ∞ÁîüÊàê
scripts/graph-store.sh:1045:-- 6. Êõ¥Êñ∞ÁâàÊú¨
scripts/graph-store.sh:1048:-- 7. Ê∏ÖÁêÜ‰∏¥Êó∂Ë°®
scripts/graph-store.sh:1068:                [[ -f "${backup_path}-wal" ]] && cp "${backup_path}-wal" "${GRAPH_DB_PATH}-wal"
scripts/graph-store.sh:1069:                [[ -f "${backup_path}-shm" ]] && cp "${backup_path}-shm" "${GRAPH_DB_PATH}-shm"
scripts/graph-store.sh:1083:                [[ -f "${backup_path}-wal" ]] && cp "${backup_path}-wal" "${GRAPH_DB_PATH}-wal"
scripts/graph-store.sh:1084:                [[ -f "${backup_path}-shm" ]] && cp "${backup_path}-shm" "${GRAPH_DB_PATH}-shm"
scripts/graph-store.sh:1092:            if [[ -n "$fk_violations" ]]; then
scripts/graph-store.sh:1096:                [[ -f "${backup_path}-wal" ]] && cp "${backup_path}-wal" "${GRAPH_DB_PATH}-wal"
scripts/graph-store.sh:1097:                [[ -f "${backup_path}-shm" ]] && cp "${backup_path}-shm" "${GRAPH_DB_PATH}-shm"
scripts/graph-store.sh:1109:                [[ -f "${backup_path}-wal" ]] && cp "${backup_path}-wal" "${GRAPH_DB_PATH}-wal"
scripts/graph-store.sh:1110:                [[ -f "${backup_path}-shm" ]] && cp "${backup_path}-shm" "${GRAPH_DB_PATH}-shm"
scripts/graph-store.sh:1124:            [[ -f "${backup_path}-wal" ]] && cp "${backup_path}-wal" "${GRAPH_DB_PATH}-wal"
scripts/graph-store.sh:1125:            [[ -f "${backup_path}-shm" ]] && cp "${backup_path}-shm" "${GRAPH_DB_PATH}-shm"
scripts/graph-store.sh:1137:    while [[ $# -gt 0 ]]; do
scripts/graph-store.sh:1139:            --from) from_node="$2"; shift 2 ;;
scripts/graph-store.sh:1140:            --to) to_node="$2"; shift 2 ;;
scripts/graph-store.sh:1141:            --max-depth) max_depth="$2"; shift 2 ;;
scripts/graph-store.sh:1142:            --edge-types) edge_types="$2"; shift 2 ;;
scripts/graph-store.sh:1148:    if [[ -z "$from_node" || -z "$to_node" ]]; then
scripts/graph-store.sh:1149:        log_error "Missing required fields: --from, --to"
scripts/graph-store.sh:1154:    if [[ "$max_depth" -lt 1 || "$max_depth" -gt 10 ]]; then
scripts/graph-store.sh:1160:    if [[ ! -f "$GRAPH_DB_PATH" ]]; then
scripts/graph-store.sh:1171:    if [[ -n "$edge_types" ]]; then
scripts/graph-store.sh:1179:    if [[ -z "$edge_types" ]] && closure_tables_exist "$GRAPH_DB_PATH"; then
scripts/graph-store.sh:1182:        if [[ "$closure_count" -gt 0 ]]; then
scripts/graph-store.sh:1186:            if [[ -z "$closure_depth" ]]; then
scripts/graph-store.sh:1192:            path_row=$(sqlite3 -separator $'\t' "$GRAPH_DB_PATH" "SELECT path, edge_path, depth FROM path_index WHERE source_id='$from_sql' AND target_id='$to_sql' AND depth <= $max_depth LIMIT 1;" 2>/dev/null || true)
scripts/graph-store.sh:1193:            if [[ -n "$path_row" ]]; then
scripts/graph-store.sh:1195:                IFS=$'\t' read -r path_json edge_json depth_val <<< "$path_row"
scripts/graph-store.sh:1196:                [[ -z "$edge_json" ]] && edge_json="[]"
scripts/graph-store.sh:1197:                [[ -z "$depth_val" ]] && depth_val="$closure_depth"
scripts/graph-store.sh:1234:    result=$(sqlite3 -separator $'\t' "$GRAPH_DB_PATH" "$path_sql" 2>/dev/null)
scripts/graph-store.sh:1236:    if [[ -z "$result" ]]; then
scripts/graph-store.sh:1242:    IFS=$'\t' read -r node_id path_str depth <<< "$result"
scripts/graph-store.sh:1245:    path_json=$(printf '%s\n' "$path_str" | tr '>' '\n' | jq -R '.' | jq -s '.')
scripts/graph-store.sh:1249:    IFS='>' read -r -a node_list <<< "$path_str"
scripts/graph-store.sh:1250:    if [ "${#node_list[@]}" -gt 1 ]; then
scripts/graph-store.sh:1257:            edges_json=$(echo "$edges_json" | jq --arg from "$from_id" --arg to "$to_id" --arg type "$edge_type" \
scripts/graph-store.sh:1273:    graph-store.sh --enable-all-features <command> [options]
scripts/graph-store.sh:1291:    --id <id>               ËäÇÁÇπ IDÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh:1292:    --symbol <symbol>       Á¨¶Âè∑ÂêçÁß∞ÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh:1293:    --kind <kind>           ËäÇÁÇπÁ±ªÂûãÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh:1294:    --file <path>           Êñá‰ª∂Ë∑ØÂæÑÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh:1295:    --line-start <n>        Ëµ∑ÂßãË°åÂè∑
scripts/graph-store.sh:1296:    --line-end <n>          ÁªìÊùüË°åÂè∑
scripts/graph-store.sh:1299:    --source <id>           Ê∫êËäÇÁÇπ IDÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh:1300:    --target <id>           ÁõÆÊ†áËäÇÁÇπ IDÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh:1301:    --type <type>           ËæπÁ±ªÂûãÔºàÂøÖÂ°´Ôºâ: DEFINES, IMPORTS, CALLS, MODIFIES, REFERENCES,
scripts/graph-store.sh:1303:    --file <path>           Êñá‰ª∂Ë∑ØÂæÑ
scripts/graph-store.sh:1304:    --line <n>              Ë°åÂè∑
scripts/graph-store.sh:1307:    --skip-precompute       Ë∑≥ËøáÈó≠ÂåÖË°®È¢ÑËÆ°ÁÆó
scripts/graph-store.sh:1310:    --from <id>             Ê∫êËäÇÁÇπ ID
scripts/graph-store.sh:1311:    --to <id>               ÁõÆÊ†áËäÇÁÇπ ID
scripts/graph-store.sh:1312:    --type <type>           ËæπÁ±ªÂûã
scripts/graph-store.sh:1315:    --exclude <pattern>     ÊéíÈô§Ê®°ÂºèÔºàglobÔºâ
scripts/graph-store.sh:1318:    --file <path>           JSON Êñá‰ª∂Ë∑ØÂæÑ
scripts/graph-store.sh:1319:    --skip-precompute       Ë∑≥ËøáÈó≠ÂåÖË°®È¢ÑËÆ°ÁÆó
scripts/graph-store.sh:1322:    --from <id>             Ê∫êËäÇÁÇπ IDÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh:1323:    --to <id>               ÁõÆÊ†áËäÇÁÇπ IDÔºàÂøÖÂ°´Ôºâ
scripts/graph-store.sh:1324:    --max-depth <n>         ÊúÄÂ§ßÊêúÁ¥¢Ê∑±Â∫¶ÔºàÈªòËÆ§: 10Ôºâ
scripts/graph-store.sh:1325:    --edge-types <types>    ÈÄóÂè∑ÂàÜÈöîÁöÑËæπÁ±ªÂûãËøáÊª§
scripts/graph-store.sh:1328:    --check                 Ê£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅËøÅÁßª
scripts/graph-store.sh:1329:    --apply                 ÊâßË°åËøÅÁßªÔºàËá™Âä®Â§á‰ªΩÔºâ
scripts/graph-store.sh:1330:    --status                ÊòæÁ§∫ÂΩìÂâçÁä∂ÊÄÅ
scripts/graph-store.sh:1331:    --skip-precompute       Ë∑≥ËøáÈó≠ÂåÖË°®È¢ÑËÆ°ÁÆó
scripts/graph-store.sh:1342:    graph-store.sh add-node --id "sym:func:main" --symbol "main" --kind "function" --file "src/index.ts"
scripts/graph-store.sh:1345:    graph-store.sh add-edge --source "sym:func:main" --target "sym:func:helper" --type CALLS
scripts/graph-store.sh:1348:    graph-store.sh query-edges --from "sym:func:main" --type CALLS
scripts/graph-store.sh:1366:    if declare -f is_feature_enabled &>/dev/null; then
scripts/dependency-guard-report.sh:17:    git diff --cached --name-only --diff-filter=ACMR 2>/dev/null | grep -E '\.(ts|tsx|js|jsx|sh)$' || true
scripts/dependency-guard-report.sh:28:    echo "$imports" | jq -r '.[].target' 2>/dev/null | while read -r target; do
scripts/dependency-guard-report.sh:31:        if [[ -n "$resolved" && -f "$resolved" ]]; then
scripts/dependency-guard-report.sh:56:    on_violation=$(echo "$config" | jq -r '.on_violation // "warn"')
scripts/dependency-guard-report.sh:58:    if [[ "$on_violation" == "block" && ($total_violations -gt 0 || $total_cycles -gt 0) ]]; then
scripts/dependency-guard-report.sh:70:        if [[ $total_violations -gt 0 ]]; then
scripts/dependency-guard-report.sh:71:            echo "--- Violations ---"
scripts/dependency-guard-report.sh:72:            echo "$violations" | jq -r '.[] | "[\(.severity)] \(.source):\(.line) - \(.message)"'
scripts/dependency-guard-report.sh:76:        if [[ $total_cycles -gt 0 ]]; then
scripts/dependency-guard-report.sh:77:            echo "--- Cycles ---"
scripts/dependency-guard-report.sh:78:            echo "$cycles" | jq -r '.[] | "Cycle: \(.path | join(" -> "))"'
scripts/dependency-guard-report.sh:81:        jq -n \
scripts/dependency-guard-report.sh:82:            --arg schema_version "$REPORT_SCHEMA_VERSION" \
scripts/dependency-guard-report.sh:83:            --argjson violations "$violations" \
scripts/dependency-guard-report.sh:84:            --argjson cycles "$cycles" \
scripts/dependency-guard-report.sh:85:            --argjson total_violations "$total_violations" \
scripts/dependency-guard-report.sh:86:            --argjson total_cycles "$total_cycles" \
scripts/dependency-guard-report.sh:87:            --argjson blocked "$blocked" \
scripts/dependency-guard-report.sh:88:            --argjson files_checked "$files_checked" \
scripts/federation-lite.sh:9:#   federation-lite.sh --status
scripts/federation-lite.sh:10:#   federation-lite.sh --update [--config config/federation.yaml]
scripts/federation-lite.sh:11:#   federation-lite.sh --search "<symbol>" [--format json]
scripts/federation-lite.sh:12:#   federation-lite.sh --list-contracts [--repo "<name>"]
scripts/federation-lite.sh:13:#   federation-lite.sh --help
scripts/federation-lite.sh:23:set -euo pipefail
scripts/federation-lite.sh:37:  while [[ $# -gt 0 ]]; do
scripts/federation-lite.sh:39:      --local-repo) _fast_local_repo="$2"; shift 2 ;;
scripts/federation-lite.sh:40:      --db) _fast_db_path="$2"; shift 2 ;;
scripts/federation-lite.sh:41:      --min-confidence) _fast_min_confidence="$2"; shift 2 ;;
scripts/federation-lite.sh:42:      --config) _fast_config="$2"; shift 2 ;;
scripts/federation-lite.sh:43:      --sync) _fast_sync_mode="true"; shift ;;
scripts/federation-lite.sh:50:  [[ -z "$_fast_db_path" ]] && _fast_db_path="$_fast_local_repo/.devbooks/graph.db"
scripts/federation-lite.sh:51:  [[ -z "$_fast_index" ]] && _fast_index="${FEDERATION_INDEX:-$_fast_local_repo/.devbooks/federation-index.json}"
scripts/federation-lite.sh:54:  if [[ ! -f "$_fast_index" ]]; then
scripts/federation-lite.sh:60:  mkdir -p "$(dirname "$_fast_db_path")" 2>/dev/null || true
scripts/federation-lite.sh:84:  _fast_symbols=$(grep -rhoE '(export\s+)?(async\s+)?function\s+[A-Za-z_][A-Za-z0-9_]*' "$_fast_local_repo" \
scripts/federation-lite.sh:85:    --include="*.ts" --include="*.tsx" --include="*.js" --include="*.jsx" 2>/dev/null | \
scripts/federation-lite.sh:86:    grep -oE '[A-Za-z_][A-Za-z0-9_]*$' | sort -u | jq -R -s 'split("\n") | map(select(length > 0))' 2>/dev/null || echo '[]')
scripts/federation-lite.sh:90:  _fast_result=$(jq -c \
scripts/federation-lite.sh:91:    --argjson local_symbols "$_fast_symbols" \
scripts/federation-lite.sh:92:    --arg local_repo "$_fast_local_repo_name" \
scripts/federation-lite.sh:93:    --argjson min_conf "$_fast_min_confidence" \
scripts/federation-lite.sh:176:  if [[ "$_fast_edge_count" -gt 0 ]]; then
scripts/federation-lite.sh:177:    _fast_sql=$(echo "$_fast_result" | jq -r '
scripts/federation-lite.sh:198:  jq -n --argjson created "$_fast_edge_count" --argjson total "$_fast_total" --arg db "$_fast_db_path" \
scripts/federation-lite.sh:207:if [[ -f "$SCRIPT_DIR/common.sh" ]]; then
scripts/federation-lite.sh:239:    if [[ $# -gt 0 ]] && [[ "$1" != -* ]]; then
scripts/federation-lite.sh:247:                if [[ $# -gt 1 ]] && [[ "$2" != -* ]]; then
scripts/federation-lite.sh:257:    while [[ $# -gt 0 ]]; do
scripts/federation-lite.sh:259:            --status)
scripts/federation-lite.sh:263:            --update)
scripts/federation-lite.sh:267:            --search)
scripts/federation-lite.sh:272:            --list-contracts)
scripts/federation-lite.sh:276:            --config)
scripts/federation-lite.sh:280:            --repo)
scripts/federation-lite.sh:284:            --format)
scripts/federation-lite.sh:288:            --debug)
scripts/federation-lite.sh:292:            --local-repo)
scripts/federation-lite.sh:296:            --db)
scripts/federation-lite.sh:300:            --min-confidence)
scripts/federation-lite.sh:304:            --confidence)
scripts/federation-lite.sh:308:            --sync)
scripts/federation-lite.sh:312:            --virtual-edges)
scripts/federation-lite.sh:316:            --help|-h)
scripts/federation-lite.sh:327:    if ! command -v jq &>/dev/null; then
scripts/federation-lite.sh:340:            if [[ -z "$query" ]]; then
scripts/federation-lite.sh:341:                log_error "Usage: federation-lite.sh --search <symbol>"
scripts/federation-lite.sh:353:            if [[ -z "$query" ]]; then
scripts/dependency-guard-check.sh:21:    while IFS= read -r -d '' file; do
scripts/dependency-guard-check.sh:23:    done < <(find "$scope" -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" -o -name "*.sh" \) -print0 2>/dev/null)
scripts/dependency-guard-check.sh:32:        echo "$imports" | jq -c '.[]' 2>/dev/null | while read -r imp; do
scripts/dependency-guard-check.sh:34:            target=$(echo "$imp" | jq -r '.target')
scripts/dependency-guard-check.sh:38:            if [[ -n "$resolved" && -f "$resolved" ]]; then
scripts/dependency-guard-check.sh:39:                edges=$(echo "$edges" | jq --arg target "$resolved" '. + [$target]')
scripts/dependency-guard-check.sh:43:        graph=$(echo "$graph" | jq --arg file "$file" --argjson deps "$(echo "$imports" | jq '[.[] | .target]')" \
scripts/dependency-guard-check.sh:60:    while IFS= read -r file; do
scripts/dependency-guard-check.sh:63:        if [[ -n "$whitelist" ]]; then
scripts/dependency-guard-check.sh:64:            echo "$whitelist" | tr ',' '\n' | while read -r pattern; do
scripts/dependency-guard-check.sh:73:    done < <(find "$scope" -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \) 2>/dev/null)
scripts/dependency-guard-check.sh:76:    declare -A adj_list
scripts/dependency-guard-check.sh:77:    declare -A file_imports
scripts/dependency-guard-check.sh:84:        echo "$imports" | jq -c '.[]' 2>/dev/null | while read -r imp; do
scripts/dependency-guard-check.sh:86:            target=$(echo "$imp" | jq -r '.target')
scripts/dependency-guard-check.sh:90:            if [[ -n "$resolved" && -f "$resolved" ]]; then
scripts/dependency-guard-check.sh:99:    declare -A color  # 0=WHITE, 1=GRAY, 2=BLACK
scripts/dependency-guard-check.sh:113:            if [[ "${color[$dep]:-0}" -eq 1 ]]; then
scripts/dependency-guard-check.sh:116:                cycle_start=$(echo "$new_path" | tr ':' '\n' | grep -n "^${dep}$" | cut -d: -f1 | head -1)
scripts/dependency-guard-check.sh:117:                if [[ -n "$cycle_start" ]]; then
scripts/dependency-guard-check.sh:119:                    cycle_path=$(echo "$new_path" | tr ':' '\n' | tail -n "+$cycle_start")
scripts/dependency-guard-check.sh:122:                    cycles=$(echo "$cycles" | jq --arg path "$cycle_path" '. + [{"path": ($path | split("\n")), "severity": "error"}]')
scripts/dependency-guard-check.sh:124:            elif [[ "${color[$dep]:-0}" -eq 0 ]]; then
scripts/dependency-guard-check.sh:133:        if [[ "${color[$file]:-0}" -eq 0 ]]; then
scripts/dependency-guard-check.sh:150:        [[ -f "$file" ]] || continue
scripts/dependency-guard-check.sh:163:        while IFS= read -r imp; do
scripts/dependency-guard-check.sh:165:            target=$(echo "$imp" | jq -r '.target')
scripts/dependency-guard-check.sh:168:            [[ -z "$resolved" ]] && continue
scripts/dependency-guard-check.sh:180:        done < <(echo "$imports" | jq -c '.[]' 2>/dev/null)
scripts/dependency-guard-check.sh:189:    if command -v python3 &>/dev/null; then
scripts/dependency-guard-check.sh:191:    elif command -v python &>/dev/null; then
scripts/dependency-guard-check.sh:195:    if [[ -n "$python_bin" ]]; then
scripts/dependency-guard-check.sh:254:    while IFS= read -r edge1; do
scripts/dependency-guard-check.sh:255:        [[ -z "$edge1" ]] && continue
scripts/dependency-guard-check.sh:260:        if grep -qF "${dst1} -> ${src1}" "$input_edges" 2>/dev/null; then
scripts/dependency-guard-check.sh:261:            cycles=$(echo "$cycles" | jq --arg src "$src1" --arg dst "$dst1" \
scripts/dependency-guard-check.sh:277:    temp_dir=$(mktemp -d)
scripts/dependency-guard-check.sh:282:    while IFS= read -r -d '' file; do
scripts/dependency-guard-check.sh:284:    done < <(find "$scope" -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \) -print0 2>/dev/null)
scripts/dependency-guard-check.sh:286:    if [[ ${#files[@]} -gt 0 ]]; then
scripts/dependency-guard-check.sh:292:    rm -rf "$temp_dir"
scripts/dependency-guard-check.sh:304:    temp_dir=$(mktemp -d)
scripts/dependency-guard-check.sh:308:    if [[ ${#files[@]} -gt 0 ]]; then
scripts/dependency-guard-check.sh:314:    rm -rf "$temp_dir"
scripts/complexity.sh:6:set -euo pipefail
scripts/complexity.sh:18:  command -v radon &>/dev/null || missing+=("radon (pip install radon)")
scripts/complexity.sh:19:  command -v scc &>/dev/null || missing+=("scc (brew install scc)")
scripts/complexity.sh:20:  command -v gocyclo &>/dev/null || missing+=("gocyclo (go install github.com/fzipp/gocyclo/cmd/gocyclo@latest)")
scripts/complexity.sh:22:  if [ ${#missing[@]} -eq 3 ]; then
scripts/complexity.sh:37:  if command -v gtimeout &>/dev/null; then
scripts/complexity.sh:39:  elif command -v timeout &>/dev/null; then
scripts/complexity.sh:52:  if ! command -v radon &>/dev/null; then
scripts/complexity.sh:59:  result=$(run_with_timeout "$TIMEOUT_SEC" radon cc "$file" -s 2>/dev/null | \
scripts/complexity.sh:60:    sed -n 's/.*(\([0-9]*\))$/\1/p' | \
scripts/complexity.sh:61:    sort -rn | head -1)
scripts/complexity.sh:63:  if [ -n "$result" ] && [ "$result" -gt 0 ]; then
scripts/complexity.sh:74:  if ! command -v scc &>/dev/null; then
scripts/complexity.sh:80:  result=$(run_with_timeout "$TIMEOUT_SEC" scc --format json "$file" 2>/dev/null | \
scripts/complexity.sh:81:    jq -r '.[0].Complexity // empty' 2>/dev/null)
scripts/complexity.sh:83:  if [ -n "$result" ] && [ "$result" -gt 0 ]; then
scripts/complexity.sh:94:  if ! command -v gocyclo &>/dev/null; then
scripts/complexity.sh:102:    awk '{print $1}' | sort -rn | head -1)
scripts/complexity.sh:104:  if [ -n "$result" ] && [ "$result" -gt 0 ]; then
scripts/complexity.sh:119:  if [ ! -f "$file" ]; then
scripts/complexity.sh:152:  if [ -n "$complexity" ] && [ "$complexity" -gt 0 ]; then
scripts/complexity.sh:164:  if [ -z "$file" ]; then
scripts/pattern-learner.sh:18:set -euo pipefail
scripts/pattern-learner.sh:31:  while [[ $# -gt 0 ]]; do
scripts/pattern-learner.sh:33:      --patterns-file|--patterns) _fast_patterns_file="$2"; shift 2 ;;
scripts/pattern-learner.sh:34:      --eliminate-threshold) _fast_elimination_threshold="$2"; shift 2 ;;
scripts/pattern-learner.sh:35:      --cwd) _fast_cwd="$2"; shift 2 ;;
scripts/pattern-learner.sh:36:      --format) _fast_format="$2"; shift 2 ;;
scripts/pattern-learner.sh:37:      --daily) shift ;;  # ÂøΩÁï•Ôºå‰øùÊåÅÂÖºÂÆπ
scripts/pattern-learner.sh:46:  if [[ ! -f "$_fast_patterns_file" ]]; then
scripts/pattern-learner.sh:53:  if [[ -n "${PATTERN_DECAY_MOCK_DATE:-}" ]]; then
scripts/pattern-learner.sh:54:    _mock_arg=$(echo '{}' | jq --arg d "$PATTERN_DECAY_MOCK_DATE" '($d | fromdateiso8601 / 86400 | floor)')
scripts/pattern-learner.sh:58:  _result=$(jq -c \
scripts/pattern-learner.sh:59:    --argjson t "$_fast_elimination_threshold" \
scripts/pattern-learner.sh:60:    --argjson mock_today "$_mock_arg" \
scripts/pattern-learner.sh:97:if [ -f "$COMMON_LIB" ]; then
scripts/pattern-learner.sh:108:  log_info()  { echo -e "${BLUE}[PatternLearner]${NC} $1" >&2; }
scripts/pattern-learner.sh:109:  log_ok()    { echo -e "${GREEN}[PatternLearner]${NC} $1" >&2; }
scripts/pattern-learner.sh:110:  log_warn()  { echo -e "${YELLOW}[PatternLearner]${NC} $1" >&2; }
scripts/pattern-learner.sh:111:  log_error() { echo -e "${RED}[PatternLearner]${NC} $1" >&2; }
scripts/pattern-learner.sh:115:if declare -f check_dependencies &>/dev/null; then
scripts/pattern-learner.sh:118:  command -v jq &>/dev/null || { log_error "Áº∫Â∞ë‰æùËµñ: jq"; exit 2; }
scripts/pattern-learner.sh:124:if declare -f is_feature_enabled &>/dev/null; then
scripts/pattern-learner.sh:163:  pattern-learner.sh --learn [ÈÄâÈ°π]  Á≠âÂêå‰∫é learn
scripts/pattern-learner.sh:164:  pattern-learner.sh --detect [ÈÄâÈ°π] Á≠âÂêå‰∫é detect
scripts/pattern-learner.sh:167:  --confidence-threshold <n>  ÁΩÆ‰ø°Â∫¶ÈòàÂÄº 0.0-1.0ÔºàÈªòËÆ§: 0.85Ôºâ
scripts/pattern-learner.sh:168:  --patterns-file <path>      Ê®°ÂºèÊñá‰ª∂Ë∑ØÂæÑÔºàÈªòËÆ§: .devbooks/learned-patterns.jsonÔºâ
scripts/pattern-learner.sh:169:  --output <path>             ËæìÂá∫Êñá‰ª∂Ë∑ØÂæÑÔºàÂèØÈÄâÔºåÈªòËÆ§‰ΩøÁî® patterns-fileÔºâ
scripts/pattern-learner.sh:170:  --cwd <path>                Â∑•‰ΩúÁõÆÂΩïÔºàÈªòËÆ§: ÂΩìÂâçÁõÆÂΩïÔºâ
scripts/pattern-learner.sh:171:  --format <text|json>        ËæìÂá∫Ê†ºÂºèÔºàÈªòËÆ§: jsonÔºâ
scripts/pattern-learner.sh:172:  --decay-factor <n>          Ë°∞ÂáèÂõ†Â≠ê 0.0-1.0ÔºàÈªòËÆ§: 0.9Ôºâ
scripts/pattern-learner.sh:173:  --version                   ÊòæÁ§∫ÁâàÊú¨
scripts/pattern-learner.sh:174:  --help                      ÊòæÁ§∫Ê≠§Â∏ÆÂä©
scripts/pattern-learner.sh:177:  --auto-discover             ÂêØÁî®Ëá™Âä®Ê®°ÂºèÂèëÁé∞ÔºàÂü∫‰∫éÂëΩÂêçÁ∫¶ÂÆöÔºâ
scripts/pattern-learner.sh:178:  --min-frequency <n>         ÊúÄÂ∞èÂá∫Áé∞È¢ëÁéáÈòàÂÄºÔºàÈªòËÆ§: 3Ôºâ
scripts/pattern-learner.sh:179:  --project <path>            È°πÁõÆÁõÆÂΩïË∑ØÂæÑ
scripts/pattern-learner.sh:182:  --daily                     ÂêØÁî®ÊØèÊó•Ë°∞ÂáèÊ®°Âºè
scripts/pattern-learner.sh:183:  --eliminate-threshold <n>   Ê∑òÊ±∞ÈòàÂÄºÔºàÈªòËÆ§: 0.3Ôºâ
scripts/pattern-learner.sh:216:  pattern-learner.sh learn --cwd ./src
scripts/pattern-learner.sh:219:  pattern-learner.sh --learn --output patterns.json
scripts/pattern-learner.sh:222:  pattern-learner.sh detect --confidence-threshold 0.9
scripts/pattern-learner.sh:228:  pattern-learner.sh decay --patterns-file ./patterns.json
scripts/pattern-learner.sh:240:  # Ëß£ÊûêÂëΩ‰ª§ÔºàÊîØÊåÅÂ≠êÂëΩ‰ª§Âíå --learn/--detect ÂÖºÂÆπÊ†ºÂºèÔºâ
scripts/pattern-learner.sh:241:  if [[ $# -gt 0 ]]; then
scripts/pattern-learner.sh:247:      --learn)
scripts/pattern-learner.sh:251:      --detect)
scripts/pattern-learner.sh:255:      --*)
scripts/pattern-learner.sh:265:  while [[ $# -gt 0 ]]; do
scripts/pattern-learner.sh:267:      --learn)
scripts/pattern-learner.sh:271:      --detect)
scripts/pattern-learner.sh:275:      --confidence-threshold)
scripts/pattern-learner.sh:279:      --patterns-file|--patterns)
scripts/pattern-learner.sh:283:      --output)
scripts/pattern-learner.sh:287:      --cwd)
scripts/pattern-learner.sh:292:      --format)
scripts/pattern-learner.sh:296:      --auto-discover)
scripts/pattern-learner.sh:300:      --min-frequency)
scripts/pattern-learner.sh:304:      --project)
scripts/pattern-learner.sh:310:      --decay-factor)
scripts/pattern-learner.sh:314:      --eliminate-threshold)
scripts/pattern-learner.sh:318:      --daily)
scripts/pattern-learner.sh:322:      --type)
scripts/pattern-learner.sh:323:        # ÊîØÊåÅ --type ÂèÇÊï∞Ôºànaming, structure Á≠âÔºâÔºåÁî®‰∫éÂÖºÂÆπÊÄß
scripts/pattern-learner.sh:327:      --version)
scripts/pattern-learner.sh:331:      --help|-h)
scripts/pattern-learner.sh:337:        if [ "$COMMAND" = "merge" ] && [ -z "${MERGE_FILE:-}" ]; then
scripts/pattern-learner.sh:350:  if [ -n "$OUTPUT_FILE" ]; then
scripts/pattern-learner.sh:355:  if ! echo "$CONFIDENCE_THRESHOLD" | grep -qE '^[0-9]+\.?[0-9]*$'; then
scripts/pattern-learner.sh:361:  if ! echo "$MIN_FREQUENCY" | grep -qE '^[0-9]+$'; then
scripts/pattern-learner.sh:367:  if ! echo "$DECAY_FACTOR" | grep -qE '^[0-9]+\.?[0-9]*$'; then
scripts/pattern-learner.sh:373:  if ! echo "$ELIMINATION_THRESHOLD" | grep -qE '^[0-9]+\.?[0-9]*$'; then
scripts/pattern-learner.sh:434:  if [ -n "$features_config" ] && [ -f "$features_config" ]; then
scripts/pattern-learner.sh:435:    if grep -q "enabled: false" "$features_config" 2>/dev/null; then
scripts/pattern-learner.sh:449:  files=$(find "$search_dir" -type f \( -name "*.ts" -o -name "*.js" -o -name "*.tsx" -o -name "*.jsx" -o -name "*.py" \) 2>/dev/null | head -500)
scripts/pattern-learner.sh:451:  if [ -z "$files" ]; then
scripts/pattern-learner.sh:459:  while IFS= read -r file; do
scripts/pattern-learner.sh:460:    [ -z "$file" ] && continue
scripts/pattern-learner.sh:466:    suffix=$(echo "$basename" | sed -E 's/^[a-z0-9]+//; s/^[A-Z][a-z0-9]+//' | grep -oE '^[A-Z][a-zA-Z0-9]+$' || true)
scripts/pattern-learner.sh:468:    if [ -z "$suffix" ]; then
scripts/pattern-learner.sh:470:      suffix=$(echo "$basename" | grep -oE '[A-Z][a-z]+$' || true)
scripts/pattern-learner.sh:473:    if [ -n "$suffix" ] && [ ${#suffix} -ge 4 ]; then
scripts/pattern-learner.sh:476:      current_count=$(echo "$suffix_counts" | jq -r --arg s "$suffix" '.[$s] // 0')
scripts/pattern-learner.sh:477:      suffix_counts=$(echo "$suffix_counts" | jq --arg s "$suffix" --argjson c "$((current_count + 1))" '.[$s] = $c')
scripts/pattern-learner.sh:503:  if [ ! -d "$search_dir" ]; then
scripts/pattern-learner.sh:516:  if [ "$total_suffixes" -eq 0 ]; then
scripts/pattern-learner.sh:521:    result=$(jq -n \
scripts/pattern-learner.sh:522:      --arg msg "Insufficient source files for pattern discovery" \
scripts/pattern-learner.sh:540:  entries=$(echo "$suffix_counts" | jq -c 'to_entries | sort_by(-.value) | .[]')
scripts/pattern-learner.sh:542:  while IFS= read -r entry; do
scripts/pattern-learner.sh:543:    [ -z "$entry" ] && continue
scripts/pattern-learner.sh:546:    suffix=$(echo "$entry" | jq -r '.key')
scripts/pattern-learner.sh:547:    count=$(echo "$entry" | jq -r '.value')
scripts/pattern-learner.sh:550:    if [ "$count" -ge "$MIN_FREQUENCY" ]; then
scripts/pattern-learner.sh:556:        --arg id "NP-$(printf '%03d' $pattern_id)" \
scripts/pattern-learner.sh:557:        --arg name "${suffix}Pattern" \
scripts/pattern-learner.sh:558:        --arg suffix "$suffix" \
scripts/pattern-learner.sh:559:        --argjson freq "$count" \
scripts/pattern-learner.sh:560:        --argjson conf "$confidence" \
scripts/pattern-learner.sh:577:  result=$(jq -n \
scripts/pattern-learner.sh:578:    --arg version "1.0" \
scripts/pattern-learner.sh:579:    --arg timestamp "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
scripts/pattern-learner.sh:580:    --argjson patterns "$patterns" \
scripts/pattern-learner.sh:581:    --argjson min_freq "$MIN_FREQUENCY" \
scripts/pattern-learner.sh:594:  mkdir -p "$devbooks_dir" 2>/dev/null
scripts/pattern-learner.sh:615:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/pattern-learner.sh:618:  if [ -z "$rg_cmd" ]; then
scripts/pattern-learner.sh:625:  for lang in $(echo "$languages" | jq -r '.[]'); do
scripts/pattern-learner.sh:626:    type_args="$type_args -t $lang"
scripts/pattern-learner.sh:632:  count=$("$rg_cmd" -c $type_args "$pattern" "$CWD" 2>/dev/null | awk -F: '{sum+=$2} END {print sum+0}') || echo "0"
scripts/pattern-learner.sh:644:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/pattern-learner.sh:647:  if [ -z "$rg_cmd" ]; then
scripts/pattern-learner.sh:654:  for lang in $(echo "$languages" | jq -r '.[]'); do
scripts/pattern-learner.sh:655:    type_args="$type_args -t $lang"
scripts/pattern-learner.sh:661:  results=$("$rg_cmd" -n --max-count="$max_examples" $type_args "$pattern" "$CWD" 2>/dev/null | head -"$max_examples") || true
scripts/pattern-learner.sh:663:  while IFS= read -r line; do
scripts/pattern-learner.sh:664:    [ -z "$line" ] && continue
scripts/pattern-learner.sh:666:    file_line=$(echo "$line" | cut -d: -f1-2)
scripts/pattern-learner.sh:668:    examples=$(echo "$examples" | jq --arg e "$file_line" '. + [$e]')
scripts/pattern-learner.sh:696:    id=$(echo "$definition" | jq -r '.id')
scripts/pattern-learner.sh:697:    name=$(echo "$definition" | jq -r '.name')
scripts/pattern-learner.sh:698:    description=$(echo "$definition" | jq -r '.description')
scripts/pattern-learner.sh:699:    regex=$(echo "$definition" | jq -r '.regex')
scripts/pattern-learner.sh:701:    min_occurrences=$(echo "$definition" | jq -r '.min_occurrences')
scripts/pattern-learner.sh:711:    if [ "$occurrences" -ge "$min_occurrences" ]; then
scripts/pattern-learner.sh:724:      --arg id "$id" \
scripts/pattern-learner.sh:725:      --arg name "$name" \
scripts/pattern-learner.sh:726:      --arg desc "$description" \
scripts/pattern-learner.sh:727:      --argjson occ "$occurrences" \
scripts/pattern-learner.sh:728:      --argjson conf "$confidence" \
scripts/pattern-learner.sh:729:      --argjson examples "$examples" \
scripts/pattern-learner.sh:742:  result=$(jq -n \
scripts/pattern-learner.sh:743:    --arg version "1.0" \
scripts/pattern-learner.sh:744:    --arg timestamp "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
scripts/pattern-learner.sh:745:    --argjson patterns "$patterns" \
scripts/pattern-learner.sh:754:  mkdir -p "$(dirname "$patterns_path")" 2>/dev/null
scripts/pattern-learner.sh:774:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/pattern-learner.sh:777:  if [ -z "$rg_cmd" ]; then
scripts/pattern-learner.sh:790:      async_without_try=$("$rg_cmd" -n --max-count=5 -t ts -t js \
scripts/pattern-learner.sh:792:        grep -v 'try\s*{' | head -5) || true
scripts/pattern-learner.sh:794:      while IFS= read -r line; do
scripts/pattern-learner.sh:795:        [ -z "$line" ] && continue
scripts/pattern-learner.sh:797:        file_path=$(echo "$line" | cut -d: -f1)
scripts/pattern-learner.sh:799:        line_num=$(echo "$line" | cut -d: -f2)
scripts/pattern-learner.sh:802:          --arg file "$file_path" \
scripts/pattern-learner.sh:803:          --argjson line "$line_num" \
scripts/pattern-learner.sh:804:          --arg pid "$pattern_id" \
scripts/pattern-learner.sh:805:          --arg msg "async ÂáΩÊï∞Êú™‰ΩøÁî® try-catch ÂåÖË£π" \
scripts/pattern-learner.sh:819:      empty_catch=$("$rg_cmd" -n --max-count=5 -t ts -t js \
scripts/pattern-learner.sh:820:        'catch\s*\([^)]*\)\s*\{\s*\}' "$CWD" 2>/dev/null | head -5) || true
scripts/pattern-learner.sh:822:      while IFS= read -r line; do
scripts/pattern-learner.sh:823:        [ -z "$line" ] && continue
scripts/pattern-learner.sh:825:        file_path=$(echo "$line" | cut -d: -f1)
scripts/pattern-learner.sh:827:        line_num=$(echo "$line" | cut -d: -f2)
scripts/pattern-learner.sh:830:          --arg file "$file_path" \
scripts/pattern-learner.sh:831:          --argjson line "$line_num" \
scripts/pattern-learner.sh:832:          --arg pid "$pattern_id" \
scripts/pattern-learner.sh:833:          --arg msg "catch Âùó‰∏∫Á©∫ÔºåÁº∫Â∞ëÈîôËØØÊó•ÂøóËÆ∞ÂΩï" \
scripts/pattern-learner.sh:855:  if [ ! -f "$patterns_path" ]; then
scripts/pattern-learner.sh:878:    id=$(echo "$pattern" | jq -r '.id')
scripts/pattern-learner.sh:879:    name=$(echo "$pattern" | jq -r '.name')
scripts/pattern-learner.sh:880:    confidence=$(echo "$pattern" | jq -r '.confidence')
scripts/pattern-learner.sh:896:    definition=$(echo "$definitions" | jq --arg id "$id" '.[] | select(.id == $id)')
scripts/pattern-learner.sh:898:    if [ -z "$definition" ] || [ "$definition" = "null" ]; then
scripts/pattern-learner.sh:903:    regex=$(echo "$definition" | jq -r '.regex // ""')
scripts/pattern-learner.sh:906:    if [ -z "$regex" ]; then
scripts/pattern-learner.sh:914:    if [ -n "$detected_anomalies" ] && [ "$detected_anomalies" != "[]" ]; then
scripts/pattern-learner.sh:915:      anomalies=$(echo "$anomalies" | jq --argjson new "$detected_anomalies" '. + $new')
scripts/pattern-learner.sh:921:  result=$(jq -n \
scripts/pattern-learner.sh:922:    --arg version "1.0" \
scripts/pattern-learner.sh:923:    --argjson patterns "$patterns" \
scripts/pattern-learner.sh:924:    --argjson anomalies "$anomalies" \
scripts/pattern-learner.sh:925:    --argjson threshold "$CONFIDENCE_THRESHOLD" \
scripts/pattern-learner.sh:945:  if [ ! -f "$merge_file" ]; then
scripts/pattern-learner.sh:956:  if [ -f "$patterns_path" ]; then
scripts/pattern-learner.sh:962:  merged=$(jq -n \
scripts/pattern-learner.sh:963:    --argjson existing "$existing_patterns" \
scripts/pattern-learner.sh:964:    --argjson external "$external_patterns" \
scripts/pattern-learner.sh:976:  mkdir -p "$(dirname "$patterns_path")" 2>/dev/null
scripts/pattern-learner.sh:1006:  score=$(awk -v f="$frequency" -v d="$decay" -v days="$days_since_last" \
scripts/pattern-learner.sh:1036:  result=$(awk -v init="$initial_confidence" -v d="$decay" -v days="$days" \
scripts/pattern-learner.sh:1058:  local end_date="${2:-$(date -u +"%Y-%m-%dT%H:%M:%SZ")}"
scripts/pattern-learner.sh:1066:    start_day=$(date -j -f "%Y-%m-%dT%H:%M:%SZ" "$start_date" "+%s" 2>/dev/null || \
scripts/pattern-learner.sh:1067:                date -j -f "%Y-%m-%d" "${start_date:0:10}" "+%s" 2>/dev/null || echo "0")
scripts/pattern-learner.sh:1068:    end_day=$(date -j -f "%Y-%m-%dT%H:%M:%SZ" "$end_date" "+%s" 2>/dev/null || \
scripts/pattern-learner.sh:1069:              date -j -f "%Y-%m-%d" "${end_date:0:10}" "+%s" 2>/dev/null || date "+%s")
scripts/pattern-learner.sh:1072:    start_day=$(date -d "$start_date" "+%s" 2>/dev/null || \
scripts/pattern-learner.sh:1073:                date -d "${start_date:0:10}" "+%s" 2>/dev/null || echo "0")
scripts/pattern-learner.sh:1074:    end_day=$(date -d "$end_date" "+%s" 2>/dev/null || \
scripts/pattern-learner.sh:1075:              date -d "${end_date:0:10}" "+%s" 2>/dev/null || date "+%s")
scripts/pattern-learner.sh:1083:  if [ "$diff_days" -lt 0 ]; then
scripts/pattern-learner.sh:1104:  if [ ! -f "$patterns_path" ]; then
scripts/pattern-learner.sh:1117:  if [[ -n "${PATTERN_DECAY_MOCK_DATE:-}" ]]; then
scripts/pattern-learner.sh:1119:    mock_today=$(echo '{}' | jq --arg d "${PATTERN_DECAY_MOCK_DATE}" '
scripts/pattern-learner.sh:1126:  result=$(jq -c \
scripts/pattern-learner.sh:1127:    --argjson t "$ELIMINATION_THRESHOLD" \
scripts/pattern-learner.sh:1128:    --argjson mock_today "${mock_today:-null}" \
scripts/pattern-learner.sh:1170:  mkdir -p "$(dirname "$patterns_path")" 2>/dev/null
scripts/pattern-learner.sh:1199:    if [ "$pattern_count" -gt 0 ]; then
scripts/pattern-learner.sh:1208:        id=$(echo "$pattern" | jq -r '.id')
scripts/pattern-learner.sh:1209:        name=$(echo "$pattern" | jq -r '.name')
scripts/pattern-learner.sh:1210:        occurrences=$(echo "$pattern" | jq -r '.occurrences')
scripts/pattern-learner.sh:1211:        confidence=$(echo "$pattern" | jq -r '.confidence')
scripts/pattern-learner.sh:1222:    if [ "$anomaly_count" -gt 0 ]; then
scripts/pattern-learner.sh:1231:        file_path=$(echo "$anomaly" | jq -r '.file_path')
scripts/pattern-learner.sh:1232:        line=$(echo "$anomaly" | jq -r '.line')
scripts/pattern-learner.sh:1233:        message=$(echo "$anomaly" | jq -r '.message')
scripts/pattern-learner.sh:1258:      if [ -z "${MERGE_FILE:-}" ]; then
scripts/call-chain-trace.sh:14:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/call-chain-trace.sh:17:  if [ -z "$rg_cmd" ]; then
scripts/call-chain-trace.sh:26:    --max-count=1 \
scripts/call-chain-trace.sh:27:    -n \
scripts/call-chain-trace.sh:28:    --pcre2 \
scripts/call-chain-trace.sh:29:    -t py -t js -t ts -t go \
scripts/call-chain-trace.sh:30:    "$def_pattern" "$CWD" 2>/dev/null | head -1)
scripts/call-chain-trace.sh:32:  if [ -n "$result" ]; then
scripts/call-chain-trace.sh:34:    file_path=$(echo "$result" | cut -d: -f1)
scripts/call-chain-trace.sh:35:    line=$(echo "$result" | cut -d: -f2)
scripts/call-chain-trace.sh:38:    jq -n \
scripts/call-chain-trace.sh:39:      --arg symbol "$symbol" \
scripts/call-chain-trace.sh:40:      --arg file "$file_path" \
scripts/call-chain-trace.sh:41:      --argjson line "$line" \
scripts/call-chain-trace.sh:54:  echo "$VISITED_NODES" | jq -e --arg n "$node" 'index($n)' >/dev/null 2>&1
scripts/call-chain-trace.sh:60:  VISITED_NODES=$(echo "$VISITED_NODES" | jq --arg n "$node" '. + [$n]')
scripts/call-chain-trace.sh:70:  if [ ! -f "$full_path" ]; then
scripts/call-chain-trace.sh:81:    function_body=$(sed -n "/${symbol}/,/^[^ ]/p" "$full_path" 2>/dev/null | head -50)
scripts/call-chain-trace.sh:85:    calls=$(echo "$function_body" | grep -oE '\b[a-zA-Z_][a-zA-Z0-9_]*\s*\(' | \
scripts/call-chain-trace.sh:86:      sed 's/\s*(//' | grep -vE '^(if|for|while|switch|return|print|console|log)$' | \
scripts/call-chain-trace.sh:87:      sort -u | head -10)
scripts/call-chain-trace.sh:89:    while IFS= read -r callee; do
scripts/call-chain-trace.sh:90:      [ -z "$callee" ] && continue
scripts/call-chain-trace.sh:91:      results=$(echo "$results" | jq --arg c "$callee" '. + [{symbol_id: $c, type: "callee"}]')
scripts/call-chain-trace.sh:99:      [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/call-chain-trace.sh:102:    if [ -n "$rg_cmd" ]; then
scripts/call-chain-trace.sh:104:      callers=$("$rg_cmd" -l --max-count=5 -t py -t js -t ts -t go \
scripts/call-chain-trace.sh:105:        "${symbol}\\s*\\(" "$CWD" 2>/dev/null | grep -v "$file_path" | head -5)
scripts/call-chain-trace.sh:107:      while IFS= read -r caller_file; do
scripts/call-chain-trace.sh:108:        [ -z "$caller_file" ] && continue
scripts/call-chain-trace.sh:110:        results=$(echo "$results" | jq --arg f "$rel_path" '. + [{file_path: $f, type: "caller"}]')
scripts/call-chain-trace.sh:126:  if [ "$current_depth" -gt "$max_depth" ]; then
scripts/call-chain-trace.sh:144:  if [ -z "$definition" ]; then
scripts/call-chain-trace.sh:150:  file_path=$(echo "$definition" | jq -r '.file_path')
scripts/call-chain-trace.sh:151:  line=$(echo "$definition" | jq -r '.line')
scripts/call-chain-trace.sh:159:  node=$(jq -n \
scripts/call-chain-trace.sh:160:    --arg symbol "$symbol" \
scripts/call-chain-trace.sh:161:    --arg file "$file_path" \
scripts/call-chain-trace.sh:162:    --argjson line "$line" \
scripts/call-chain-trace.sh:163:    --argjson depth "$current_depth" \
scripts/call-chain-trace.sh:172:  if [ "$current_depth" -lt "$max_depth" ]; then
scripts/call-chain-trace.sh:183:      call_type=$(echo "$call" | jq -r '.type')
scripts/call-chain-trace.sh:185:      call_symbol=$(echo "$call" | jq -r '.symbol_id // .file_path')
scripts/call-chain-trace.sh:190:        callees=$(echo "$callees" | jq --argjson c "$child" '. + [$c]')
scripts/call-chain-trace.sh:192:        callers=$(echo "$callers" | jq --argjson c "$call" '. + [$c]')
scripts/call-chain-trace.sh:196:    node=$(echo "$node" | jq --argjson callers "$callers" --argjson callees "$callees" \
scripts/call-chain-trace.sh:211:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/call-chain-trace.sh:214:  if [ -z "$rg_cmd" ]; then
scripts/call-chain-trace.sh:220:  usages=$("$rg_cmd" -n --max-count=10 -t py -t js -t ts -t go \
scripts/call-chain-trace.sh:221:    "${symbol}\\s*\\(" "$CWD" 2>/dev/null | head -10)
scripts/call-chain-trace.sh:225:  while IFS= read -r usage; do
scripts/call-chain-trace.sh:226:    [ -z "$usage" ] && continue
scripts/call-chain-trace.sh:228:    file_path=$(echo "$usage" | cut -d: -f1)
scripts/call-chain-trace.sh:229:    line=$(echo "$usage" | cut -d: -f2)
scripts/call-chain-trace.sh:233:      --arg file "$file_path" \
scripts/call-chain-trace.sh:234:      --argjson line "$line" \
scripts/call-chain-trace.sh:235:      --arg symbol "$symbol" \
scripts/call-chain-trace.sh:251:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/call-chain-trace.sh:255:  if [ -z "$rg_cmd" ]; then
scripts/call-chain-trace.sh:256:    rg_cmd=$(command -v rg 2>/dev/null || true)
scripts/call-chain-trace.sh:259:  if [ -z "$rg_cmd" ]; then
scripts/call-chain-trace.sh:261:    jq -n \
scripts/call-chain-trace.sh:262:      --arg symbol "$symbol" \
scripts/call-chain-trace.sh:284:  if [ -n "$definition" ]; then
scripts/call-chain-trace.sh:285:    source_file=$(echo "$definition" | jq -r '.file_path')
scripts/call-chain-trace.sh:286:    source_line=$(echo "$definition" | jq -r '.line')
scripts/call-chain-trace.sh:291:  usages=$("$rg_cmd" -n --max-count=20 -t py -t js -t ts -t go \
scripts/call-chain-trace.sh:292:    "${symbol}\\s*\\(" "$CWD" 2>/dev/null | head -20)
scripts/call-chain-trace.sh:296:  while IFS= read -r usage; do
scripts/call-chain-trace.sh:297:    [ -z "$usage" ] && continue
scripts/call-chain-trace.sh:300:    file_path=$(echo "$usage" | cut -d: -f1)
scripts/call-chain-trace.sh:301:    line=$(echo "$usage" | cut -d: -f2)
scripts/call-chain-trace.sh:302:    content=$(echo "$usage" | cut -d: -f3-)
scripts/call-chain-trace.sh:307:    args=$(echo "$content" | grep -oE "${symbol}\\s*\\([^)]*\\)" | sed "s/${symbol}\\s*(//;s/)$//" | head -1)
scripts/call-chain-trace.sh:311:    flow=$(jq -n \
scripts/call-chain-trace.sh:312:      --arg source "$source_file:$source_line" \
scripts/call-chain-trace.sh:313:      --arg path "$file_path:$line" \
scripts/call-chain-trace.sh:314:      --arg sink "$symbol" \
scripts/call-chain-trace.sh:315:      --arg args "$args" \
scripts/call-chain-trace.sh:324:    flows=$(echo "$flows" | jq --argjson f "$flow" '. + [$f]')
scripts/call-chain-trace.sh:328:  jq -n \
scripts/call-chain-trace.sh:329:    --arg symbol "$symbol" \
scripts/call-chain-trace.sh:330:    --arg source_file "$source_file" \
scripts/call-chain-trace.sh:331:    --argjson source_line "${source_line:-0}" \
scripts/call-chain-trace.sh:332:    --argjson flows "$flows" \
scripts/adr-parser.sh:14:set -euo pipefail
scripts/adr-parser.sh:61:    if [[ ${#lower_word} -lt 3 ]]; then
scripts/adr-parser.sh:89:        if [[ -d "$full_path" ]]; then
scripts/adr-parser.sh:109:    first_line=$(head -1 "$file" | tr -d '\r')
scripts/adr-parser.sh:134:    awk -v section="$section" '
scripts/adr-parser.sh:165:    first_line=$(head -1 "$file" | tr -d '\r')
scripts/adr-parser.sh:178:    [[ -z "$status" ]] && status="Unknown"
scripts/adr-parser.sh:190:    jq -n \
scripts/adr-parser.sh:191:        --arg id "$adr_id" \
scripts/adr-parser.sh:192:        --arg title "$title" \
scripts/adr-parser.sh:193:        --arg status "$status" \
scripts/adr-parser.sh:194:        --arg context "$context" \
scripts/adr-parser.sh:195:        --arg decision "$decision" \
scripts/adr-parser.sh:196:        --arg consequences "$consequences" \
scripts/adr-parser.sh:197:        --arg file_path "$file" \
scripts/adr-parser.sh:198:        --arg format "madr" \
scripts/adr-parser.sh:218:    first_line=$(head -1 "$file" | tr -d '\r')
scripts/adr-parser.sh:230:    adr_date=$(grep -E "^Date:" "$file" 2>/dev/null | head -1 | sed 's/^Date:[[:space:]]*//' | tr -d '\r')
scripts/adr-parser.sh:235:    [[ -z "$status" ]] && status="Unknown"
scripts/adr-parser.sh:247:    jq -n \
scripts/adr-parser.sh:248:        --arg id "$adr_id" \
scripts/adr-parser.sh:249:        --arg title "$title" \
scripts/adr-parser.sh:250:        --arg status "$status" \
scripts/adr-parser.sh:251:        --arg date "$adr_date" \
scripts/adr-parser.sh:252:        --arg context "$context" \
scripts/adr-parser.sh:253:        --arg decision "$decision" \
scripts/adr-parser.sh:254:        --arg consequences "$consequences" \
scripts/adr-parser.sh:255:        --arg file_path "$file" \
scripts/adr-parser.sh:256:        --arg format "nygard" \
scripts/adr-parser.sh:274:    if [[ ! -f "$file" ]]; then
scripts/adr-parser.sh:303:    decision=$(echo "$adr_json" | jq -r '.decision // ""')
scripts/adr-parser.sh:304:    context=$(echo "$adr_json" | jq -r '.context // ""')
scripts/adr-parser.sh:305:    title=$(echo "$adr_json" | jq -r '.title // ""')
scripts/adr-parser.sh:311:    while IFS= read -r match; do
scripts/adr-parser.sh:312:        [[ -n "$match" ]] && keywords+=("$match")
scripts/adr-parser.sh:313:    done < <(echo "$all_text" | grep -oE '\`[^\`]+\`' | sed 's/\`//g')
scripts/adr-parser.sh:316:    while IFS= read -r match; do
scripts/adr-parser.sh:317:        if [[ -n "$match" ]] && ! is_stop_word "$match"; then
scripts/adr-parser.sh:320:    done < <(echo "$all_text" | grep -oE '\b[A-Z][a-z]+([A-Z][a-z]*)+\b')
scripts/adr-parser.sh:323:    while IFS= read -r match; do
scripts/adr-parser.sh:324:        if [[ -n "$match" ]] && ! is_stop_word "$match" && [[ ${#match} -ge 4 ]]; then
scripts/adr-parser.sh:327:    done < <(echo "$all_text" | grep -oE '\b[A-Z][a-zA-Z]+\b')
scripts/adr-parser.sh:330:    while IFS= read -r match; do
scripts/adr-parser.sh:331:        if [[ -n "$match" ]] && ! is_stop_word "$match"; then
scripts/adr-parser.sh:334:    done < <(echo "$all_text" | grep -oE '\b[a-z]+([A-Z][a-z]+)+\b')
scripts/adr-parser.sh:337:    while IFS= read -r match; do
scripts/adr-parser.sh:338:        if [[ -n "$match" ]] && ! is_stop_word "$match"; then
scripts/adr-parser.sh:341:    done < <(echo "$all_text" | grep -oE '\b[A-Z][A-Z_]+\b')
scripts/adr-parser.sh:344:    while IFS= read -r match; do
scripts/adr-parser.sh:345:        [[ -n "$match" ]] && keywords+=("$match")
scripts/adr-parser.sh:346:    done < <(echo "$all_text" | grep -oE '[a-zA-Z0-9_-]+\.(ts|tsx|js|jsx|py|go|sh|md)' 2>/dev/null || true)
scripts/adr-parser.sh:349:    while IFS= read -r match; do
scripts/adr-parser.sh:350:        [[ -n "$match" ]] && keywords+=("$match")
scripts/adr-parser.sh:351:    done < <(echo "$all_text" | grep -oE '[a-zA-Z0-9_/.-]+\.(ts|tsx|js|jsx|py|go|sh)' 2>/dev/null || true)
scripts/adr-parser.sh:357:    if [[ ${#keywords[@]} -eq 0 ]]; then
scripts/adr-parser.sh:367:        if [[ -n "$cleaned" && ${#cleaned} -ge 3 ]]; then
scripts/adr-parser.sh:377:    if [[ ${#unique_keywords[@]} -eq 0 ]]; then
scripts/adr-parser.sh:381:    printf '%s\n' "${unique_keywords[@]}" | jq -R . | jq -s .
scripts/adr-parser.sh:390:    if [[ ! -f "$GRAPH_DB_PATH" ]]; then
scripts/adr-parser.sh:400:    while IFS= read -r keyword; do
scripts/adr-parser.sh:401:        [[ -z "$keyword" ]] && continue
scripts/adr-parser.sh:417:        if [[ -n "$matches" ]]; then
scripts/adr-parser.sh:419:            while IFS='|' read -r node_id symbol file_path; do
scripts/adr-parser.sh:420:                [[ -z "$node_id" ]] && continue
scripts/adr-parser.sh:448:    done < <(echo "$keywords_json" | jq -r '.[]')
scripts/adr-parser.sh:452:    if [[ ${#related_nodes[@]} -eq 0 ]]; then
scripts/adr-parser.sh:455:        unique_nodes=$(printf '%s\n' "${related_nodes[@]}" | sort -u | jq -R . | jq -s .)
scripts/adr-parser.sh:458:    jq -n \
scripts/adr-parser.sh:459:        --argjson related_nodes "$unique_nodes" \
scripts/adr-parser.sh:460:        --argjson edges_added "$edges_added" \
scripts/adr-parser.sh:470:    while [[ $# -gt 0 ]]; do
scripts/adr-parser.sh:472:            --format) format="$2"; shift 2 ;;
scripts/adr-parser.sh:477:    if [[ -z "$file" ]]; then
scripts/adr-parser.sh:493:    result=$(echo "$adr_json" | jq --argjson keywords "$keywords_json" '. + {keywords: $keywords}')
scripts/adr-parser.sh:496:    jq -n --argjson adr "$result" '{adrs: [$adr], edges_generated: 0}'
scripts/adr-parser.sh:504:    while [[ $# -gt 0 ]]; do
scripts/adr-parser.sh:510:    if [[ -z "$file" ]]; then
scripts/adr-parser.sh:530:    while [[ $# -gt 0 ]]; do
scripts/adr-parser.sh:532:            --adr-dir) adr_dir="$2"; shift 2 ;;
scripts/adr-parser.sh:533:            --link) link=true; shift ;;
scripts/adr-parser.sh:534:            --format) format="$2"; shift 2 ;;
scripts/adr-parser.sh:542:    if [[ -z "$adr_dir" ]]; then
scripts/adr-parser.sh:548:    if [[ -z "$adr_dir" || ! -d "$adr_dir" ]]; then
scripts/adr-parser.sh:559:        [[ -f "$adr_file" ]] || continue
scripts/adr-parser.sh:572:        adr_json=$(echo "$adr_json" | jq --argjson keywords "$keywords_json" '. + {keywords: $keywords}')
scripts/adr-parser.sh:574:        # Â¶ÇÊûúÂêØÁî® --linkÔºåÂÖ≥ËÅîÂà∞Âõæ
scripts/adr-parser.sh:577:            adr_id=$(echo "$adr_json" | jq -r '.id')
scripts/adr-parser.sh:583:            edges_added=$(echo "$link_result" | jq -r '.edges_added')
scripts/adr-parser.sh:589:            adr_json=$(echo "$adr_json" | jq --argjson related "$related_nodes" '. + {related_nodes: $related}')
scripts/adr-parser.sh:597:    if [[ ${#adrs[@]} -eq 0 ]]; then
scripts/adr-parser.sh:600:        adrs_array=$(printf '%s\n' "${adrs[@]}" | jq -s .)
scripts/adr-parser.sh:604:    result=$(jq -n \
scripts/adr-parser.sh:605:        --argjson adrs "$adrs_array" \
scripts/adr-parser.sh:606:        --argjson edges "$total_edges" \
scripts/adr-parser.sh:609:    # Â¶ÇÊûúÂêØÁî® --linkÔºåÊõ¥Êñ∞Á¥¢ÂºïÊñá‰ª∂
scripts/adr-parser.sh:631:    if [[ -n "$adr_dir" && -d "$adr_dir" ]]; then
scripts/adr-parser.sh:632:        adr_count=$(ls "$adr_dir"/*.md 2>/dev/null | wc -l | tr -d ' ')
scripts/adr-parser.sh:635:    if [[ -f "$ADR_INDEX_PATH" ]]; then
scripts/adr-parser.sh:637:        index_mtime=$(stat -f "%m" "$ADR_INDEX_PATH" 2>/dev/null || stat -c "%Y" "$ADR_INDEX_PATH" 2>/dev/null || echo "0")
scripts/adr-parser.sh:640:    if [[ -f "$GRAPH_DB_PATH" ]]; then
scripts/adr-parser.sh:644:    jq -n \
scripts/adr-parser.sh:645:        --arg adr_dir "${adr_dir:-none}" \
scripts/adr-parser.sh:646:        --argjson adr_count "$adr_count" \
scripts/adr-parser.sh:647:        --argjson index_exists "$index_exists" \
scripts/adr-parser.sh:648:        --arg index_mtime "$index_mtime" \
scripts/adr-parser.sh:649:        --argjson edge_count "$edge_count" \
scripts/adr-parser.sh:667:    mkdir -p "$(dirname "$ADR_INDEX_PATH")"
scripts/adr-parser.sh:675:        --argjson updated_at "$now" \
scripts/adr-parser.sh:698:    --format json|text  ËæìÂá∫Ê†ºÂºèÔºàÈªòËÆ§ jsonÔºâ
scripts/adr-parser.sh:701:    --adr-dir <path>    ÊåáÂÆö ADR ÁõÆÂΩïÔºàË¶ÜÁõñËá™Âä®ÂèëÁé∞Ôºâ
scripts/adr-parser.sh:702:    --link              ÁîüÊàêÂÖ≥ËÅîËæπÂÜôÂÖ• graph.db
scripts/adr-parser.sh:703:    --format json|text  ËæìÂá∫Ê†ºÂºèÔºàÈªòËÆ§ jsonÔºâ
scripts/adr-parser.sh:731:    adr-parser.sh scan --link
scripts/semantic-anomaly.sh:19:#   semantic-anomaly.sh --pattern <file> <path>  ‰ΩøÁî®Ëá™ÂÆö‰πâÊ®°ÂºèÊñá‰ª∂
scripts/semantic-anomaly.sh:20:#   semantic-anomaly.sh --output json <path>   ÊåáÂÆöËæìÂá∫Ê†ºÂºè
scripts/semantic-anomaly.sh:21:#   semantic-anomaly.sh --threshold 0.8 <path> ËÆæÁΩÆÁΩÆ‰ø°Â∫¶ÈòàÂÄº
scripts/semantic-anomaly.sh:25:set -euo pipefail
scripts/semantic-anomaly.sh:30:  if [[ -n "${_TEMP_FILES:-}" ]]; then
scripts/semantic-anomaly.sh:32:      [[ -f "$f" ]] && rm -f "$f" 2>/dev/null || true
scripts/semantic-anomaly.sh:36:  if [[ -n "${_PATTERN_CACHE:-}" ]] && [[ -f "$_PATTERN_CACHE" ]]; then
scripts/semantic-anomaly.sh:37:    rm -f "$_PATTERN_CACHE" 2>/dev/null || true
scripts/semantic-anomaly.sh:50:if [ -f "$COMMON_LIB" ]; then
scripts/semantic-anomaly.sh:61:  log_info()  { echo -e "${BLUE}[SemanticAnomaly]${NC} $1" >&2; }
scripts/semantic-anomaly.sh:62:  log_ok()    { echo -e "${GREEN}[SemanticAnomaly]${NC} $1" >&2; }
scripts/semantic-anomaly.sh:63:  log_warn()  { echo -e "${YELLOW}[SemanticAnomaly]${NC} $1" >&2; }
scripts/semantic-anomaly.sh:64:  log_error() { echo -e "${RED}[SemanticAnomaly]${NC} $1" >&2; }
scripts/semantic-anomaly.sh:68:if declare -f check_dependencies &>/dev/null; then
scripts/semantic-anomaly.sh:71:  command -v jq &>/dev/null || { log_error "Áº∫Â∞ë‰æùËµñ: jq"; exit 2; }
scripts/semantic-anomaly.sh:115: --pattern <file>       ‰ΩøÁî®Ëá™ÂÆö‰πâÊ®°ÂºèÊñá‰ª∂
scripts/semantic-anomaly.sh:116:  --output <file|format> ËæìÂá∫Êñá‰ª∂ÔºàJSONLÔºâÊàñÊ†ºÂºè: json | text
scripts/semantic-anomaly.sh:117:  --threshold <0.0-1.0>  ÁΩÆ‰ø°Â∫¶ÈòàÂÄº (ÈªòËÆ§: 0.8)
scripts/semantic-anomaly.sh:118:  --verbose              ÊòæÁ§∫ËØ¶ÁªÜËæìÂá∫
scripts/semantic-anomaly.sh:119:  --report               ÁîüÊàêÊä•ÂëäÂà∞ evidence/semantic-anomaly-report.md
scripts/semantic-anomaly.sh:120:  --feedback <file> <line> <feedback>
scripts/semantic-anomaly.sh:122:  --enable-anomaly-detection
scripts/semantic-anomaly.sh:124:  --enable-all-features  ÂøΩÁï•ÂäüËÉΩÂºÄÂÖ≥ÈÖçÁΩÆÔºåÂº∫Âà∂ÂêØÁî®ÊâÄÊúâÂäüËÉΩ
scripts/semantic-anomaly.sh:125:  --help                 ÊòæÁ§∫Ê≠§Â∏ÆÂä©
scripts/semantic-anomaly.sh:126:  --version              ÊòæÁ§∫ÁâàÊú¨
scripts/semantic-anomaly.sh:164:  semantic-anomaly.sh --pattern my-patterns.json src/
scripts/semantic-anomaly.sh:167:  semantic-anomaly.sh --threshold 0.9 src/
scripts/semantic-anomaly.sh:179:  while [[ $# -gt 0 ]]; do
scripts/semantic-anomaly.sh:181:      --pattern)
scripts/semantic-anomaly.sh:185:      --output)
scripts/semantic-anomaly.sh:186:        if [[ -z "${2:-}" ]]; then
scripts/semantic-anomaly.sh:197:      --threshold)
scripts/semantic-anomaly.sh:201:      --report)
scripts/semantic-anomaly.sh:205:      --feedback)
scripts/semantic-anomaly.sh:212:      --enable-anomaly-detection)
scripts/semantic-anomaly.sh:216:      --enable-all-features)
scripts/semantic-anomaly.sh:220:      --verbose|-v)
scripts/semantic-anomaly.sh:224:      --version)
scripts/semantic-anomaly.sh:228:      --help|-h)
scripts/semantic-anomaly.sh:245:    if [[ -z "$FEEDBACK_FILE" || -z "$FEEDBACK_LINE" || -z "$FEEDBACK_STATUS" ]]; then
scripts/semantic-anomaly.sh:253:  if [[ "$REPORT_MODE" == "true" && -z "$TARGET_PATH" ]]; then
scripts/semantic-anomaly.sh:258:  if [ -z "$TARGET_PATH" ]; then
scripts/semantic-anomaly.sh:264:  if [ ! -e "$TARGET_PATH" ]; then
scripts/semantic-anomaly.sh:270:  if ! echo "$CONFIDENCE_THRESHOLD" | grep -qE '^[0-9]+\.?[0-9]*$'; then
scripts/semantic-anomaly.sh:287:  if [ -n "$PATTERNS_FILE" ]; then
scripts/semantic-anomaly.sh:288:    if [ -f "$PATTERNS_FILE" ]; then
scripts/semantic-anomaly.sh:296:  if [ -z "$patterns_path" ]; then
scripts/semantic-anomaly.sh:307:  if [ -f "$patterns_path" ]; then
scripts/semantic-anomaly.sh:309:    patterns=$(jq -c '.patterns // []' "$patterns_path" 2>/dev/null || echo '[]')
scripts/semantic-anomaly.sh:334:  matched_pattern=$(echo "$LOADED_PATTERNS" | jq -r --arg type "$pattern_type" '
scripts/semantic-anomaly.sh:338:  if [ -n "$matched_pattern" ] && [ "$matched_pattern" != "null" ]; then
scripts/semantic-anomaly.sh:359:    --arg type "$type" \
scripts/semantic-anomaly.sh:360:    --arg file "$file" \
scripts/semantic-anomaly.sh:361:    --argjson line "$line" \
scripts/semantic-anomaly.sh:362:    --arg severity "$severity" \
scripts/semantic-anomaly.sh:363:    --arg message "$message" \
scripts/semantic-anomaly.sh:364:    --arg suggestion "$suggestion" \
scripts/semantic-anomaly.sh:365:    --arg pattern_source "$pattern_source" \
scripts/semantic-anomaly.sh:388:  before_content=$(echo "$content" | head -n "$target_line")
scripts/semantic-anomaly.sh:396:  func_declarations=$(echo "$before_content" | grep -n 'function[[:space:]]\+[a-zA-Z_][a-zA-Z0-9_]*' 2>/dev/null | tail -1 || true)
scripts/semantic-anomaly.sh:398:  if [ -n "$func_declarations" ]; then
scripts/semantic-anomaly.sh:399:    func_line=$(echo "$func_declarations" | cut -d: -f2-)
scripts/semantic-anomaly.sh:402:    func_name=$(echo "$func_line" | sed -E 's/.*function[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/')
scripts/semantic-anomaly.sh:406:  if [ -z "$func_name" ]; then
scripts/semantic-anomaly.sh:407:    func_declarations=$(echo "$before_content" | grep -n '[a-zA-Z_][a-zA-Z0-9_]*[[:space:]]*=[[:space:]]*\(async[[:space:]]*\)\?(' 2>/dev/null | tail -1 || true)
scripts/semantic-anomaly.sh:409:    if [ -n "$func_declarations" ]; then
scripts/semantic-anomaly.sh:410:      func_line=$(echo "$func_declarations" | cut -d: -f2-)
scripts/semantic-anomaly.sh:411:      func_name=$(echo "$func_line" | sed -E 's/.*(const|let|var)[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*)[[:space:]]*=.*/\2/')
scripts/semantic-anomaly.sh:426:  before_content=$(echo "$content" | head -n "$target_line")
scripts/semantic-anomaly.sh:430:  func_count=$(echo "$before_content" | grep -c 'function\s\+[a-zA-Z_]' 2>/dev/null || true)
scripts/semantic-anomaly.sh:434:  if [ "$func_count" -gt 1 ]; then
scripts/semantic-anomaly.sh:449:  before_content=$(echo "$content" | head -n "$target_line")
scripts/semantic-anomaly.sh:453:  func_line_num=$(echo "$before_content" | grep -n 'function\s\+[a-zA-Z_]' 2>/dev/null | tail -1 | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:455:  if [ -z "$func_line_num" ]; then
scripts/semantic-anomaly.sh:462:  func_content=$(echo "$content" | sed -n "${func_line_num},${target_line}p")
scripts/semantic-anomaly.sh:466:  try_count=$(echo "$func_content" | grep -c 'try\s*{' 2>/dev/null || true)
scripts/semantic-anomaly.sh:468:  catch_count=$(echo "$func_content" | grep -c 'catch\s*(' 2>/dev/null || true)
scripts/semantic-anomaly.sh:471:  if [ "$try_count" -gt "$catch_count" ]; then
scripts/semantic-anomaly.sh:487:  await_lines=$(echo "$content" | grep -n 'await\s' 2>/dev/null | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:492:    before_content=$(echo "$content" | head -n "$line_num")
scripts/semantic-anomaly.sh:495:    try_count=$(echo "$before_content" | grep -c 'try\s*{' 2>/dev/null || true)
scripts/semantic-anomaly.sh:497:    catch_count=$(echo "$before_content" | grep -c 'catch\s*(' 2>/dev/null || true)
scripts/semantic-anomaly.sh:500:    if [ "$try_count" -gt "$catch_count" ]; then
scripts/semantic-anomaly.sh:505:    current_line=$(echo "$content" | sed -n "${line_num}p")
scripts/semantic-anomaly.sh:506:    if echo "$current_line" | grep -q '\.catch(' ; then
scripts/semantic-anomaly.sh:512:      call_name=$(echo "$current_line" | sed -n 's/.*await\s\+\([a-zA-Z_][a-zA-Z0-9_]*\).*/\1/p' | head -1)
scripts/semantic-anomaly.sh:520:      [ -z "$pattern_source" ] && pattern_source="builtin:async-try-catch"
scripts/semantic-anomaly.sh:523:      if [ -n "$enclosing_func" ]; then
scripts/semantic-anomaly.sh:547:  promise_lines=$(echo "$content" | grep -n '\.then\s*(' 2>/dev/null | grep -v '\.catch' | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:551:    current_line=$(echo "$content" | sed -n "${line_num}p")
scripts/semantic-anomaly.sh:554:    next_lines=$(echo "$content" | tail -n "+$((line_num + 1))" | head -5)
scripts/semantic-anomaly.sh:556:    if ! echo "$next_lines" | grep -q '\.catch\s*(' && ! echo "$current_line" | grep -q '\.catch\s*('; then
scripts/semantic-anomaly.sh:558:      before_content=$(echo "$content" | head -n "$line_num")
scripts/semantic-anomaly.sh:560:      try_count=$(echo "$before_content" | grep -c 'try\s*{' 2>/dev/null || true)
scripts/semantic-anomaly.sh:562:      catch_count=$(echo "$before_content" | grep -c 'catch\s*(' 2>/dev/null || true)
scripts/semantic-anomaly.sh:565:      if [ "$try_count" -le "$catch_count" ]; then
scripts/semantic-anomaly.sh:568:        [ -z "$pattern_source" ] && pattern_source="builtin:promise-catch"
scripts/semantic-anomaly.sh:589:  bare_fetch_lines=$(echo "$content" | grep -n 'fetch\s*(' 2>/dev/null | grep -v 'await\s*fetch' | grep -v '\.then' | grep -v '\.catch' | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:593:    current_line=$(echo "$content" | sed -n "${line_num}p")
scripts/semantic-anomaly.sh:596:    if echo "$current_line" | grep -qE '^\s*(const|let|var)\s+[a-zA-Z_]'; then
scripts/semantic-anomaly.sh:616:      before_content=$(echo "$content" | head -n "$line_num")
scripts/semantic-anomaly.sh:618:      try_count=$(echo "$before_content" | grep -c 'try\s*{' 2>/dev/null || true)
scripts/semantic-anomaly.sh:620:      catch_count=$(echo "$before_content" | grep -c 'catch\s*(' 2>/dev/null || true)
scripts/semantic-anomaly.sh:623:      if [ "$try_count" -le "$catch_count" ]; then
scripts/semantic-anomaly.sh:631:      [ -z "$pattern_source" ] && pattern_source="builtin:fetch-error"
scripts/semantic-anomaly.sh:634:      if [ -n "$enclosing_func" ]; then
scripts/semantic-anomaly.sh:664:    [ -x "$p" ] && { rg_cmd="$p"; break; }
scripts/semantic-anomaly.sh:667:  if [ -z "$rg_cmd" ]; then
scripts/semantic-anomaly.sh:668:    rg_cmd="grep -n"
scripts/semantic-anomaly.sh:674:  if [ -z "$content" ]; then
scripts/semantic-anomaly.sh:699:  if [ -z "$content" ]; then
scripts/semantic-anomaly.sh:706:  has_logger_import=$(echo "$content" | grep -c "import.*logger\|require.*logger" 2>/dev/null || true)
scripts/semantic-anomaly.sh:709:  if [ "$has_logger_import" -gt 0 ]; then
scripts/semantic-anomaly.sh:712:    console_lines=$(echo "$content" | grep -n 'console\.\(log\|warn\|error\|info\|debug\)' 2>/dev/null | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:717:      [ -z "$pattern_source" ] && pattern_source="builtin:consistent-logging"
scripts/semantic-anomaly.sh:732:    console_lines=$(echo "$content" | grep -n 'console\.\(log\|warn\|error\|info\)' 2>/dev/null | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:737:      [ -z "$pattern_source" ] && pattern_source="builtin:console-usage"
scripts/semantic-anomaly.sh:766:  if [ -z "$content" ]; then
scripts/semantic-anomaly.sh:775:    snake_case_lines=$(echo "$content" | grep -nE '(const|let|var)[[:space:]]+[a-z][a-z0-9]*_[a-z]' 2>/dev/null | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:779:      current_line=$(echo "$content" | sed -n "${line_num}p")
scripts/semantic-anomaly.sh:783:      var_name=$(echo "$current_line" | sed -E 's/.*(const|let|var)[[:space:]]+([a-z][a-z0-9_]*).*/\2/')
scripts/semantic-anomaly.sh:786:      if echo "$var_name" | grep -q '^[A-Z_]*$'; then
scripts/semantic-anomaly.sh:792:      [ -z "$pattern_source" ] && pattern_source="builtin:camelCase"
scripts/semantic-anomaly.sh:810:    snake_func_lines=$(echo "$content" | grep -nE 'function[[:space:]]+[a-z][a-z0-9]*_[a-z]' 2>/dev/null | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:814:      current_line=$(echo "$content" | sed -n "${line_num}p")
scripts/semantic-anomaly.sh:817:      func_name=$(echo "$current_line" | sed -E 's/.*function[[:space:]]+([a-z][a-z0-9_]*).*/\1/')
scripts/semantic-anomaly.sh:821:      [ -z "$pattern_source" ] && pattern_source="builtin:camelCase"
scripts/semantic-anomaly.sh:852:  if [ -z "$content" ]; then
scripts/semantic-anomaly.sh:872:    func_lines=$(echo "$content" | grep -ni "\(async\s\+\)\?function\s\+[a-zA-Z_]*${pattern}[a-zA-Z_]*\|[a-zA-Z_]*${pattern}[a-zA-Z_]*\s*=\s*\(async\s*\)\?(" 2>/dev/null | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:877:      func_body=$(echo "$content" | tail -n "+$line_num" | head -20)
scripts/semantic-anomaly.sh:881:      has_log=$(echo "$func_body" | grep -c '\(console\.\|logger\.\|log\.\)\(info\|warn\|error\|debug\|log\)' 2>/dev/null || true)
scripts/semantic-anomaly.sh:884:      if [ "$has_log" -eq 0 ]; then
scripts/semantic-anomaly.sh:886:        current_line=$(echo "$content" | sed -n "${line_num}p")
scripts/semantic-anomaly.sh:889:        func_name=$(echo "$current_line" | sed -n 's/.*function\s\+\([a-zA-Z_][a-zA-Z0-9_]*\).*/\1/p')
scripts/semantic-anomaly.sh:890:        [ -z "$func_name" ] && func_name=$(echo "$current_line" | sed -n 's/.*\([a-zA-Z_][a-zA-Z0-9_]*\)\s*=.*/\1/p')
scripts/semantic-anomaly.sh:895:        [ -z "$pattern_source" ] && pattern_source="builtin:critical-logging"
scripts/semantic-anomaly.sh:911:  catch_lines=$(echo "$content" | grep -n 'catch\s*(' 2>/dev/null | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:916:    catch_body=$(echo "$content" | tail -n "+$line_num" | head -5)
scripts/semantic-anomaly.sh:920:    has_handling=$(echo "$catch_body" | grep -c '\(console\.\|logger\.\|log\.\|throw\)' 2>/dev/null || true)
scripts/semantic-anomaly.sh:923:    if [ "$has_handling" -eq 0 ]; then
scripts/semantic-anomaly.sh:926:      [ -z "$pattern_source" ] && pattern_source="builtin:catch-logging"
scripts/semantic-anomaly.sh:954:  if [ -z "$content" ]; then
scripts/semantic-anomaly.sh:960:  import_lines=$(echo "$content" | grep -n '^import ' 2>/dev/null | head -50 || true)
scripts/semantic-anomaly.sh:962:  while IFS= read -r import_line; do
scripts/semantic-anomaly.sh:963:    [ -z "$import_line" ] && continue
scripts/semantic-anomaly.sh:966:    line_num=$(echo "$import_line" | cut -d: -f1)
scripts/semantic-anomaly.sh:968:    line_content=$(echo "$import_line" | cut -d: -f2-)
scripts/semantic-anomaly.sh:974:    if echo "$line_content" | grep -q '{'; then
scripts/semantic-anomaly.sh:975:      imported_names=$(echo "$line_content" | sed -E 's/.*\{[[:space:]]*//' | sed -E 's/[[:space:]]*\}.*//' | tr ',' '\n' | sed -E 's/[[:space:]]*as[[:space:]]+[a-zA-Z_][a-zA-Z0-9_]*//' | tr -d ' ')
scripts/semantic-anomaly.sh:977:    elif echo "$line_content" | grep -q 'import [a-zA-Z_]'; then
scripts/semantic-anomaly.sh:978:      imported_names=$(echo "$line_content" | sed -E 's/import[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*).*/\1/')
scripts/semantic-anomaly.sh:983:      [ -z "$name" ] && continue
scripts/semantic-anomaly.sh:987:      remaining_content=$(echo "$content" | tail -n "+$((line_num + 1))")
scripts/semantic-anomaly.sh:992:      code_only=$(echo "$remaining_content" | grep -v '^\s*//' | sed 's|//.*||g')
scripts/semantic-anomaly.sh:994:      # ‰ΩøÁî® grep -w ËøõË°åÂçïËØçËæπÁïåÂåπÈÖç
scripts/semantic-anomaly.sh:996:      usage_count=$(echo "$code_only" | grep -cw "${name}" 2>/dev/null || true)
scripts/semantic-anomaly.sh:999:      if [ "$usage_count" -eq 0 ]; then
scripts/semantic-anomaly.sh:1002:        [ -z "$pattern_source" ] && pattern_source="builtin:unused-import"
scripts/semantic-anomaly.sh:1031:  if [ -z "$content" ]; then
scripts/semantic-anomaly.sh:1037:  callback_lines=$(echo "$content" | grep -n '\.then[[:space:]]*(' 2>/dev/null | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:1041:    current_line=$(echo "$content" | sed -n "${line_num}p")
scripts/semantic-anomaly.sh:1045:    next_lines=$(echo "$content" | tail -n "+$line_num" | head -10)
scripts/semantic-anomaly.sh:1049:    then_count=$(echo "$next_lines" | grep -o '\.then[[:space:]]*(' 2>/dev/null | wc -l || true)
scripts/semantic-anomaly.sh:1050:    then_count=$(echo "$then_count" | tr -d ' ')
scripts/semantic-anomaly.sh:1053:    if [ "$then_count" -ge 2 ]; then
scripts/semantic-anomaly.sh:1056:      [ -z "$pattern_source" ] && pattern_source="builtin:async-await"
scripts/semantic-anomaly.sh:1071:  var_lines=$(echo "$content" | grep -nw 'var' 2>/dev/null | cut -d: -f1 || true)
scripts/semantic-anomaly.sh:1076:    [ -z "$pattern_source" ] && pattern_source="builtin:const-let"
scripts/semantic-anomaly.sh:1124:  files=$(find "$dir" -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \) \
scripts/semantic-anomaly.sh:1125:    -not -path "*/node_modules/*" \
scripts/semantic-anomaly.sh:1126:    -not -path "*/.git/*" \
scripts/semantic-anomaly.sh:1127:    -not -path "*/dist/*" \
scripts/semantic-anomaly.sh:1128:    -not -path "*/build/*" \
scripts/semantic-anomaly.sh:1131:  while IFS= read -r file; do
scripts/semantic-anomaly.sh:1132:    [ -z "$file" ] && continue
scripts/semantic-anomaly.sh:1154:  if [ -z "$output_file" ]; then
scripts/semantic-anomaly.sh:1158:  mkdir -p "$(dirname "$output_file")"
scripts/semantic-anomaly.sh:1160:  echo "$ANOMALIES_JSON" | jq -c '
scripts/semantic-anomaly.sh:1181:  if [ -z "$target_file" ] || [ -z "$target_line" ] || [ -z "$feedback" ]; then
scripts/semantic-anomaly.sh:1192:  mkdir -p "$devbooks_dir"
scripts/semantic-anomaly.sh:1198:  jq -cn \
scripts/semantic-anomaly.sh:1199:    --arg file "$target_file" \
scripts/semantic-anomaly.sh:1200:    --argjson line "$target_line" \
scripts/semantic-anomaly.sh:1201:    --arg feedback "$feedback" \
scripts/semantic-anomaly.sh:1202:    --argjson timestamp "$ts" \
scripts/semantic-anomaly.sh:1212:  mkdir -p "$report_dir"
scripts/semantic-anomaly.sh:1217:    echo "- Total: $(echo "$summary" | jq -r '.total')"
scripts/semantic-anomaly.sh:1219:    echo "$summary" | jq -r '.by_type | to_entries[] | "  - \(.key): \(.value)"'
scripts/semantic-anomaly.sh:1221:    echo "$summary" | jq -r '.by_severity | to_entries[] | "  - \(.key): \(.value)"'
scripts/semantic-anomaly.sh:1225:    echo "$ANOMALIES_JSON" | jq -r '.[] | "- [\(.severity)] \(.file):\(.line) \(.type) - \(.message)"'
scripts/semantic-anomaly.sh:1234:  jq -n \
scripts/semantic-anomaly.sh:1235:    --argjson anomalies "$ANOMALIES_JSON" \
scripts/semantic-anomaly.sh:1236:    --argjson summary "$summary" \
scripts/semantic-anomaly.sh:1253:  echo "  Total anomalies: $(echo "$summary" | jq -r '.total')"
scripts/semantic-anomaly.sh:1256:  echo "$summary" | jq -r '.by_type | to_entries[] | "  \(.key): \(.value)"'
scripts/semantic-anomaly.sh:1259:  echo "$summary" | jq -r '.by_severity | to_entries[] | "  \(.key): \(.value)"'
scripts/semantic-anomaly.sh:1264:  echo "$ANOMALIES_JSON" | jq -r '.[] | "\(.severity | ascii_upcase) \(.file):\(.line) [\(.type)]\n  \(.message)\n  Suggestion: \(.suggestion)\n"'
scripts/semantic-anomaly.sh:1277:  # Â¶ÇÊûúÁî®Êà∑ÊòéÁ°ÆËØ∑Ê±ÇËæìÂá∫Ôºà--output, --reportÔºâÊàñÂº∫Âà∂ÂêØÁî®ÔºåÂàôË∑≥ËøáÂäüËÉΩÂºÄÂÖ≥Ê£ÄÊü•
scripts/semantic-anomaly.sh:1279:  if [[ "$FORCE_ENABLE_ANOMALY" == "true" || "$REPORT_MODE" == "true" || -n "$OUTPUT_FILE" ]]; then
scripts/semantic-anomaly.sh:1283:  if [[ "$skip_feature_check" != "true" ]] && declare -f is_feature_enabled &>/dev/null; then
scripts/semantic-anomaly.sh:1294:  if [ -d "$TARGET_PATH" ]; then
scripts/semantic-anomaly.sh:1300:  if [ -n "$OUTPUT_FILE" ]; then
