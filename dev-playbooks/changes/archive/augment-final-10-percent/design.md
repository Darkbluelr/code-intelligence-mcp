# 设计文档：弥合 Augment 最后 10% 轻资产差距

> **Change ID**: `augment-final-10-percent`
> **Version**: 1.0.0
> **Status**: Draft
> **Last Updated**: 2026-01-17

---

## 1. Problem Context（问题上下文）

### 1.1 现状分析

当前项目代码智能能力与 Augment Code 对比：

| 能力域 | 当前 | 目标 | 差距 |
|--------|------|------|------|
| LLM 重排序 | 硬编码单厂商 | 可插拔多厂商 | 抽象接口缺失 |
| 语义分析 | 模式学习 | 异常检测 | 检测器缺失 |
| 数据流 | 单函数 | 跨函数 | 算法缺失 |
| 延迟 | 50ms 取消 | <10ms 取消 | 优化空间 |
| 上下文 | 原始代码 | 智能压缩 | 压缩器缺失 |
| 记忆 | 10 轮 | 无限 | 存储缺失 |

### 1.2 设计目标

1. **可扩展性**：新增 LLM 厂商无需修改核心代码
2. **性能**：关键路径延迟优化 80%
3. **准确性**：Bug 定位准确率提升 15%
4. **兼容性**：100% 后向兼容现有 API

---

## 2. Architecture（架构设计）

### 2.1 整体架构

```
┌─────────────────────────────────────────────────────────────────────┐
│                        Code Intelligence MCP                         │
├─────────────────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐ │
│  │  MCP Tools  │  │   Hooks     │  │   Daemon    │  │   Config    │ │
│  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘ │
│         │                │                │                │         │
│  ┌──────┴────────────────┴────────────────┴────────────────┴──────┐ │
│  │                     Core Analysis Layer                         │ │
│  │  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐   │ │
│  │  │LLM      │ │Semantic │ │DataFlow │ │Context  │ │Drift    │   │ │
│  │  │Provider │ │Anomaly  │ │Tracer   │ │Compress │ │Detector │   │ │
│  │  └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘   │ │
│  └───────┼───────────┼───────────┼───────────┼───────────┼────────┘ │
│          │           │           │           │           │          │
│  ┌───────┴───────────┴───────────┴───────────┴───────────┴────────┐ │
│  │                     Shared Infrastructure                       │ │
│  │  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐   │ │
│  │  │Graph    │ │Pattern  │ │Cache    │ │Intent   │ │Federation│  │ │
│  │  │Store    │ │Learner  │ │Manager  │ │Learner  │ │Lite     │   │ │
│  │  └─────────┘ └─────────┘ └─────────┘ └─────────┘ └─────────┘   │ │
│  └────────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────┘
```

### 2.2 M1: LLM Provider 抽象架构

```
┌─────────────────────────────────────────────────────────────────┐
│                      llm-provider.sh                             │
├─────────────────────────────────────────────────────────────────┤
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                    Provider Interface                    │    │
│  │  ─────────────────────────────────────────────────────  │    │
│  │  llm_rerank(query, candidates) → RankedResult           │    │
│  │  llm_call(prompt) → Response                            │    │
│  │  llm_validate_config() → bool                           │    │
│  │  llm_get_info() → ProviderInfo                          │    │
│  └─────────────────────────────────────────────────────────┘    │
│                              │                                   │
│         ┌────────────────────┼────────────────────┐              │
│         ▼                    ▼                    ▼              │
│  ┌─────────────┐      ┌─────────────┐      ┌─────────────┐      │
│  │  anthropic  │      │   openai    │      │   ollama    │      │
│  │  .sh        │      │   .sh       │      │   .sh       │      │
│  ├─────────────┤      ├─────────────┤      ├─────────────┤      │
│  │ API: Claude │      │ API: GPT    │      │ API: Local  │      │
│  │ Key: ANT_*  │      │ Key: OAI_*  │      │ Key: None   │      │
│  │ Model: haiku│      │ Model: mini │      │ Model: any  │      │
│  └─────────────┘      └─────────────┘      └─────────────┘      │
└─────────────────────────────────────────────────────────────────┘
```

**Provider 注册机制**：

```bash
# config/llm-providers.yaml
providers:
  anthropic:
    script: llm-providers/anthropic.sh
    env_key: ANTHROPIC_API_KEY
    default_model: claude-3-haiku-20240307

  openai:
    script: llm-providers/openai.sh
    env_key: OPENAI_API_KEY
    default_model: gpt-4o-mini

  ollama:
    script: llm-providers/ollama.sh
    env_key: null  # 无需 API Key
    default_model: llama3
    endpoint: http://localhost:11434
```

### 2.3 M2: 语义异常检测架构

```
┌─────────────────────────────────────────────────────────────────┐
│                    semantic-anomaly.sh                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌─────────────┐     ┌─────────────┐     ┌─────────────┐        │
│  │  Pattern    │     │  Anomaly    │     │  Report     │        │
│  │  Loader     │────▶│  Detector   │────▶│  Generator  │        │
│  └─────────────┘     └─────────────┘     └─────────────┘        │
│         │                   │                                    │
│         ▼                   ▼                                    │
│  ┌─────────────┐     ┌─────────────┐                            │
│  │ pattern-    │     │  AST        │                            │
│  │ learner.sh  │     │  Analyzer   │                            │
│  └─────────────┘     └─────────────┘                            │
│                                                                  │
│  检测类型：                                                       │
│  ─────────                                                       │
│  • MISSING_ERROR_HANDLER  - 缺失错误处理                         │
│  • INCONSISTENT_API_CALL  - 不一致的 API 调用                    │
│  • NAMING_VIOLATION       - 命名约定违规                         │
│  • MISSING_LOG            - 缺失日志/监控                        │
│  • UNUSED_IMPORT          - 未使用的导入                         │
│  • DEPRECATED_PATTERN     - 使用已废弃模式                       │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 2.4 M3: 跨函数数据流追踪架构

```
┌─────────────────────────────────────────────────────────────────┐
│                  call-chain.sh --data-flow                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  输入: symbol + 追踪方向(forward/backward)                       │
│                                                                  │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                    Data Flow Graph                       │    │
│  │                                                          │    │
│  │   ┌───────┐    ┌───────┐    ┌───────┐    ┌───────┐      │    │
│  │   │ Src A │───▶│ Func B│───▶│ Func C│───▶│ Sink D│      │    │
│  │   │ (def) │    │(trans)│    │(trans)│    │ (use) │      │    │
│  │   └───────┘    └───────┘    └───────┘    └───────┘      │    │
│  │       │            │            │            │           │    │
│  │       ▼            ▼            ▼            ▼           │    │
│  │    [x=input]  [y=f(x)]    [z=g(y)]    [print(z)]        │    │
│  │                                                          │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                  │
│  算法：污点传播（Taint Propagation）                             │
│  ─────                                                           │
│  1. 从源符号开始，标记为 TAINTED                                 │
│  2. 沿调用图边传播污点                                           │
│  3. 记录每个转换点的变量映射                                     │
│  4. 到达 sink 或深度限制时停止                                   │
│                                                                  │
│  输出格式：                                                       │
│  {                                                               │
│    "source": {"symbol": "x", "file": "a.ts", "line": 10},       │
│    "sink": {"symbol": "z", "file": "c.ts", "line": 50},         │
│    "path": [                                                     │
│      {"symbol": "x", "transform": "input", "file": "a.ts"},     │
│      {"symbol": "y", "transform": "f(x)", "file": "b.ts"},      │
│      {"symbol": "z", "transform": "g(y)", "file": "c.ts"}       │
│    ]                                                             │
│  }                                                               │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 2.5 M4: 击键级请求取消架构

```
┌─────────────────────────────────────────────────────────────────┐
│                    daemon.sh (优化版)                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  当前实现（50ms 轮询）：                                         │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  while true; do                                          │    │
│  │    sleep 0.05  # 50ms                                    │    │
│  │    check_cancel_flag                                     │    │
│  │  done                                                    │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                  │
│  优化实现（信号驱动 <10ms）：                                    │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  # 预分配取消令牌                                        │    │
│  │  cancel_token=$(mktemp)                                  │    │
│  │                                                          │    │
│  │  # 信号处理器                                            │    │
│  │  trap 'echo "cancelled" > $cancel_token' SIGUSR1        │    │
│  │                                                          │    │
│  │  # 工作进程定期检查令牌（原子读取）                       │    │
│  │  if [[ -s "$cancel_token" ]]; then                       │    │
│  │    exit 130  # Cancelled                                 │    │
│  │  fi                                                      │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                  │
│  取消流程：                                                       │
│  ┌───────┐    SIGUSR1    ┌───────┐    read token   ┌───────┐   │
│  │Client │──────────────▶│Daemon │───────────────▶│Worker │    │
│  └───────┘    (<1ms)     └───────┘     (<5ms)      └───────┘    │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 2.6 M5: 上下文智能压缩架构

```
┌─────────────────────────────────────────────────────────────────┐
│                   context-compressor.sh                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  输入: 代码文件列表 + Token 预算                                 │
│                                                                  │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                   压缩流水线                              │    │
│  │                                                          │    │
│  │  Stage 1: AST 骨架提取                                   │    │
│  │  ────────────────────                                    │    │
│  │  • 保留：函数签名、类定义、接口                          │    │
│  │  • 移除：函数体、注释、空白                              │    │
│  │  • 压缩率：~60%                                          │    │
│  │                                                          │    │
│  │  Stage 2: 符号签名摘要                                   │    │
│  │  ────────────────────                                    │    │
│  │  • 提取：参数类型、返回类型、泛型约束                    │    │
│  │  • 格式：`fn(A, B) → C`                                  │    │
│  │  • 压缩率：~80%                                          │    │
│  │                                                          │    │
│  │  Stage 3: 热点优先选择                                   │    │
│  │  ────────────────────                                    │    │
│  │  • 按热点分数排序                                        │    │
│  │  • 优先保留高热点代码                                    │    │
│  │  • 在预算内最大化覆盖                                    │    │
│  │                                                          │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                  │
│  输出格式：                                                       │
│  {                                                               │
│    "compressed_context": "...",                                  │
│    "original_tokens": 10000,                                     │
│    "compressed_tokens": 2000,                                    │
│    "compression_ratio": 0.8,                                     │
│    "preserved_symbols": ["fn1", "fn2", "class1"]                │
│  }                                                               │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 2.7 M6: 对话长期记忆架构

```
┌─────────────────────────────────────────────────────────────────┐
│                  intent-learner.sh (扩展)                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │              Conversation Memory Store                   │    │
│  │              .devbooks/conversation-memory.db            │    │
│  │                                                          │    │
│  │  Tables:                                                 │    │
│  │  ────────                                                │    │
│  │  conversations(id, created_at, summary)                  │    │
│  │  turns(id, conv_id, role, content, symbols[], ts)       │    │
│  │  summaries(id, conv_id, turn_range, summary, ts)        │    │
│  │  symbol_index(symbol, conv_id, turn_id, relevance)      │    │
│  │                                                          │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                  │
│  记忆策略：                                                       │
│  ──────────                                                      │
│  1. 实时存储：每轮对话立即写入 turns 表                          │
│  2. 滚动摘要：每 10 轮生成一次摘要，存入 summaries 表           │
│  3. 符号索引：提取对话中的代码符号，建立倒排索引                 │
│  4. 按需召回：根据当前查询，检索相关历史上下文                   │
│                                                                  │
│  召回算法：                                                       │
│  ──────────                                                      │
│  1. 提取当前查询的关键符号                                       │
│  2. 在 symbol_index 中检索相关对话                               │
│  3. 获取对应的 summaries 或 turns                                │
│  4. 按相关性排序，返回 Top-K                                     │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 3. Constraints（约束条件）

### 3.1 技术约束

| ID | 约束 | 原因 |
|----|------|------|
| CON-001 | 所有新脚本必须 source common.sh | 保持一致性 |
| CON-002 | LLM Provider 必须支持 Mock 模式 | 测试需求 |
| CON-003 | 数据流追踪深度默认 ≤5 跳 | 性能考虑 |
| CON-004 | 上下文压缩必须保留完整签名 | 准确性需求 |
| CON-005 | 记忆存储必须使用 SQLite | 与 graph.db 一致 |

### 3.2 兼容性约束

| ID | 约束 | 验证方式 |
|----|------|----------|
| COMPAT-001 | 现有 `llm_call()` API 不变 | 回归测试 |
| COMPAT-002 | 现有配置格式兼容 | 升级测试 |
| COMPAT-003 | 现有 MCP 工具签名不变 | 契约测试 |

---

## 4. Data Flow（数据流）

### 4.1 LLM 重排序数据流

```
┌─────────┐     ┌─────────────┐     ┌─────────────┐     ┌─────────┐
│ Query   │────▶│ graph-rag   │────▶│ llm-provider│────▶│ Ranked  │
│         │     │ (Top-K)     │     │ (Rerank)    │     │ Results │
└─────────┘     └─────────────┘     └─────────────┘     └─────────┘
                      │                    │
                      ▼                    ▼
               ┌─────────────┐     ┌─────────────┐
               │ Vector      │     │ Provider    │
               │ Search      │     │ Selector    │
               └─────────────┘     └─────────────┘
```

### 4.2 语义异常检测数据流

```
┌─────────┐     ┌─────────────┐     ┌─────────────┐     ┌─────────┐
│ Files   │────▶│ pattern-    │────▶│ semantic-   │────▶│ Report  │
│         │     │ learner     │     │ anomaly     │     │         │
└─────────┘     └─────────────┘     └─────────────┘     └─────────┘
                      │                    │
                      ▼                    ▼
               ┌─────────────┐     ┌─────────────┐
               │ Learned     │     │ AST         │
               │ Patterns    │     │ Analysis    │
               └─────────────┘     └─────────────┘
```

---

## 5. Acceptance Criteria（验收标准）

### AC-001: LLM Provider 抽象接口

**Given**: 配置文件指定 `provider: openai`
**When**: 调用 `llm_rerank()`
**Then**:
- 自动加载 OpenAI Provider
- 使用 OpenAI API 进行重排序
- 返回标准化结果格式

### AC-002: Provider 无缝切换

**Given**: 已有使用 Anthropic 的代码
**When**: 修改配置为 `provider: ollama`
**Then**:
- 无需修改调用代码
- 自动切换到 Ollama
- 功能正常工作

### AC-003: 语义异常检测

**Given**: 项目中存在不一致的 API 调用模式
**When**: 运行 `semantic-anomaly.sh`
**Then**:
- 检测出 ≥3 种异常类型
- 输出可读的报告
- 提供修复建议

### AC-004: 跨函数数据流

**Given**: 变量从函数 A 传递到函数 C（经过 B）
**When**: 运行 `call-chain.sh --data-flow A.x`
**Then**:
- 追踪到完整路径 A → B → C
- 显示每个转换点
- 深度支持 ≥3 跳

### AC-005: 请求取消延迟

**Given**: 正在执行的长时间查询
**When**: 发送取消信号
**Then**: P95 延迟 < 10ms 响应取消

### AC-006: 上下文压缩

**Given**: 10000 Token 的代码上下文
**When**: 运行 `context-compressor.sh --budget 5000`
**Then**:
- 输出 ≤5000 Token
- 保留所有函数签名
- 优先保留热点代码

### AC-007: 对话长期记忆

**Given**: 100 轮历史对话
**When**: 查询相关符号
**Then**:
- 召回相关历史上下文
- 延迟 < 100ms

---

## 6. Decision Log

| 日期 | 决策 | 理由 |
|------|------|------|
| 2026-01-17 | 采用 Bash 函数级 Provider 抽象 | 简单、与现有架构一致 |
| 2026-01-17 | 数据流追踪基于 SCIP | 充分利用现有索引 |
| 2026-01-17 | 长期记忆使用 SQLite | 与 graph.db 保持一致 |
| 2026-01-17 | 请求取消使用信号机制 | 延迟最低 |
