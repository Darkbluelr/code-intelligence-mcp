
    # 获取相对路径
    local rel_path="${file#$PROJECT_ROOT/}"

    # 读取文件内容（限制大小）
    if [ -f "$file" ] && [ $(wc -c < "$file") -lt 1000000 ]; then
      local content=$(cat "$file" | tr '\n' ' ' | head -c 10000)
      echo -e "$rel_path\t$content" >> "$output_file"
    fi
  done

  local file_count=$(wc -l < "$output_file")
  log_ok "提取完成: $file_count 个文件"
}

# ==================== 向量数据库 ====================

# 初始化向量数据库
init_vector_db() {
  log_info "初始化向量数据库: $VECTOR_DB_DIR"

  mkdir -p "$VECTOR_DB_DIR"

  # 创建元数据文件
  cat > "$VECTOR_DB_DIR/metadata.json" <<EOF
{
  "model": "$API_MODEL",
  "dimension": $DIMENSION,
  "index_type": "$INDEX_TYPE",
  "created_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "updated_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
}
EOF

  > "$VECTOR_DB_DIR/index.tsv"

  log_ok "向量数据库已初始化"
}

# 构建向量索引
build_index() {
  log_info "开始构建向量索引..."

  if [ "$ENABLED" != "true" ]; then
    log_warn "Embedding 功能未启用"
    return 1
  fi

  # 初始化
  init_vector_db

  # 提取代码文件
  local code_files="$TEMP_DIR/code_files.tsv"
  extract_code_files "$code_files"

  if [ ! -s "$code_files" ]; then
    log_warn "未找到代码文件"
    return 0
  fi

  # 批量生成向量
  batch_embed "$code_files" "$VECTOR_DB_DIR"

  # 更新元数据
  local file_count=$(wc -l < "$VECTOR_DB_DIR/index.tsv")
  local updated_metadata=$(jq \
    --arg updated "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
    --arg count "$file_count" \
    '.updated_at = $updated | .file_count = ($count | tonumber)' \
    "$VECTOR_DB_DIR/metadata.json")

  echo "$updated_metadata" > "$VECTOR_DB_DIR/metadata.json"

  log_ok "索引构建完成: $file_count 个文件"
}

# 增量更新索引
update_index() {
  log_info "增量更新向量索引..."

  if [ ! -f "$VECTOR_DB_DIR/index.tsv" ]; then
    log_warn "索引不存在，执行全量构建"
    build_index
    return $?
  fi

  # 检查修改的文件
  local modified_files="$TEMP_DIR/modified_files.tsv"
  > "$modified_files"

  # 获取索引更新时间
  local index_mtime=$(stat -f %m "$VECTOR_DB_DIR/index.tsv" 2>/dev/null || stat -c %Y "$VECTOR_DB_DIR/index.tsv" 2>/dev/null)

  # 查找比索引更新的文件
  extract_code_files "$TEMP_DIR/all_files.tsv"

  while IFS=$'\t' read -r file_path content; do
    local full_path="$PROJECT_ROOT/$file_path"
    if [ -f "$full_path" ]; then
      local file_mtime=$(stat -f %m "$full_path" 2>/dev/null || stat -c %Y "$full_path" 2>/dev/null)
      if [ "$file_mtime" -gt "$index_mtime" ]; then
        echo -e "$file_path\t$content" >> "$modified_files"
      fi
    fi
  done < "$TEMP_DIR/all_files.tsv"

  local modified_count=$(wc -l < "$modified_files" 2>/dev/null || echo 0)

  if [ "$modified_count" -eq 0 ]; then
    log_ok "索引已是最新，无需更新"
    return 0
  fi

  log_info "发现 $modified_count 个修改的文件"

  # 删除旧向量
  while IFS=$'\t' read -r file_path hash; do
    rm -f "$VECTOR_DB_DIR/$hash.json"
  done < <(grep -Ff <(cut -f1 "$modified_files") "$VECTOR_DB_DIR/index.tsv" 2>/dev/null || true)

  # 重建这些文件的向量
  batch_embed "$modified_files" "$VECTOR_DB_DIR"

  log_ok "增量更新完成: $modified_count 个文件"
}

# ==================== 搜索 ====================

# 计算余弦相似度
cosine_similarity() {
  local vec1="$1"
  local vec2="$2"

  # 使用 Python 计算（如果可用）
  if command -v python3 &>/dev/null; then
    python3 -c "
import json
import sys
from math import sqrt

v1 = json.loads('$vec1')
v2 = json.loads('$vec2')

dot = sum(a*b for a, b in zip(v1, v2))
norm1 = sqrt(sum(a*a for a in v1))
norm2 = sqrt(sum(b*b for b in v2))

similarity = dot / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else 0
print(f'{similarity:.6f}')
"
  else
    # 降级：返回随机相似度（仅用于测试）
    echo "0.500000"
  fi
}

# 语义搜索（支持三级降级）
semantic_search() {
  local query="$1"
  local top_k="${2:-$TOP_K}"
  local format="${CLI_FORMAT:-text}"

  # JSON 输出时启用静默模式
  if [[ "$format" == "json" ]]; then
    QUIET_MODE=true
  fi

  log_info "语义搜索: \"$query\""

  # 记录开始时间（macOS 兼容）
  local start_time
  if [[ "$OSTYPE" == "darwin"* ]]; then
    start_time=$(($(date +%s) * 1000))
  else
    start_time=$(date +%s%3N 2>/dev/null || echo $(($(date +%s) * 1000)))
  fi

  # 确定 provider
  local requested_provider="${CLI_PROVIDER:-$EMBEDDING_PROVIDER}"
  _select_provider "$requested_provider"
  ACTUAL_PROVIDER="$SELECTED_PROVIDER"

  log_info "使用 provider: $ACTUAL_PROVIDER"

  local candidates=()
  local model_used=""
  local search_success=false

  case "$ACTUAL_PROVIDER" in
    ollama)
      model_used="${CLI_OLLAMA_MODEL:-$OLLAMA_MODEL}"
      if _semantic_search_with_embedding "ollama" "$query" "$top_k"; then
        search_success=true
      else
        # 降级到 OpenAI
        log_warn "Ollama 搜索失败，降级到 OpenAI API"
        ACTUAL_PROVIDER="openai"
        if _detect_openai_api && _semantic_search_with_embedding "openai" "$query" "$top_k"; then
          model_used="$API_MODEL"
          search_success=true
        else
          # 降级到关键词
          log_warn "OpenAI API 不可用，降级到关键词搜索"
          ACTUAL_PROVIDER="keyword"
        fi
      fi
      ;;

    openai)
      model_used="$API_MODEL"
      if _semantic_search_with_embedding "openai" "$query" "$top_k"; then
        search_success=true
      else
        # 降级到关键词
        log_warn "OpenAI 搜索失败，降级到关键词搜索"
        ACTUAL_PROVIDER="keyword"
      fi
      ;;

    keyword)
      # 直接使用关键词搜索
      ;;
  esac

  # 如果需要关键词搜索
  if [[ "$ACTUAL_PROVIDER" == "keyword" ]]; then
    model_used="ripgrep"
    local keyword_results
    keyword_results=$(_search_with_keyword "$query" "$top_k")
    for file in $keyword_results; do
      candidates+=("$file")
    done
    search_success=true
  fi

  # 记录结束时间（macOS 兼容）
  local end_time
  if [[ "$OSTYPE" == "darwin"* ]]; then
    end_time=$(($(date +%s) * 1000))
  else
    end_time=$(date +%s%3N 2>/dev/null || echo $(($(date +%s) * 1000)))
  fi
  local latency_ms=$((end_time - start_time))

  # 输出结果
  if [[ "$format" == "json" ]]; then
    _output_json_results "$query" "$ACTUAL_PROVIDER" "$model_used" "$latency_ms" "$top_k"
  else
    _output_text_results "$query" "$top_k"
  fi

  if [[ "$search_success" == "true" ]]; then
    return 0
  else
    return 1
  fi
}

# 使用向量嵌入进行语义搜索
_semantic_search_with_embedding() {
  local provider="$1"
  local query="$2"
  local top_k="$3"

  # Mock 模式：创建假索引用于测试
  local using_mock_index=false
  if [[ -n "${MOCK_OLLAMA_AVAILABLE:-}" ]] || [[ "$API_KEY" == "sk-test-mock-key"* ]]; then
    if [ ! -f "$VECTOR_DB_DIR/index.tsv" ]; then
      log_debug "Mock 模式：创建临时测试索引"
      mkdir -p "$VECTOR_DB_DIR"
      # 创建假索引，使用关键词搜索的结果作为候选文件
      local mock_results
      mock_results=$(_search_with_keyword "$query" "$top_k")
      local idx=0
      for file in $mock_results; do
        local hash="mock_$(echo "$file" | md5sum 2>/dev/null | cut -d' ' -f1 || echo "$idx")"
        echo -e "${file}\t${hash}" >> "$VECTOR_DB_DIR/index.tsv"
        # 创建假向量文件
        echo '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]' > "$VECTOR_DB_DIR/${hash}.json"
        ((idx++)) || true
      done
      using_mock_index=true
    fi
  fi

  if [ ! -f "$VECTOR_DB_DIR/index.tsv" ]; then
    log_warn "向量索引不存在，请先运行: $0 build"
    return 1
  fi

  # 生成查询向量
  local query_vector_file="$TEMP_DIR/query_vector.json"

  case "$provider" in
    ollama)
      if ! _embed_with_ollama "$query" "$query_vector_file"; then
        return 1
      fi
      ;;
    openai)
      if ! call_embedding_api "$query" "$query_vector_file"; then
        return 1
      fi
      ;;
    *)
      log_error "未知 provider: $provider"
      return 1
      ;;
  esac

  local query_vector
  query_vector=$(cat "$query_vector_file")

  # 搜索相似向量
  local results="$TEMP_DIR/search_results.tsv"
  > "$results"

  log_debug "计算相似度..."

  while IFS=$'\t' read -r file_path hash; do
    local vector_file="$VECTOR_DB_DIR/$hash.json"

    if [ ! -f "$vector_file" ]; then
      continue
    fi

    local file_vector
    file_vector=$(cat "$vector_file")
    local similarity
    similarity=$(cosine_similarity "$query_vector" "$file_vector")

    # 过滤低于阈值的结果
    if (( $(echo "$similarity >= $SIMILARITY_THRESHOLD" | bc -l 2>/dev/null || echo 1) )); then
      echo -e "$similarity\t$file_path" >> "$results"
    fi
  done < "$VECTOR_DB_DIR/index.tsv"

  # 保存结果供后续输出
  if [ -s "$results" ]; then
    sort -rn "$results" | head -n "$top_k" > "$TEMP_DIR/final_results.tsv"
    return 0
  else
    return 1
  fi
}

# 输出 JSON 格式结果
_output_json_results() {
  local query="$1"
  local source="$2"
  local model="$3"
  local latency_ms="$4"
  local top_k="$5"

  local candidates_json="[]"

  if [[ "$source" == "keyword" ]]; then
    # 关键词搜索结果
    local keyword_results
    keyword_results=$(_search_with_keyword "$query" "$top_k")
    local idx=0
    local items=()
    for file in $keyword_results; do
      items+=("{\"file\":\"$file\",\"score\":0.5,\"source\":\"keyword\"}")
      ((idx++)) || true
    done
    if [[ ${#items[@]} -gt 0 ]]; then
      candidates_json=$(printf '%s\n' "${items[@]}" | jq -s '.')
    fi
  elif [ -f "$TEMP_DIR/final_results.tsv" ]; then
    # 向量搜索结果
    local items=()
    while IFS=$'\t' read -r score file; do
      items+=("{\"file\":\"$file\",\"score\":$score,\"source\":\"$source\"}")
    done < "$TEMP_DIR/final_results.tsv"
    if [[ ${#items[@]} -gt 0 ]]; then
      candidates_json=$(printf '%s\n' "${items[@]}" | jq -s '.')
    fi
  fi

  # 构建警告数组 JSON
  local warnings_json="[]"
  if [[ ${#COLLECTED_WARNINGS[@]} -gt 0 ]]; then
    warnings_json=$(printf '%s\n' "${COLLECTED_WARNINGS[@]}" | jq -R -s -c 'split("\n") | map(select(length > 0))')
  fi

  # 构建完整 JSON
  jq -n \
    --arg schema_version "1.0" \
    --arg query "$query" \
    --arg source "$source" \
    --arg model "$model" \
    --argjson candidates "$candidates_json" \
    --argjson latency_ms "$latency_ms" \
    --argjson warnings "$warnings_json" \
    '{
      schema_version: $schema_version,
      query: $query,
      source: $source,
      model: $model,
      candidates: $candidates,
      warnings: $warnings,
      metadata: {
        provider: $source,
        latency_ms: $latency_ms
      }
    }'
}

# 输出文本格式结果
_output_text_results() {
  local query="$1"
  local top_k="$2"

  if [[ "$ACTUAL_PROVIDER" == "keyword" ]]; then
    local keyword_results
    keyword_results=$(_search_with_keyword "$query" "$top_k")
    log_ok "找到关键词匹配结果"
    for file in $keyword_results; do
      echo "[keyword] $file"
      local full_path="$PROJECT_ROOT/$file"
      if [ -f "$full_path" ]; then
        echo "---"
        head -n 10 "$full_path" | sed 's/^/  /'
        echo ""
      fi
    done
  elif [ -f "$TEMP_DIR/final_results.tsv" ]; then
    log_ok "找到 $(wc -l < "$TEMP_DIR/final_results.tsv") 个相关结果"
    while IFS=$'\t' read -r score file; do
      echo "[$score] $file"
      local full_path="$PROJECT_ROOT/$file"
      if [ -f "$full_path" ]; then
        echo "---"
        head -n 10 "$full_path" | sed 's/^/  /'
        echo ""
      fi
    done < "$TEMP_DIR/final_results.tsv"
  else
    log_warn "未找到相关结果"
  fi
